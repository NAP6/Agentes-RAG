,type,block_type,Clasificacion Mamual,makes_sense,text,description,,coordinates_points,filetype,languages,page_number,filename,detection_class_prob,parent_id,image_path,,,,element_id
0,UncategorizedText,UncategorizedText,UncategorizedText,FALSE,1 2 0 2,The text block '1 2 0 2' does not provide coherent or understandable information and does not fit into any of the specified categories.,,"((45.388888888888886, 589.6111111111111), (45.388888888888886, 700.7222222222222), (100.94444444444446, 700.7222222222222), (100.94444444444446, 589.6111111111111))",application/pdf,['eng'],1,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,,,,,,,2a79c74e7aacdeced6760e8e3a21a60e
1,Header,UncategorizedText,UncategorizedText,FALSE,r p A 2 1 ] L C . s c [,The text block does not form a coherent or understandable sentence or phrase.,,"((45.1381721496582, 688.5795288085938), (45.1381721496582, 1412.005126953125), (100.94444444444446, 1412.005126953125), (100.94444444444446, 688.5795288085938))",application/pdf,['eng'],1,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.515811861,,,,,,6afcf8d92b2e1513a713972102cd8216
2,UncategorizedText,UncategorizedText,UncategorizedText,FALSE,4 v 1 0 4 1 1 . 5 0 0 2 : v i X r a,The text block does not make sense and does not fit into any of the specified categories.,,"((45.388888888888886, 1094.1666666666665), (45.388888888888886, 1555.5555555555554), (100.94444444444446, 1555.5555555555554), (100.94444444444446, 1094.1666666666665))",application/pdf,['eng'],1,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,,6afcf8d92b2e1513a713972102cd8216,,,,,3a8065e6efc332ca5cd4bf6950df8663
3,Title,Title,Title,TRUE,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks,"The text is a title for a document or section, likely related to a method or approach in natural language processing (NLP) that involves retrieval-augmented generation for tasks requiring extensive knowledge.",,"((463.0325927734375, 276.19338500000003), (463.0325927734375, 381.2864074707031), (1239.3253173828125, 381.2864074707031), (1239.3253173828125, 276.19338500000003))",application/pdf,['eng'],1,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.479248047,6afcf8d92b2e1513a713972102cd8216,,,,,683c711fcc9f2170bd2584bb150a2725
4,NarrativeText,Author Names,Author Names,TRUE,"Patrick Lewis'?, Ethan Perez*,","The text block lists the names of authors, specifically Patrick Lewis and Ethan Perez.",,"((664.65380859375, 498.6003255555554), (664.65380859375, 530.0421761111108), (1038.976318359375, 530.0421761111108), (1038.976318359375, 498.6003255555554))",application/pdf,['eng'],1,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.432447553,683c711fcc9f2170bd2584bb150a2725,,,,,5549ff0886ea40db28c2e81555d860fb
5,NarrativeText,Author Names,Author Names,TRUE,"Aleksandra Piktus†, Fabio Petroni†, Vladimir Karpukhin†, Naman Goyal†, Heinrich Küttler†,","This text block lists the names of authors, typically found at the beginning of academic papers or articles.",,"((301.7610168457031, 576.878103333333), (301.7610168457031, 608.3171761111107), (1434.0615234375, 608.3171761111107), (1434.0615234375, 576.878103333333))",application/pdf,['eng'],1,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.440989166,683c711fcc9f2170bd2584bb150a2725,,,,,55a1a3e368bec0cc7cf08f0f2c37199a
6,NarrativeText,Author Names,Author Names,TRUE,"Mike Lewis†, Wen-tau Yih†, Tim Rocktäschel†‡, Sebastian Riedel†‡, Douwe Kiela†",This text block lists the names of the authors of a document.,,"((363.132080078125, 655.153103333333), (363.132080078125, 686.5921761111107), (1333.4135456666668, 686.5921761111107), (1333.4135456666668, 655.153103333333))",application/pdf,['eng'],1,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.403286755,683c711fcc9f2170bd2584bb150a2725,,,,,e854e908dcc69424c54ebccb27b30973
7,Title,UncategorizedText,UncategorizedText,FALSE,TFacebook Al Research; {University College London; *New York University; plewis@fb.com,"The text block does not form a coherent or understandable sentence or phrase. It appears to be a mix of affiliations and an email address, but it is not clear or complete enough to classify accurately.",,"((419.68611111111125, 729.250325555555), (419.68611111111125, 796.8880477777773), (1280.3141022222221, 796.8880477777773), (1280.3141022222221, 729.250325555555))",application/pdf,['eng'],1,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,,6afcf8d92b2e1513a713972102cd8216,,,,,15df17659502acdb0a3d461eb47e5fb0
8,Title,Title,Title,TRUE,Abstract,The text 'Abstract' is a sectional heading commonly used in academic and research documents to introduce a summary of the content.,,"((788.2166666666667, 878.8706577777773), (788.2166666666667, 912.0795466666661), (914.9134521484375, 912.0795466666661), (914.9134521484375, 878.8706577777773))",application/pdf,['eng'],1,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.859497309,6afcf8d92b2e1513a713972102cd8216,,,,,9a1b9a1d4083b4182615d5e9266c2f20
9,NarrativeText,NarrativeText,NarrativeText,TRUE,"Large pre-trained language models have been shown to store factual knowledge in their parameters, and achieve state-of-the-art results when ﬁne-tuned on down- stream NLP tasks. However, their ability to access and precisely manipulate knowl- edge is still limited, and hence on knowledge-intensive tasks, their performance lags behind task-speciﬁc architectures. Additionally, providing provenance for their decisions and updating their world knowledge remain open research problems. Pre- trained models with a differentiable access mechanism to explicit non-parametric memory have so far been only investigated for extractive downstream tasks. We explore a general-purpose ﬁne-tuning recipe for retrieval-augmented generation (RAG) — models which combine pre-trained parametric and non-parametric mem- ory for language generation. We introduce RAG models where the parametric memory is a pre-trained seq2seq model and the non-parametric memory is a dense vector index of Wikipedia, accessed with a pre-trained neural retriever. We com- pare two RAG formulations, one which conditions on the same retrieved passages across the whole generated sequence, and another which can use different passages per token. We ﬁne-tune and evaluate our models on a wide range of knowledge- intensive NLP tasks and set the state of the art on three open domain QA tasks, outperforming parametric seq2seq models and task-speciﬁc retrieve-and-extract architectures. For language generation tasks, we ﬁnd that RAG models generate more speciﬁc, diverse and factual language than a state-of-the-art parametric-only seq2seq baseline.","This text block discusses the capabilities and limitations of large pre-trained language models, particularly in the context of knowledge-intensive tasks. It introduces Retrieval-Augmented Generation (RAG) models, which combine parametric and non-parametric memory for language generation, and compares their performance to other models on various NLP tasks.",,"((398.7138888888889, 953.0675600000001), (398.7138888888889, 1586.7997822222223), (1312.1536865234375, 1586.7997822222223), (1312.1536865234375, 953.0675600000001))",application/pdf,['eng'],1,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.943194985,9a1b9a1d4083b4182615d5e9266c2f20,,,,,a0c2906439baeb7c4d258c8af0abf5c4
10,Title,Title,Title,TRUE,1 Introduction,"This text block is a sectional heading, specifically the introduction section of a document.",,"((295.1087646484375, 1657.353991111111), (295.1087646484375, 1690.56288), (535.5828247070312, 1690.56288), (535.5828247070312, 1657.353991111111))",application/pdf,['eng'],1,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.898455501,6afcf8d92b2e1513a713972102cd8216,,,,,fcf19257d4d0f0e39665499fc870ede6
11,NarrativeText,NarrativeText,NarrativeText,TRUE,"Pre-trained neural language models have been shown to learn a substantial amount of in-depth knowl- edge from data [47]. They can do so without any access to an external memory, as a parameterized implicit knowledge base [51, 52]. While this development is exciting, such models do have down- sides: They cannot easily expand or revise their memory, can’t straightforwardly provide insight into their predictions, and may produce “hallucinations” [38]. Hybrid models that combine parametric memory with non-parametric (i.e., retrieval-based) memories [20, 26, 48] can address some of these issues because knowledge can be directly revised and expanded, and accessed knowledge can be inspected and interpreted. REALM [20] and ORQA [31], two recently introduced models that combine masked language models [8] with a differentiable retriever, have shown promising results,","The text discusses the capabilities and limitations of pre-trained neural language models, highlighting the benefits of hybrid models that combine parametric and non-parametric memories. It mentions specific models like REALM and ORQA as examples of such hybrid approaches.",,"((300.0, 1729.7647822222223), (300.0, 1999.8608933333335), (1408.0704345703125, 1999.8608933333335), (1408.0704345703125, 1729.7647822222223))",application/pdf,['eng'],1,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.948178589,fcf19257d4d0f0e39665499fc870ede6,,,,,f38e5e95a1651b2ecb889bf68e6e1f95
12,Image,,,,"D I el The middle ear includes End-to-End Backprop through q and pe the tympanic cavity and the three ossicles. (y) Define ""middle ear"" (x) Question Answering: Question Query Retriever p Document Generator pg Chnower Gereratn Index (Non-Parametric) (Parametric) d2) supports (y) Barack Obama was born in Hawaii.(x) q(x) Fact Verification: Fact Query Fact Verification: Label Generation The Divine This 14th century work Comedy (x) is divided into 3 Jeopardy Question Generation: Answer Query Sections: ""Inferno"", ""Burgatorio® & ""Paradiso"" 2 Question Generation",,,"((306.85675048828125, 189.9801788330078), (306.85675048828125, 507.15521240234375), (1382.9215087890625, 507.15521240234375), (1382.9215087890625, 189.9801788330078))",application/pdf,['eng'],2,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.922900915,,./images/Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf/figure-2-1.jpg,,,,ab0bd2254a3cce2989f826c24652ee5e
13,NarrativeText,FigureCaption,FigureCaption,TRUE,"Figure 1: Overview of our approach. We combine a pre-trained retriever (Query Encoder + Document Index) with a pre-trained seq2seq model (Generator) and ﬁne-tune end-to-end. For query x, we use Maximum Inner Product Search (MIPS) to ﬁnd the top-K documents zi. For ﬁnal prediction y, we treat z as a latent variable and marginalize over seq2seq predictions given different documents.","This text block is a caption for Figure 1, describing an overview of the approach combining a pre-trained retriever with a pre-trained seq2seq model, and the process of fine-tuning end-to-end.",,"((295.77911376953125, 534.0171716666664), (295.77911376953125, 653.2358933333335), (1404.668212890625, 653.2358933333335), (1404.668212890625, 534.0171716666664))",application/pdf,['eng'],2,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.875048935,,,,,,f9cd9c3003fd60a4c4efcd3ad992391d
14,NarrativeText,NarrativeText,NarrativeText,TRUE,"but have only explored open-domain extractive question answering. Here, we bring hybrid parametric and non-parametric memory to the “workhorse of NLP,” i.e. sequence-to-sequence (seq2seq) models.",The text discusses the exploration of open-domain extractive question answering and introduces the concept of hybrid parametric and non-parametric memory in sequence-to-sequence models.,,"((296.3477478027344, 714.1786711111109), (296.3477478027344, 772.1553377777777), (1406.2171630859375, 772.1553377777777), (1406.2171630859375, 714.1786711111109))",application/pdf,['eng'],2,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.939749181,,,,,,58b28c1630e26712d97fe7298b3184d7
15,NarrativeText,NarrativeText,NarrativeText,TRUE,"We endow pre-trained, parametric-memory generation models with a non-parametric memory through a general-purpose ﬁne-tuning approach which we refer to as retrieval-augmented generation (RAG). We build RAG models where the parametric memory is a pre-trained seq2seq transformer, and the non-parametric memory is a dense vector index of Wikipedia, accessed with a pre-trained neural retriever. We combine these components in a probabilistic model trained end-to-end (Fig. 1). The retriever (Dense Passage Retriever [26], henceforth DPR) provides latent documents conditioned on the input, and the seq2seq model (BART [32]) then conditions on these latent documents together with the input to generate the output. We marginalize the latent documents with a top-K approximation, either on a per-output basis (assuming the same document is responsible for all tokens) or a per-token basis (where different documents are responsible for different tokens). Like T5 [51] or BART, RAG can be ﬁne-tuned on any seq2seq task, whereby both the generator and retriever are jointly learned.","The text describes a method for enhancing pre-trained generation models with non-parametric memory using a fine-tuning approach called retrieval-augmented generation (RAG). It explains the components involved, such as a seq2seq transformer and a dense vector index of Wikipedia, and how they are combined in a probabilistic model trained end-to-end.",,"((298.7, 790.006448888889), (298.7, 1120.7108933333332), (1405.7005615234375, 1120.7108933333332), (1405.7005615234375, 790.006448888889))",application/pdf,['eng'],2,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.947447836,,,,,,0b98408d9ec7a03b6775a55166967b66
16,NarrativeText,NarrativeText,NarrativeText,TRUE,"There has been extensive previous work proposing architectures to enrich systems with non-parametric memory which are trained from scratch for speciﬁc tasks, e.g. memory networks [64, 55], stack- augmented networks [25] and memory layers [30]. In contrast, we explore a setting where both parametric and non-parametric memory components are pre-trained and pre-loaded with extensive knowledge. Crucially, by using pre-trained access mechanisms, the ability to access knowledge is present without additional training.","The text discusses the use of pre-trained parametric and non-parametric memory components in systems, contrasting it with previous work that trained such components from scratch for specific tasks.",,"((299.14166666666665, 1138.5592266666665), (299.14166666666665, 1317.7497822222222), (1408.96142578125, 1317.7497822222222), (1408.96142578125, 1138.5592266666665))",application/pdf,['eng'],2,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.944713175,,,,,,acbac10c6dc0657cc2a12c4bd094fcba
17,NarrativeText,NarrativeText,NarrativeText,TRUE,"Our results highlight the beneﬁts of combining parametric and non-parametric memory with genera- tion for knowledge-intensive tasks—tasks that humans could not reasonably be expected to perform without access to an external knowledge source. Our RAG models achieve state-of-the-art results on open Natural Questions [29], WebQuestions [3] and CuratedTrec [2] and strongly outperform recent approaches that use specialised pre-training objectives on TriviaQA [24]. Despite these being extractive tasks, we ﬁnd that unconstrained generation outperforms previous extractive approaches. For knowledge-intensive generation, we experiment with MS-MARCO [1] and Jeopardy question generation, and we ﬁnd that our models generate responses that are more factual, speciﬁc, and diverse than a BART baseline. For FEVER [56] fact veriﬁcation, we achieve results within 4.3% of state-of-the-art pipeline models which use strong retrieval supervision. Finally, we demonstrate that the non-parametric memory can be replaced to update the models’ knowledge as the world changes.1","This text block discusses the benefits of combining parametric and non-parametric memory for knowledge-intensive tasks, highlights the performance of RAG models on various datasets, and mentions the ability to update the models' knowledge as the world changes.",,"((299.0027777777778, 1335.5981155555553), (299.0027777777778, 1666.30256), (1409.3521728515625, 1666.30256), (1409.3521728515625, 1335.5981155555553))",application/pdf,['eng'],2,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.948646843,,,,,,1b2e64cf663ea23f235f0cb5fcb75715
18,Title,Title,Title,TRUE,2 Methods,This text block is a sectional heading indicating the methods section of a document.,,"((295.83807373046875, 1712.1428799999999), (295.83807373046875, 1745.3517688888887), (474.6036682128906, 1745.3517688888887), (474.6036682128906, 1712.1428799999999))",application/pdf,['eng'],2,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.901631117,,,,,,50dd4b92531656815e2f268ed8b9fe66
19,NarrativeText,NarrativeText,NarrativeText,TRUE,"We explore RAG models, which use the input sequence x to retrieve text documents z and use them as additional context when generating the target sequence y. As shown in Figure 1, our models leverage two components: (i) a retriever pη(z|x) with parameters η that returns (top-K truncated) distributions over text passages given a query x and (ii) a generator pθ(yi|x, z, y1:i−1) parametrized","The text discusses RAG models, explaining their components: a retriever and a generator, and how they work together to generate target sequences using retrieved text documents as context.",,"((296.85443115234375, 1779.5226233333333), (296.85443115234375, 1900.6442144444443), (1406.84716796875, 1900.6442144444443), (1406.84716796875, 1779.5226233333333))",application/pdf,['eng'],2,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.945021987,50dd4b92531656815e2f268ed8b9fe66,,,,,a0da01ef26708057d4cc0306e0e0cd50
20,NarrativeText,NarrativeText,NarrativeText,TRUE,1Code to run experiments with RAG has been open-sourced as part of the HuggingFace Transform- ers Library [66] and can be found at https://github.com/huggingface/transformers/blob/master/ examples/rag/. An interactive demo of RAG models can be found at https://huggingface.co/rag/,"The text provides information about the availability of code and an interactive demo for running experiments with RAG, part of the HuggingFace Transformers Library.",,"((297.1602783203125, 1921.0543377777778), (297.1602783203125, 2005.5292799999997), (1404.1372789333336, 2005.5292799999997), (1404.1372789333336, 1921.0543377777778))",application/pdf,['eng'],2,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.918508649,50dd4b92531656815e2f268ed8b9fe66,,,,,bf9c21f5b9c6ce9a6458713bd5905f7b
21,Footer,UncategorizedText,NarrativeText,FALSE,2,The text '2' does not provide enough context or information to be classified into any specific category.,,"((843.0670166015625, 2061.325893333333), (843.0670166015625, 2088.999782222222), (857.8004760742188, 2088.999782222222), (857.8004760742188, 2061.325893333333))",application/pdf,['eng'],2,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.783855855,,,,,,d2264acf5acd398f1b67636fbaeb14e9
22,NarrativeText,UncategorizedText,NarrativeText,TRUE,"by θ that generates a current token based on a context of the previous i − 1 tokens y1:i−1, the original input x and a retrieved passage z.","The text appears to be a fragment of a technical or academic discussion, possibly related to machine learning or natural language processing, but it lacks sufficient context to be fully understood.",,"((293.5028076171875, 205.3698455555554), (293.5028076171875, 263.95533777777774), (1409.98828125, 263.95533777777774), (1409.98828125, 205.3698455555554))",application/pdf,['eng'],3,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.934583306,,,,,,7b5a8dbec96a0efd1d06a8369d4f331f
23,NarrativeText,NarrativeText,NarrativeText,TRUE,"To train the retriever and generator end-to-end, we treat the retrieved document as a latent variable. We propose two models that marginalize over the latent documents in different ways to produce a distribution over generated text. In one approach, RAG-Sequence, the model uses the same document to predict each target token. The second approach, RAG-Token, can predict each target token based on a different document. In the following, we formally introduce both models and then describe the pη and pθ components, as well as the training and decoding procedure.","The text discusses two models, RAG-Sequence and RAG-Token, for training a retriever and generator end-to-end by treating the retrieved document as a latent variable. It explains how these models marginalize over latent documents to produce a distribution over generated text and mentions the training and decoding procedure.",,"((298.7, 281.803671111111), (298.7, 462.92477000000014), (1409.3265380859375, 462.92477000000014), (1409.3265380859375, 281.803671111111))",application/pdf,['eng'],3,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.9448511,,,,,,45d66f0c430688b64c982031a8b576be
24,Title,Title,Title,TRUE,2.1 Models,"This text block is a sectional heading, indicating the start of a new section in a document, specifically section 2.1 titled 'Models'.",,"((298.10308837890625, 499.8182872222224), (298.10308837890625, 527.4921761111111), (448.48065185546875, 527.4921761111111), (448.48065185546875, 499.8182872222224))",application/pdf,['eng'],3,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.860383332,,,,,,1364452f97c794bc0b56d74319a77002
25,NarrativeText,NarrativeText,NarrativeText,TRUE,"RAG-Sequence Model The RAG-Sequence model uses the same retrieved document to generate the complete sequence. Technically, it treats the retrieved document as a single latent variable that is marginalized to get the seq2seq probability p(y|x) via a top-K approximation. Concretely, the top K documents are retrieved using the retriever, and the generator produces the output sequence probability for each document, which are then marginalized,","The text describes the RAG-Sequence model, explaining how it uses retrieved documents to generate sequences and the process of marginalizing the sequence probability.",,"((296.9883117675781, 555.3043983333336), (296.9883117675781, 704.3858933333335), (1410.18896484375, 704.3858933333335), (1410.18896484375, 555.3043983333336))",application/pdf,['eng'],3,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.939395249,1364452f97c794bc0b56d74319a77002,,,,,f7336e3c514488e3e1176668b0aee5a5
26,Formula,UncategorizedText,NarrativeText,FALSE,"N Pracseasence(U7) = D py(2l@)po(yla.z) = D puzlz) [ [ po(wilz, 2, y1i-1) z€top-k(p(-|z)) z€top-k(p(-|z)) i",The text block does not make sense and does not fit into any of the specified categories.,,"((398.22777777777776, 720.0003255555556), (398.22777777777776, 812.1522216796875), (1301.7734864999998, 812.1522216796875), (1301.7734864999998, 720.0003255555556))",application/pdf,['eng'],3,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.812188447,,,,,,42ab8ac66a27bc76ad6cc76dab72bbf1
27,NarrativeText,NarrativeText,NarrativeText,TRUE,"RAG-Token Model In the RAG-Token model we can draw a different latent document for each target token and marginalize accordingly. This allows the generator to choose content from several documents when producing an answer. Concretely, the top K documents are retrieved using the retriever, and then the generator produces a distribution for the next output token for each document, before marginalizing, and repeating the process with the following output token, Formally, we deﬁne:","The text describes the RAG-Token model, explaining how it retrieves and marginalizes documents to generate answers.",,"((295.8310546875, 839.7905094444448), (295.8310546875, 988.8692266666666), (1407.905517578125, 988.8692266666666), (1407.905517578125, 839.7905094444448))",application/pdf,['eng'],3,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.937785327,,,,,,fb12f95b0899cc7b5c570161715fb064
28,Formula,UncategorizedText,UncategorizedText,FALSE,"N Pracnen (W7) ~ [ S paGlpeilr, 2z p1) i z€top-k(p(-|z))",The text block does not make sense and does not fit into any of the specified categories.,,"((505.2166666666666, 1004.4864366666668), (505.2166666666666, 1098.7362060546875), (1194.7845976111112, 1098.7362060546875), (1194.7845976111112, 1004.4864366666668))",application/pdf,['eng'],3,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.787407458,,,,,,12ce1178d589addb2928385031ac205b
29,NarrativeText,,NarrativeText,,"Finally, we note that RAG can be used for sequence classiﬁcation tasks by considering the target class as a target sequence of length one, in which case RAG-Sequence and RAG-Token are equivalent.",,,"((293.3083801269531, 1124.1647822222221), (293.3083801269531, 1182.1414488888888), (1407.800048828125, 1182.1414488888888), (1407.800048828125, 1124.1647822222221))",application/pdf,['eng'],3,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.913191199,,,,,,fdb47fd0a70f8dfce454e911bbfab3b7
30,Title,Title,Title,TRUE,2.2 Retriever: DPR,"The text '2.2 Retriever: DPR' appears to be a sectional heading, likely indicating a specific part or subsection of a document.",,"((297.1885986328125, 1220.9655094444445), (297.1885986328125, 1248.6393983333332), (548.4008266666667, 1248.6393983333332), (548.4008266666667, 1220.9655094444445))",application/pdf,['eng'],3,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.89526999,,,,,,4304a0d6f74e64a1800095490a884d6a
31,NarrativeText,NarrativeText,NarrativeText,TRUE,The retrieval component pη(z|x) is based on DPR [26]. DPR follows a bi-encoder architecture:,"The text describes the retrieval component pη(z|x) based on DPR, which follows a bi-encoder architecture.",,"((299.14166666666665, 1276.0365122222222), (299.14166666666665, 1306.2525477777776), (1355.186771666667, 1306.2525477777776), (1355.186771666667, 1276.0365122222222))",application/pdf,['eng'],3,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.825883448,4304a0d6f74e64a1800095490a884d6a,,,,,973dfae111ba3ad2a5910c17b2b558dc
32,Title,UncategorizedText,UncategorizedText,FALSE,py(zl2) cexp (d(z)Ta()),The text block does not make sense and does not fit into any of the specified categories.,,"((429.64722222222224, 1312.8665555555556), (429.64722222222224, 1354.260881111111), (751.4329432777777, 1354.260881111111), (751.4329432777777, 1312.8665555555556))",application/pdf,['eng'],3,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,,,,,,,0cff167889198e1537967b87359c519f
33,Formula,UncategorizedText,UncategorizedText,TRUE,"d(z) = BERTd(z), q(x) = BERTq(x)","The text appears to be a formula or notation involving BERT, but it lacks context to be fully understood.",,"((444.9538879394531, 1324.0476233333334), (444.9538879394531, 1354.260881111111), (1270.3540420555562, 1354.260881111111), (1270.3540420555562, 1324.0476233333334))",application/pdf,['eng'],3,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.487331748,,,,,,6150d0afd7f420db69c582cb10d2dae0
34,NarrativeText,NarrativeText,NarrativeText,TRUE,"where d(z) is a dense representation of a document produced by a BERTBASE document encoder [8], and q(x) a query representation produced by a query encoder, also based on BERTBASE. Calculating top-k(pη(·|x)), the list of k documents z with highest prior probability pη(z|x), is a Maximum Inner Product Search (MIPS) problem, which can be approximately solved in sub-linear time [23]. We use a pre-trained bi-encoder from DPR to initialize our retriever and to build the document index. This retriever was trained to retrieve documents which contain answers to TriviaQA [24] questions and Natural Questions [29]. We refer to the document index as the non-parametric memory.","This text block discusses the use of BERT-based encoders for document and query representation, the Maximum Inner Product Search (MIPS) problem, and the initialization of a retriever using a pre-trained bi-encoder from DPR for document retrieval in the context of TriviaQA and Natural Questions.",,"((299.0027777777778, 1369.6727272222222), (299.0027777777778, 1579.80256), (1407.091064453125, 1579.80256), (1407.091064453125, 1369.6727272222222))",application/pdf,['eng'],3,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.947717369,,,,,,0255aaab2b672f13e4aa22f5faf56fed
35,Title,Title,Title,TRUE,2.3 Generator: BART,"The text '2.3 Generator: BART' appears to be a sectional heading, likely indicating a specific part or subsection of a document.",,"((298.1676330566406, 1618.6266205555555), (298.1676330566406, 1646.3005094444443), (578.5135498046875, 1646.3005094444443), (578.5135498046875, 1618.6266205555555))",application/pdf,['eng'],3,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.849403501,,,,,,4ee1f4f148a1b04123886a1e72752ec1
36,NarrativeText,NarrativeText,NarrativeText,TRUE,"The generator component pθ(yi|x, z, y1:i−1) could be modelled using any encoder-decoder. We use BART-large [32], a pre-trained seq2seq transformer [58] with 400M parameters. To combine the input x with the retrieved content z when generating from BART, we simply concatenate them. BART was pre-trained using a denoising objective and a variety of different noising functions. It has obtained state-of-the-art results on a diverse set of generation tasks and outperforms comparably-sized T5 models [32]. We refer to the BART generator parameters θ as the parametric memory henceforth.","This text block discusses the use of the BART-large model, a pre-trained seq2seq transformer, for generating text. It explains how the input and retrieved content are combined and highlights the model's pre-training and performance.",,"((299.14166666666665, 1673.6976233333332), (299.14166666666665, 1853.4942266666667), (1407.786865234375, 1853.4942266666667), (1407.786865234375, 1673.6976233333332))",application/pdf,['eng'],3,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.946033299,4ee1f4f148a1b04123886a1e72752ec1,,,,,48ba381148e4f560f12fb05c7f51d962
37,Title,Title,Title,TRUE,2.4 Training,"This text block is a sectional heading, indicating a specific part of a document related to training.",,"((297.0955505371094, 1892.3210649999999), (297.0955505371094, 1919.994953888889), (466.24639892578125, 1919.994953888889), (466.24639892578125, 1892.3210649999999))",application/pdf,['eng'],3,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.85428232,,,,,,fbf283a1b37562d1887626973f73615f
38,NarrativeText,NarrativeText,NarrativeText,TRUE,"We jointly train the retriever and generator components without any direct supervision on what document should be retrieved. Given a ﬁne-tuning training corpus of input/output pairs (xj, yj), we","The text discusses the joint training of retriever and generator components without direct supervision on document retrieval, within the context of a fine-tuning training corpus of input/output pairs.",,"((294.2911071777344, 1948.0008933333331), (294.2911071777344, 2007.9081033333332), (1410.3592529296875, 2007.9081033333332), (1410.3592529296875, 1948.0008933333331))",application/pdf,['eng'],3,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.931190491,fbf283a1b37562d1887626973f73615f,,,,,e7f943db8cad0600fb35bae147138288
39,Footer,,UncategorizedText,,3,,,"((842.001953125, 2061.325893333333), (842.001953125, 2088.999782222222), (857.6129150390625, 2088.999782222222), (857.6129150390625, 2061.325893333333))",application/pdf,['eng'],3,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.734965563,,,,,,d9773f424914a45999087e0f0e2e4ca4
40,NarrativeText,NarrativeText,NarrativeText,TRUE,"minimize the negative marginal log-likelihood of each target, Z] —log p(y;|a;) using stochastic gradient descent with Adam [28]. Updating the document encoder BERT,; during training is costly as it requires the document index to be periodically updated as REALM does during pre-training [20]. We do not find this step necessary for strong performance, and keep the document encoder (and index) fixed, only fine-tuning the query encoder BERT, and the BART generator.","The text discusses the process of minimizing the negative marginal log-likelihood using stochastic gradient descent with Adam, and the decision to keep the document encoder fixed while fine-tuning the query encoder and generator.",,"((298.7, 195.84988888888876), (298.7, 360.09143666666654), (1406.2216796875, 360.09143666666654), (1406.2216796875, 195.84988888888876))",application/pdf,['eng'],4,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.942621827,,,,,,9ee9181a16b78d29add024c89543b752
41,Title,Title,Title,TRUE,2.5 Decoding,"This text block is a sectional heading, likely indicating a subsection within a larger document, specifically related to the topic of decoding.",,"((297.3731994628906, 398.1821761111111), (297.3731994628906, 425.8560649999999), (473.09332275390625, 425.8560649999999), (473.09332275390625, 398.1821761111111))",application/pdf,['eng'],4,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.864804685,,,,,,1d080bc28a22963b9b5c291a85126152
42,NarrativeText,UncategorizedText,NarrativeText,TRUE,"At test time, RAG-Sequence and RAG-Token require different ways to approximate arg maxy p(y|x).","The text discusses the requirements for approximating arg maxy p(y|x) at test time for RAG-Sequence and RAG-Token, but it is too brief to be considered a narrative text block.",,"((299.0027777777778, 453.2531788888889), (299.0027777777778, 486.08032555555536), (1404.8439916666666, 486.08032555555536), (1404.8439916666666, 453.2531788888889))",application/pdf,['eng'],4,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,,1d080bc28a22963b9b5c291a85126152,,,,,669f5b76bafd1b99fa227c6892d8da23
43,NarrativeText,UncategorizedText,NarrativeText,FALSE,"RAG-Token The RAG-Token model can be seen as a standard, autoregressive seq2seq genera- tor with transition probability: pj(yi|z,y1.i-1) = Zzemp,k(p(_‘x)) n(zil2)po(ysl|z, zi, y1:i—1) To decode, we can plug pg(yi |, y1.4—1) into a standard beam decoder.",The text block contains technical jargon and mathematical notation that is not self-explanatory or coherent without additional context.,,"((298.34228515625, 517.8210650000002), (298.34228515625, 618.3275477777777), (1407.8101806640625, 618.3275477777777), (1407.8101806640625, 517.8210650000002))",application/pdf,['eng'],4,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.929188967,1d080bc28a22963b9b5c291a85126152,,,,,667b79c645d658878aec98605e699338
44,NarrativeText,NarrativeText,NarrativeText,TRUE,"RAG-Sequence For RAG-Sequence, the likelihood p(y|x) does not break into a conventional per- token likelihood, hence we cannot solve it with a single beam search. Instead, we run beam search for each document z, scoring each hypothesis using pθ(yi|x, z, y1:i−1). This yields a set of hypotheses Y , some of which may not have appeared in the beams of all documents. To estimate the probability of an hypothesis y we run an additional forward pass for each document z for which y does not appear in the beam, multiply generator probability with pη(z|x) and then sum the probabilities across beams for the marginals. We refer to this decoding procedure as “Thorough Decoding.” For longer output sequences, |Y | can become large, requiring many forward passes. For more efﬁcient decoding, we can make a further approximation that pθ(y|x, zi) ≈ 0 where y was not generated during beam search from x, zi. This avoids the need to run additional forward passes once the candidate set Y has been generated. We refer to this decoding procedure as “Fast Decoding.”","The text block discusses the RAG-Sequence decoding procedures, including Thorough Decoding and Fast Decoding, for generating hypotheses and estimating probabilities in a machine learning context.",,"((299.0027777777778, 648.5781788888889), (299.0027777777778, 979.8914488888887), (1407.185302734375, 979.8914488888887), (1407.185302734375, 648.5781788888889))",application/pdf,['eng'],4,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.951742947,1d080bc28a22963b9b5c291a85126152,,,,,6fe0ef45d21c39bf53a23e3bdf932b3c
45,Title,Title,Title,TRUE,3 Experiments,The text '3 Experiments' serves as a heading or title for a section likely detailing three different experiments.,,"((295.4057922363281, 1026.4651022222222), (295.4057922363281, 1059.673991111111), (535.625244140625, 1059.673991111111), (535.625244140625, 1026.4651022222222))",application/pdf,['eng'],4,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.902167141,,,,,,b44cd191660dc39609ef4c1720389a9a
46,NarrativeText,NarrativeText,NarrativeText,TRUE,"We experiment with RAG in a wide range of knowledge-intensive tasks. For all experiments, we use a single Wikipedia dump for our non-parametric knowledge source. Following Lee et al. [31] and Karpukhin et al. [26], we use the December 2018 dump. Each Wikipedia article is split into disjoint 100-word chunks, to make a total of 21M documents. We use the document encoder to compute an embedding for each document, and build a single MIPS index using FAISS [23] with a Hierarchical Navigable Small World approximation for fast retrieval [37]. During training, we retrieve the top k documents for each query. We consider k ∈ {5, 10} for training and set k for test time using dev data. We now discuss experimental details for each task.","The text describes an experimental setup for using RAG in knowledge-intensive tasks, detailing the use of a Wikipedia dump, document encoding, and retrieval process.",,"((297.925, 1094.8309326171875), (297.925, 1334.9858933333333), (1408.6573486328125, 1334.9858933333333), (1408.6573486328125, 1094.8309326171875))",application/pdf,['eng'],4,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.953218102,b44cd191660dc39609ef4c1720389a9a,,,,,d6854008cb35b41f0bc899c89faf5371
47,Title,Title,Title,TRUE,3.1 Open-domain Question Answering,This text block is a sectional heading indicating a specific part of a document related to open-domain question answering.,,"((297.234375, 1375.007176111111), (297.234375, 1402.681065), (774.6889038085938, 1402.681065), (774.6889038085938, 1375.007176111111))",application/pdf,['eng'],4,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.883240759,,,,,,0126a0c969b7610c23fddd72b230ee58
48,NarrativeText,NarrativeText,NarrativeText,TRUE,"Open-domain question answering (QA) is an important real-world application and common testbed for knowledge-intensive tasks [20]. We treat questions and answers as input-output text pairs (x, y) and train RAG by directly minimizing the negative log-likelihood of answers. We compare RAG to the popular extractive QA paradigm [5, 7, 31, 26], where answers are extracted spans from retrieved documents, relying primarily on non-parametric knowledge. We also compare to “Closed-Book QA” approaches [52], which, like RAG, generate answers, but which do not exploit retrieval, instead relying purely on parametric knowledge. We consider four popular open-domain QA datasets: Natural Questions (NQ) [29], TriviaQA (TQA) [24]. WebQuestions (WQ) [3] and CuratedTrec (CT) [2]. As CT and WQ are small, we follow DPR [26] by initializing CT and WQ models with our NQ RAG model. We use the same train/dev/test splits as prior work [31, 26] and report Exact Match (EM) scores. For TQA, to compare with T5 [52], we also evaluate on the TQA Wiki test set.","The text discusses the methodology and comparison of different approaches in open-domain question answering (QA), including RAG, extractive QA, and Closed-Book QA. It also mentions the datasets used for evaluation and the metrics reported.",,"((300.0, 1430.6058349609375), (300.0, 1761.3914488888888), (1407.7315673828125, 1761.3914488888888), (1407.7315673828125, 1430.6058349609375))",application/pdf,['eng'],4,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.951989353,0126a0c969b7610c23fddd72b230ee58,,,,,3bb54c4e859851db06a7827fc9cccebd
49,Title,,Title,,3.2 Abstractive Question Answering,,,"((299.9292297363281, 1801.4127316666666), (299.9292297363281, 1829.0866205555553), (748.2533569335938, 1829.0866205555553), (748.2533569335938, 1801.4127316666666))",application/pdf,['eng'],4,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.875863314,,,,,,6b09ccf0af4ab5f68013a395cbe4b5e5
50,NarrativeText,NarrativeText,NarrativeText,TRUE,"RAG models can go beyond simple extractive QA and answer questions with free-form, abstractive text generation. To test RAG’s natural language generation (NLG) in a knowledge-intensive setting, we use the MSMARCO NLG task v2.1 [43]. The task consists of questions, ten gold passages retrieved from a search engine for each question, and a full sentence answer annotated from the retrieved passages. We do not use the supplied passages, only the questions and answers, to treat","The text discusses the capabilities of RAG models in generating free-form, abstractive answers in a knowledge-intensive setting, specifically using the MSMARCO NLG task v2.1.",,"((299.0027777777778, 1856.7432861328125), (299.0027777777778, 2005.97756), (1405.9337158203125, 2005.97756), (1405.9337158203125, 1856.7432861328125))",application/pdf,['eng'],4,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.943702102,6b09ccf0af4ab5f68013a395cbe4b5e5,,,,,d4b176ec5a8de85dec1415da4dfdf774
51,UncategorizedText,Title,UncategorizedText,TRUE,4,The text '4' could represent a section or chapter number in a document.,,"((843.0805555555555, 2061.325893333333), (843.0805555555555, 2088.999782222222), (856.9174999999999, 2088.999782222222), (856.9174999999999, 2061.325893333333))",application/pdf,['eng'],4,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,,6b09ccf0af4ab5f68013a395cbe4b5e5,,,,,29d9e55eda2626067c8cdcdfa50be8d2
52,NarrativeText,NarrativeText,NarrativeText,TRUE,"MSMARCO as an open-domain abstractive QA task. MSMARCO has some questions that cannot be answered in a way that matches the reference answer without access to the gold passages, such as “What is the weather in Volcano, CA?” so performance will be lower without using gold passages. We also note that some MSMARCO questions cannot be answered using Wikipedia alone. Here, RAG can rely on parametric knowledge to generate reasonable responses.","The text discusses the challenges of using MSMARCO for open-domain abstractive QA tasks, noting that some questions require gold passages or cannot be answered using Wikipedia alone. It also mentions the use of RAG for generating reasonable responses based on parametric knowledge.",,"((295.1864013671875, 205.97867111111094), (295.1864013671875, 354.86367111111133), (1414.4527587890625, 354.86367111111133), (1414.4527587890625, 205.97867111111094))",application/pdf,['eng'],5,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.940415144,6b09ccf0af4ab5f68013a395cbe4b5e5,,,,,5e31e919f2ffe2a20644912486ccee09
53,Title,Title,NarrativeText,TRUE,Jeopardy Question Generation,"The text 'Jeopardy Question Generation' serves as a main or sectional heading, indicating the topic or focus of a document or section.",,"((300.0, 393.2960650000003), (300.0, 420.96995388888905), (728.5462036132812, 420.96995388888905), (728.5462036132812, 393.2960650000003))",application/pdf,['eng'],5,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.86276257,,,,,,61ae474d1454f38608f7ed3f9c95f1f9
54,NarrativeText,NarrativeText,NarrativeText,TRUE,"To evaluate RAG’s generation abilities in a non-QA setting, we study open-domain question gen- eration. Rather than use questions from standard open-domain QA tasks, which typically consist of short, simple questions, we propose the more demanding task of generating Jeopardy questions. Jeopardy is an unusual format that consists of trying to guess an entity from a fact about that entity. For example, “The World Cup” is the answer to the question “In 1986 Mexico scored as the ﬁrst country to host this international sports competition twice.” As Jeopardy questions are precise, factual statements, generating Jeopardy questions conditioned on their answer entities constitutes a challenging knowledge-intensive generation task.","The text discusses the evaluation of RAG’s generation abilities in a non-QA setting by proposing the task of generating Jeopardy questions, which are precise, factual statements conditioned on their answer entities.",,"((299.14166666666665, 448.97589333333326), (299.14166666666665, 688.7720044444446), (1413.1656494140625, 688.7720044444446), (1413.1656494140625, 448.97589333333326))",application/pdf,['eng'],5,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.953645289,61ae474d1454f38608f7ed3f9c95f1f9,,,,,14bdfb18dee3ef41bfc4434b11be764e
55,NarrativeText,NarrativeText,NarrativeText,TRUE,"We use the splits from SearchQA [10], with 100K train, 14K dev, and 27K test examples. As this is a new task, we train a BART model for comparison. Following [67], we evaluate using the SQuAD-tuned Q-BLEU-1 metric [42]. Q-BLEU is a variant of BLEU with a higher weight for matching entities and has higher correlation with human judgment for question generation than standard metrics. We also perform two human evaluations, one to assess generation factuality, and one for speciﬁcity. We deﬁne factuality as whether a statement can be corroborated by trusted external sources, and speciﬁcity as high mutual dependence between the input and output [33]. We follow best practice and use pairwise comparative evaluation [34]. Evaluators are shown an answer and two generated questions, one from BART and one from RAG. They are then asked to pick one of four options—quuestion A is better, question B is better, both are good, or neither is good.","The text describes the methodology and evaluation metrics used in a research study involving a BART model and RAG for question generation. It includes details about the dataset, evaluation metrics, and human evaluation criteria.",,"((298.7, 706.6203377777775), (298.7, 1007.0220044444443), (1410.490478515625, 1007.0220044444443), (1410.490478515625, 706.6203377777775))",application/pdf,['eng'],5,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.951050937,61ae474d1454f38608f7ed3f9c95f1f9,,,,,7f759e20e5de5b9b00c2fb6e9b95a324
56,Title,Title,Title,TRUE,3.4 Fact Veriﬁcation,"This text block is a sectional heading, indicating a specific part of a document related to fact verification.",,"((299.1194152832031, 1044.563232421875), (299.1194152832031, 1073.128287222222), (561.927001953125, 1073.128287222222), (561.927001953125, 1044.563232421875))",application/pdf,['eng'],5,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.851257384,,,,,,6a54bde792c4bff8de896687b12ddd9b
57,NarrativeText,NarrativeText,NarrativeText,TRUE,"FEVER [56] requires classifying whether a natural language claim is supported or refuted by Wikipedia, or whether there is not enough information to decide. The task requires retrieving evidence from Wikipedia relating to the claim and then reasoning over this evidence to classify whether the claim is true, false, or unveriﬁable from Wikipedia alone. FEVER is a retrieval problem coupled with an challenging entailment reasoning task. It also provides an appropriate testbed for exploring the RAG models’ ability to handle classiﬁcation rather than generation. We map FEVER class labels (supports, refutes, or not enough info) to single output tokens and directly train with claim-class pairs. Crucially, unlike most other approaches to FEVER, we do not use supervision on retrieved evidence. In many real-world applications, retrieval supervision signals aren’t available, and models that do not require such supervision will be applicable to a wider range of tasks. We explore two variants: the standard 3-way classiﬁcation task (supports/refutes/not enough info) and the 2-way (supports/refutes) task studied in Thorne and Vlachos [57]. In both cases we report label accuracy.","The text discusses the FEVER task, which involves classifying natural language claims based on evidence from Wikipedia. It explains the process of retrieving evidence, reasoning over it, and classifying claims as supported, refuted, or unverifiable. The text also mentions the use of RAG models for this task and the importance of not relying on retrieval supervision.",,"((298.7, 1100.6939697265625), (298.7, 1462.1414488888888), (1410.81494140625, 1462.1414488888888), (1410.81494140625, 1100.6939697265625))",application/pdf,['eng'],5,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.952387333,6a54bde792c4bff8de896687b12ddd9b,,,,,360f97864d2d286babc4fe24f8c1f7f4
58,Title,Title,Title,TRUE,4 Results,The text '4 Results' is a heading that likely introduces a section of a document where results are discussed.,,"((297.14093017578125, 1504.8990478515625), (297.14093017578125, 1540.3351022222218), (455.539794921875, 1540.3351022222218), (455.539794921875, 1504.8990478515625))",application/pdf,['eng'],5,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.833058119,,,,,,c53619e770b686d2c739eaa19ae1c93d
59,Title,Title,Title,TRUE,4.1 Open-domain Question Answering,This text block is a section heading indicating a specific part of a document related to open-domain question answering.,,"((298.3166198730469, 1574.0682872222221), (298.3166198730469, 1601.742176111111), (775.4529418945312, 1601.742176111111), (775.4529418945312, 1574.0682872222221))",application/pdf,['eng'],5,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.866592586,,,,,,46a88f2d086d8626f6c694b54605ef5a
60,NarrativeText,NarrativeText,NarrativeText,TRUE,"Table 1 shows results for RAG along with state-of-the-art models. On all four open-domain QA tasks, RAG sets a new state of the art (only on the T5-comparable split for TQA). RAG combines the generation ﬂexibility of the “closed-book” (parametric only) approaches and the performance of ""open-book"" retrieval-based approaches. Unlike REALM and T5+SSM, RAG enjoys strong results without expensive, specialized “salient span masking” pre-training [20]. It is worth noting that RAG’s retriever is initialized using DPR’s retriever, which uses retrieval supervision on Natural Questions and TriviaQA. RAG compares favourably to the DPR QA system, which uses a BERT-based “cross- encoder” to re-rank documents, along with an extractive reader. RAG demonstrates that neither a re-ranker nor extractive reader is necessary for state-of-the-art performance.","The text discusses the performance of the RAG model in comparison to other state-of-the-art models on open-domain QA tasks. It highlights RAG's advantages, such as not requiring expensive pre-training and not needing a re-ranker or extractive reader for state-of-the-art performance.",,"((299.0027777777778, 1629.335205078125), (299.0027777777778, 1899.8470044444446), (1410.6458740234375, 1899.8470044444446), (1410.6458740234375, 1629.335205078125))",application/pdf,['eng'],5,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.95199883,46a88f2d086d8626f6c694b54605ef5a,,,,,0520451468ffaba8e273d4dca739c79c
61,NarrativeText,NarrativeText,NarrativeText,TRUE,"There are several advantages to generating answers even when it is possible to extract them. Docu- ments with clues about the answer but do not contain the answer verbatim can still contribute towards a correct answer being generated, which is not possible with standard extractive approaches, leading","The text discusses the advantages of generating answers over extracting them, particularly in cases where documents contain clues but not the exact answer verbatim.",,"((296.2929992675781, 1917.6981155555554), (296.2929992675781, 2005.97756), (1411.20947265625, 2005.97756), (1411.20947265625, 1917.6981155555554))",application/pdf,['eng'],5,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.938223004,46a88f2d086d8626f6c694b54605ef5a,,,,,6fef0d8e0a13c261a6e6a9d78a493a48
62,Footer,UncategorizedText,UncategorizedText,FALSE,5,The text '5' does not provide enough context or information to be classified into any specific category.,,"((842.5166625976562, 2061.325893333333), (842.5166625976562, 2088.999782222222), (857.4764404296875, 2088.999782222222), (857.4764404296875, 2061.325893333333))",application/pdf,['eng'],5,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.743658781,,,,,,e9ebc5eac859348bb2fd10ee17b9b149
63,FigureCaption,FigureCaption,FigureCaption,TRUE,"Table 1: Open-Domain QA Test Scores. For TQA, left column uses the standard test set for Open- Domain QA, right column uses the TQA-Wiki test set. See Appendix D for further details. Table 2: Generation and classiﬁcation Test Scores. MS-MARCO SotA is [4], FEVER-3 is [68] and FEVER-2 is [57] *Uses gold context/evidence. Best model without gold access underlined.","The text block provides descriptions and details for two tables: Table 1, which shows Open-Domain QA Test Scores, and Table 2, which shows Generation and Classification Test Scores. It also references specific test sets and models used in the evaluations.",,"((296.57073974609375, 218.8870044444444), (296.57073974609375, 338.0053377777778), (1404.8495682777782, 338.0053377777778), (1404.8495682777782, 218.8870044444444))",application/pdf,['eng'],6,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.74523896,,,,,,c4914ad233c82284ca32c89b4fc5b195
64,Title,Title,UncategorizedText,TRUE,Model,"The text 'Model' serves as a heading or title, likely indicating a section or part of a document related to a model or modeling.",,"((392.75852341666666, 364.4403745710223), (392.75852341666666, 387.70494470435546), (453.5023160348, 387.70494470435546), (453.5023160348, 364.4403745710223))",application/pdf,['eng'],6,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,,,,,,,965e762a3c1af12888fa2e935a6c4bb0
65,Title,UncategorizedText,UncategorizedText,FALSE,NQ,The text 'NQ' does not provide enough context or information to be classified into any specific category.,,"((554.3309629926666, 364.4403745710223), (554.3309629926666, 387.70494470435546), (587.9250022652, 387.70494470435546), (587.9250022652, 364.4403745710223))",application/pdf,['eng'],6,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,,,,,,,ed29d81c7a3d9420df44e72467022495
66,Title,UncategorizedText,UncategorizedText,FALSE,TQA WQ CT,The text 'TQA WQ CT' does not make sense by itself and does not fit into any of the specified categories.,,"((632.2207437990667, 364.4403745710223), (632.2207437990667, 387.70494470435546), (817.3601929201335, 387.70494470435546), (817.3601929201335, 364.4403745710223))",application/pdf,['eng'],6,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,,,,,,,37e262b8bdf1d9706cc4e259763278b6
67,Table,,,,Closed Book T5-11B [52] 34.5 T5-11B+SSM[52] 36.6 - - /50.1 37.4 /60.5 44.7 - - Model B-1 Label Acc. Open Book REALM [20] DPR [26] 40.4 / 41.5 57.9/ - - - 40.7 46.8 41.1 50.6 SotA BART - - 15.1 19.7 49.8* 49.9* 38.2 41.6 76.8 64.0 81.1 RAG-Token RAG-Seq. 44.1 55.2/66.1 45.5 50.0 44.5 56.8/68.0 45.2 52.2 RAG-Tok. 17.3 22.2 RAG-Seq. 14.7 21.4 40.1 40.8 41.5 44.2 72.5 89.5,,,"((308.11322021484375, 368.03558349609375), (308.11322021484375, 590.8518676757812), (1381.2183837890625, 590.8518676757812), (1381.2183837890625, 368.03558349609375))",application/pdf,['eng'],6,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.811567426,37e262b8bdf1d9706cc4e259763278b6,./images/Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf/table-6-1.jpg,,,,fc93745836bfdc84a55fd9430bee2fac
68,Title,UncategorizedText,UncategorizedText,FALSE,Jeopardy MSMARCO FVR3 FVR2 B-1 QB-1 R-L,The text block does not provide a clear or coherent meaning and does not fit into any of the specified categories.,,"((992.9372099444445, 386.2354078290224), (992.9372099444445, 436.33099579568926), (1386.154556709111, 436.33099579568926), (1386.154556709111, 386.2354078290224))",application/pdf,['eng'],6,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,,,,,,,f44d1cf8fef8b2ff5b80dae5c516be55
69,UncategorizedText,UncategorizedText,UncategorizedText,FALSE,92.2*,The text '92.2*' does not provide enough context or information to be classified into any specific category.,,"((1330.4555505220442, 452.577934722089), (1330.4555505220442, 476.47437179568925), (1383.8407441777777, 476.47437179568925), (1383.8407441777777, 452.577934722089))",application/pdf,['eng'],6,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,,f44d1cf8fef8b2ff5b80dae5c516be55,,,,,cfaaf16b077044b13132b0bc585bc22c
70,NarrativeText,NarrativeText,NarrativeText,TRUE,"to more effective marginalization over documents. Furthermore, RAG can generate correct answers even when the correct answer is not in any retrieved document, achieving 11.8% accuracy in such cases for NQ, where an extractive model would score 0%.","The text discusses the effectiveness of RAG in generating correct answers even when the correct answer is not in any retrieved document, highlighting its performance in comparison to an extractive model for NQ.",,"((295.8925476074219, 654.8008933333332), (295.8925476074219, 743.0831155555555), (1404.2330322265625, 743.0831155555555), (1404.2330322265625, 654.8008933333332))",application/pdf,['eng'],6,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.83710885,f44d1cf8fef8b2ff5b80dae5c516be55,,,,,6e33d105bf50cfc2d7df3c3817dc125e
71,Title,Title,Title,TRUE,4.2 Abstractive Question Answering,"This text block is a sectional heading indicating a specific part of a document, likely related to a subsection on Abstractive Question Answering.",,"((297.6317138671875, 782.6905094444443), (297.6317138671875, 810.3643983333332), (750.0015258789062, 810.3643983333332), (750.0015258789062, 782.6905094444443))",application/pdf,['eng'],6,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.868717313,,,,,,58c76b08a3a9cc6baef5d0322b1b2d51
72,NarrativeText,NarrativeText,NarrativeText,TRUE,"As shown in Table 2, RAG-Sequence outperforms BART on Open MS-MARCO NLG by 2.6 Bleu points and 2.6 Rouge-L points. RAG approaches state-of-the-art model performance, which is impressive given that (i) those models access gold passages with speciﬁc information required to generate the reference answer , (ii) many questions are unanswerable without the gold passages, and (iii) not all questions are answerable from Wikipedia alone. Table 3 shows some generated answers from our models. Qualitatively, we ﬁnd that RAG models hallucinate less and generate factually correct text more often than BART. Later, we also show that RAG generations are more diverse than BART generations (see §4.5).","This text block discusses the performance of the RAG-Sequence model compared to the BART model on the Open MS-MARCO NLG dataset. It highlights the superior performance of RAG-Sequence in terms of Bleu and Rouge-L points, and mentions qualitative findings regarding the factual correctness and diversity of generated answers.",,"((299.0027777777778, 838.3703377777778), (299.0027777777778, 1078.1664488888887), (1407.37255859375, 1078.1664488888887), (1407.37255859375, 838.3703377777778))",application/pdf,['eng'],6,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.951719284,58c76b08a3a9cc6baef5d0322b1b2d51,,,,,7309e3f1e5ca99396e2b782b743471ed
73,Title,Title,NarrativeText,TRUE,Jeopardy Question Generation,"The text 'Jeopardy Question Generation' serves as a main or sectional heading, indicating the topic or focus of the content that follows.",,"((299.3175354003906, 1117.6370849609375), (299.3175354003906, 1145.4477316666666), (729.5635986328125, 1145.4477316666666), (729.5635986328125, 1117.6370849609375))",application/pdf,['eng'],6,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.869344056,,,,,,e40ab7d69d01e1098a2d6904a1236214
74,NarrativeText,,NarrativeText,,"Table 2 shows that RAG-Token performs better than RAG-Sequence on Jeopardy question generation, with both models outperforming BART on Q-BLEU-1. 4 shows human evaluation results, over 452 pairs of generations from BART and RAG-Token. Evaluators indicated that BART was more factual than RAG in only 7.1% of cases, while RAG was more factual in 42.7% of cases, and both RAG and BART were factual in a further 17% of cases, clearly demonstrating the effectiveness of RAG on the task over a state-of-the-art generation model. Evaluators also ﬁnd RAG generations to be more speciﬁc by a large margin. Table 3 shows typical generations from each model.",,,"((299.0027777777778, 1173.4536711111111), (299.0027777777778, 1382.9470044444442), (1410.11083984375, 1382.9470044444442), (1410.11083984375, 1173.4536711111111))",application/pdf,['eng'],6,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.947323263,e40ab7d69d01e1098a2d6904a1236214,,,,,a72e6d4104f0839dd921f47b8baafa53
75,NarrativeText,NarrativeText,NarrativeText,TRUE,"Jeopardy questions often contain two separate pieces of information, and RAG-Token may perform best because it can generate responses that combine content from several documents. Figure 2 shows an example. When generating “Sun”, the posterior is high for document 2 which mentions “The Sun Also Rises”. Similarly, document 1 dominates the posterior when “A Farewell to Arms” is generated. Intriguingly, after the ﬁrst token of each book is generated, the document posterior ﬂattens. This observation suggests that the generator can complete the titles without depending on speciﬁc documents. In other words, the model’s parametric knowledge is sufﬁcient to complete the titles. We ﬁnd evidence for this hypothesis by feeding the BART-only baseline with the partial decoding ""The Sun. BART completes the generation ""The Sun Also Rises"" is a novel by this author of ""The Sun Also Rises"" indicating the title ""The Sun Also Rises"" is stored in BART’s parameters. Similarly, BART will complete the partial decoding ""The Sun Also Rises"" is a novel by this author of ""A with ""The Sun Also Rises"" is a novel by this author of ""A Farewell to Arms"". This example shows how parametric and non-parametric memories work together—the non-parametric component helps to guide the generation, drawing out speciﬁc knowledge stored in the parametric memory.",The text discusses the performance of the RAG-Token model in generating responses by combining content from several documents. It provides an example involving the titles 'The Sun Also Rises' and 'A Farewell to Arms' to illustrate how the model's parametric and non-parametric memories work together.,,"((299.0027777777778, 1400.7953377777776), (299.0027777777778, 1822.4081155555555), (1407.6715087890625, 1822.4081155555555), (1407.6715087890625, 1400.7953377777776))",application/pdf,['eng'],6,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.94713676,e40ab7d69d01e1098a2d6904a1236214,,,,,5bb55248d6e17830bf32ecc5966b28f6
76,Title,Title,Title,TRUE,4.4 Fact Veriﬁcation,"This text block is a sectional heading indicating a specific part of a document, likely related to the verification of facts.",,"((299.0622863769531, 1862.0182872222222), (299.0622863769531, 1889.692176111111), (561.35205078125, 1889.692176111111), (561.35205078125, 1862.0182872222222))",application/pdf,['eng'],6,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.858159184,,,,,,0ce35442b011e926034f4a17087165d7
77,NarrativeText,FigureCaption,NarrativeText,TRUE,"Table 2 shows our results on FEVER. For 3-way classiﬁcation, RAG scores are within 4.3% of state-of-the-art models, which are complex pipeline systems with domain-speciﬁc architectures and substantial engineering, trained using intermediate retrieval supervision, which RAG does not require.","This text block describes the results shown in Table 2, comparing RAG scores to state-of-the-art models in a 3-way classification task on FEVER.",,"((296.4414978027344, 1917.6981155555554), (296.4414978027344, 2005.97756), (1410.7568359375, 2005.97756), (1410.7568359375, 1917.6981155555554))",application/pdf,['eng'],6,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.939475,0ce35442b011e926034f4a17087165d7,,,,,dbdcb5302c7d929ea86a1dbaee0476c4
78,UncategorizedText,Title,UncategorizedText,TRUE,6,The text '6' could represent a section or chapter number in a document.,,"((843.0805555555555, 2061.325893333333), (843.0805555555555, 2088.999782222222), (856.9174999999999, 2088.999782222222), (856.9174999999999, 2061.325893333333))",application/pdf,['eng'],6,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,,0ce35442b011e926034f4a17087165d7,,,,,b57a2da14e9f50248f6ac41517d7cfd2
79,Image,,,,"Document 1: his works are considered classics of American Doc1 [ ] | literature ... His wartime experiences formed the basis for hisnovel .o . A Farewell to Arms” (1929) ... Doc3 Document 2: ... artists of the 1920s “Lost Generation” expatriate Pocd community. His debut novel, “The Sun Also Rises”, was published ¢ in1926. Doc5 Q,O(”‘ * &g%\,e QV,,OQ- & t e »\\C@@ & f\sc\ * vd&f\\ovﬁ&“",,,"((306.7382507324219, 205.90560913085938), (306.7382507324219, 376.34130859375), (1392.760009765625, 376.34130859375), (1392.760009765625, 205.90560913085938))",application/pdf,['eng'],7,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.755687654,,./images/Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf/figure-7-2.jpg,,,,944a8b5e15e363827924bb2a2357d4dd
80,Image,,,,[ ] | .,,,"((860.7219087166667, 207.0827171388888), (860.7219087166667, 328.25355047222206), (1389.02674205, 328.25355047222206), (1389.02674205, 207.0827171388888))",application/pdf,['eng'],7,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,,,./images/Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf/figure-7-3.jpg,,,,a05f36f7225b00cff5dc813d802bb729
81,NarrativeText,FigureCaption,FigureCaption,TRUE,"Figure 2: RAG-Token document posterior p(zi|x, yi, y−i) for each generated token for input “Hem- ingway"" for Jeopardy generation with 5 retrieved documents. The posterior for document 1 is high when generating “A Farewell to Arms"" and for document 2 when generating “The Sun Also Rises"".","This text is a caption for Figure 2, describing the RAG-Token document posterior for each generated token for the input 'Hemingway' in a Jeopardy generation context with 5 retrieved documents.",,"((298.70782470703125, 388.43095666666665), (298.70782470703125, 477.3220044444444), (1405.38525390625, 477.3220044444444), (1405.38525390625, 388.43095666666665))",application/pdf,['eng'],7,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.833110213,,,,,,27b24fa17f19b96c0b1d7988c7cbda7a
82,NarrativeText,FigureCaption,FigureCaption,TRUE,"Table 3: Examples from generation tasks. RAG models generate more speciﬁc and factually accurate responses. ‘?’ indicates factually incorrect responses, * indicates partially correct responses.","This text block is a caption for Table 3, describing examples from generation tasks and the performance of RAG models in generating specific and factually accurate responses.",,"((297.888671875, 534.3592266666665), (297.888671875, 592.3386711111112), (1403.4249267578125, 592.3386711111112), (1403.4249267578125, 534.3592266666665))",application/pdf,['eng'],7,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.934244931,,,,,,677e0e49b8f042eef5660e49e46088e1
83,Table,,,,"Task Input Model Generation MS- MARCO deﬁne middle ear what currency needed in scotland BART ?The middle ear is the part of the ear between the middle ear and the nose. RAG-T The middle ear is the portion of the ear internal to the eardrum. RAG-S The middle ear includes the tympanic cavity and the three ossicles. BART The currency needed in Scotland is Pound sterling. RAG-T Pound is the currency needed in Scotland. RAG-S The currency needed in Scotland is the pound sterling. Jeopardy Question Gener -ation Washington The Divine Comedy BART ?This state has the largest number of counties in the U.S. RAG-T It’s the only U.S. state named for a U.S. president RAG-S It’s the state where you’ll ﬁnd Mount Rainier National Park BART *This epic poem by Dante is divided into 3 parts: the Inferno, the Purgatorio & the Purgatorio RAG-T Dante’s ""Inferno"" is the ﬁrst part of this epic poem RAG-S This 14th century work is divided into 3 sections: ""Inferno"", ""Purgatorio"" & ""Paradiso""",,,"((299.7635498046875, 617.55419921875), (299.7635498046875, 970.5542602539062), (1379.8585205078125, 970.5542602539062), (1379.8585205078125, 617.55419921875))",application/pdf,['eng'],7,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.638618171,,./images/Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf/table-7-2.jpg,,,,cbf087e60000fbff990d958f34e3f1cf
84,NarrativeText,NarrativeText,NarrativeText,TRUE,"For 2-way classiﬁcation, we compare against Thorne and Vlachos [57], who train RoBERTa [35] to classify the claim as true or false given the gold evidence sentence. RAG achieves an accuracy within 2.7% of this model, despite being supplied with only the claim and retrieving its own evidence. We also analyze whether documents retrieved by RAG correspond to documents annotated as gold evidence in FEVER. We calculate the overlap in article titles between the top k documents retrieved by RAG and gold evidence annotations. We ﬁnd that the top retrieved document is from a gold article in 71% of cases, and a gold article is present in the top 10 retrieved articles in 90% of cases.","The text discusses the performance comparison of RAG and RoBERTa models in a 2-way classification task, including accuracy metrics and analysis of document retrieval in the FEVER dataset.",,"((298.7, 1037.5842266666666), (298.7, 1247.0747822222222), (1410.6202392578125, 1247.0747822222222), (1410.6202392578125, 1037.5842266666666))",application/pdf,['eng'],7,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.95014894,,,,,,8e9037cfc7c3605a6ff69e60d4a1f398
85,Title,Title,Title,TRUE,4.5 Additional Results,This text block is a sectional heading indicating additional results in a document.,,"((297.3058776855469, 1289.207176111111), (297.3058776855469, 1316.881065), (583.10302734375, 1316.881065), (583.10302734375, 1289.207176111111))",application/pdf,['eng'],7,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.886207759,,,,,,d593ed09f1e2481a0bd2298672ec7755
86,NarrativeText,NarrativeText,NarrativeText,TRUE,"Generation Diversity Section 4.3 shows that RAG models are more factual and speciﬁc than BART for Jeopardy question generation. Following recent work on diversity-promoting decoding [33, 59, 39], we also investigate generation diversity by calculating the ratio of distinct ngrams to total ngrams generated by different models. Table 5 shows that RAG-Sequence’s generations are more diverse than RAG-Token’s, and both are signiﬁcantly more diverse than BART without needing any diversity-promoting decoding.","The text discusses the diversity and factual accuracy of different models (RAG and BART) for generating Jeopardy questions, comparing their performance in terms of n-gram diversity.",,"((300.0, 1345.5155094444444), (300.0, 1524.8997822222223), (1409.1641845703125, 1524.8997822222223), (1409.1641845703125, 1345.5155094444444))",application/pdf,['eng'],7,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.944633186,d593ed09f1e2481a0bd2298672ec7755,,,,,0a2523bcb3f30398d8ca5afd602dacec
87,NarrativeText,,NarrativeText,,"Retrieval Ablations A key feature of RAG is learning to retrieve relevant information for the task. To assess the effectiveness of the retrieval mechanism, we run ablations where we freeze the retriever during training. As shown in Table 6, learned retrieval improves results for all tasks.",,,"((298.34661865234375, 1563.293287222222), (298.34661865234375, 1651.766448888889), (1411.313232421875, 1651.766448888889), (1411.313232421875, 1563.293287222222))",application/pdf,['eng'],7,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.943106055,d593ed09f1e2481a0bd2298672ec7755,,,,,2b4b2c80ba8477a43e338a135b9f00fb
88,NarrativeText,NarrativeText,NarrativeText,TRUE,"We compare RAG’s dense retriever to a word overlap-based BM25 retriever [53]. Here, we replace RAG’s retriever with a ﬁxed BM25 system, and use BM25 retrieval scores as logits when calculating p(z|x). Table 6 shows the results. For FEVER, BM25 performs best, perhaps since FEVER claims are heavily entity-centric and thus well-suited for word overlap-based retrieval. Differentiable retrieval improves results on all other tasks, especially for Open-Domain QA, where it is crucial.","The text discusses a comparison between RAG’s dense retriever and a BM25 retriever, highlighting the performance differences across various tasks, particularly noting the effectiveness of BM25 for FEVER and the advantages of differentiable retrieval for Open-Domain QA.",,"((298.7, 1669.61756), (298.7, 1818.5025599999997), (1408.5947265625, 1818.5025599999997), (1408.5947265625, 1669.61756))",application/pdf,['eng'],7,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.951090634,d593ed09f1e2481a0bd2298672ec7755,,,,,858979d8a4b9dc39fe3dde88450c77cf
89,NarrativeText,NarrativeText,NarrativeText,TRUE,"Index hot-swapping An advantage of non-parametric memory models like RAG is that knowledge can be easily updated at test time. Parametric-only models like T5 or BART need further training to update their behavior as the world changes. To demonstrate, we build an index using the DrQA [5] Wikipedia dump from December 2016 and compare outputs from RAG using this index to the newer index from our main results (December 2018). We prepare a list of 82 world leaders who had changed","The text discusses the advantages of non-parametric memory models like RAG over parametric-only models like T5 or BART, particularly in the context of updating knowledge at test time. It also mentions an experiment comparing outputs from RAG using different indices from Wikipedia dumps of different years.",,"((298.7, 1856.8988427777779), (298.7, 2005.97756), (1403.882568359375, 2005.97756), (1403.882568359375, 1856.8988427777779))",application/pdf,['eng'],7,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.944082618,d593ed09f1e2481a0bd2298672ec7755,,,,,3a70a1dd5397de59bbbab4a96c2d6b69
90,Footer,UncategorizedText,UncategorizedText,FALSE,7,The text '7' does not provide enough context or information to be classified into any specific category.,,"((842.4220581054688, 2061.325893333333), (842.4220581054688, 2088.999782222222), (857.6384887695312, 2088.999782222222), (857.6384887695312, 2061.325893333333))",application/pdf,['eng'],7,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.748104811,,,,,,fd7067354188004d3409af2776a56ccf
91,NarrativeText,FigureCaption,FigureCaption,TRUE,Table 4: Human assessments for the Jeopardy Question Generation Task.,This text block is a caption for a table that presents human assessments for the Jeopardy Question Generation Task.,,"((299.14166666666665, 218.8870044444444), (299.14166666666665, 276.8636711111112), (844.8018188476562, 276.8636711111112), (844.8018188476562, 218.8870044444444))",application/pdf,['eng'],8,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.825096428,,,,,,a49acf4ac971ad8068e885bacc3b3cfc
92,Title,FigureCaption,FigureCaption,TRUE,Table 5: Ratio of distinct to total tri-grams for generation tasks.,"This text is a caption for a table, specifically describing the ratio of distinct to total tri-grams for generation tasks.",,"((860.1361111111111, 218.8870044444444), (860.1361111111111, 276.8636711111112), (1400.4643638444445, 276.8636711111112), (1400.4643638444445, 218.8870044444444))",application/pdf,['eng'],8,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,,,,,,,7202ce69f7ea087b41e2cf96783a4507
93,Table,,NarrativeText,,Factuality Speciﬁcity MSMARCO Jeopardy QGen BART better RAG better Both good Both poor No majority 7.1% 42.7% 11.7% 17.7% 20.8% 16.8% 37.4% 11.8% 6.9% 20.1% Gold BART RAG-Token RAG-Seq. 89.6% 70.7% 77.8% 83.5% 90.0% 32.4% 46.8% 53.8%,,,"((351.8543701171875, 300.869384765625), (351.8543701171875, 482.17822265625), (1389.088623046875, 482.17822265625), (1389.088623046875, 300.869384765625))",application/pdf,['eng'],8,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.849101663,7202ce69f7ea087b41e2cf96783a4507,./images/Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf/table-8-3.jpg,,,,fa90dba547107ceeebfedeaf6f53df24
94,FigureCaption,FigureCaption,FigureCaption,TRUE,"Table 6: Ablations on the dev set. As FEVER is a classiﬁcation task, both RAG models are equivalent.","This text block is a caption for a table, specifically Table 6, discussing ablations on the dev set in the context of a classification task related to FEVER and RAG models.",,"((299.14166666666665, 549.9342266666666), (299.14166666666665, 577.6081155555557), (1400.72607421875, 577.6081155555557), (1400.72607421875, 549.9342266666666))",application/pdf,['eng'],8,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.750838697,7202ce69f7ea087b41e2cf96783a4507,,,,,49f51a4ba2fa63b24152d482d35d2c3e
95,Table,,,,Model NQ TQA WQ Exact Match CT Jeopardy-QGen MSMarco B-1 B-1 QB-1 R-L RAG-Token-BM25 RAG-Sequence-BM25 29.7 31.8 41.5 44.1 32.1 36.6 33.1 33.8 17.5 11.1 22.3 19.5 55.5 56.5 48.4 46.9 75.1 91.6 RAG-Token-Frozen RAG-Sequence-Frozen 37.8 41.2 50.1 52.1 37.1 41.8 51.1 52.6 16.7 11.8 21.7 19.6 55.9 56.7 49.4 47.3 72.9 89.4 RAG-Token RAG-Sequence 43.5 44.0 54.8 55.8 46.5 44.9 51.9 53.4 17.9 15.3 22.6 21.5 56.2 57.2 49.4 47.5 74.5 90.6,,,"((311.1646728515625, 595.7740478515625), (311.1646728515625, 875.1912841796875), (1406.42822265625, 875.1912841796875), (1406.42822265625, 595.7740478515625))",application/pdf,['eng'],8,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.925201535,7202ce69f7ea087b41e2cf96783a4507,./images/Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf/table-8-4.jpg,,,,005f32363edfe5d5a1e01bb1235715a7
96,Title,Title,UncategorizedText,TRUE,FVR-3 FVR-2 Label Accuracy,"The text appears to be a title or heading, possibly for a section that discusses the accuracy of different FVR (Feature Vector Representation) models.",,"((1244.0665777777776, 604.7120622222224), (1244.0665777777776, 657.290951111111), (1415.6486044444446, 657.290951111111), (1415.6486044444446, 604.7120622222224))",application/pdf,['eng'],8,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,,,,,,,a50cba15bb9e9fae609ace2f860ccdcf
97,NarrativeText,NarrativeText,NarrativeText,TRUE,"between these dates and use a template “Who is {position}?” (e.g. “Who is the President of Peru?”) to query our NQ RAG model with each index. RAG answers 70% correctly using the 2016 index for 2016 world leaders and 68% using the 2018 index for 2018 world leaders. Accuracy with mismatched indices is low (12% with the 2018 index and 2016 leaders, 4% with the 2016 index and 2018 leaders). This shows we can update RAG’s world knowledge by simply replacing its non-parametric memory.","The text discusses the accuracy of the NQ RAG model in identifying world leaders from different years using specific indices, and highlights the impact of updating the model's non-parametric memory on its performance.",,"((299.14166666666665, 944.1731155555557), (299.14166666666665, 1093.0581155555553), (1404.8313078444437, 1093.0581155555553), (1404.8313078444437, 944.1731155555557))",application/pdf,['eng'],8,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.948151827,a50cba15bb9e9fae609ace2f860ccdcf,,,,,8522991b2ec9d30492b54bb48d051f55
98,NarrativeText,NarrativeText,NarrativeText,TRUE,"Effect of Retrieving more documents Models are trained with either 5 or 10 retrieved latent documents, and we do not observe signiﬁcant differences in performance between them. We have the ﬂexibility to adjust the number of retrieved documents at test time, which can affect performance and runtime. Figure 3 (left) shows that retrieving more documents at test time monotonically improves Open-domain QA results for RAG-Sequence, but performance peaks for RAG-Token at 10 retrieved documents. Figure 3 (right) shows that retrieving more documents leads to higher Rouge-L for RAG-Token at the expense of Bleu-1, but the effect is less pronounced for RAG-Sequence.","The text discusses the impact of retrieving different numbers of latent documents on the performance of RAG-Sequence and RAG-Token models in Open-domain QA tasks, including performance metrics like Rouge-L and Bleu-1.",,"((300.0, 1136.1627316666666), (300.0, 1345.8470044444443), (1404.5081787109375, 1345.8470044444443), (1404.5081787109375, 1136.1627316666666))",application/pdf,['eng'],8,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.950724125,a50cba15bb9e9fae609ace2f860ccdcf,,,,,8466a5ae3d177a631a7932df7558755e
99,Image,,,,e o 80 mmmmmmmmmmmmmmmmmmmmm-oomoooe 55 = / £ i =70 g/ ] — RAGTokRL Z |l g - RAGTokB1 o 50 = . oeq B Z a0qh — racm | 5 Ch ! --- RAGSeq | Z 40 B ] I R K Retrieved Docs K Retrieved Docs K Retrieved Docs,,,"((302.67474365234375, 1383.7386474609375), (302.67474365234375, 1621.38037109375), (1406.9013671875, 1621.38037109375), (1406.9013671875, 1383.7386474609375))",application/pdf,['eng'],8,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.890675247,,./images/Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf/figure-8-4.jpg,,,,4c64b048f43f75e25b129781850ec48a
100,FigureCaption,FigureCaption,FigureCaption,TRUE,Figure 3: Left: NQ performance as more documents are retrieved. Center: Retrieval recall perfor- mance in NQ. Right: MS-MARCO Bleu-1 and Rouge-L as more documents are retrieved.,This text block is a caption for a figure that describes the performance metrics of NQ and MS-MARCO as more documents are retrieved.,,"((290.564453125, 1615.4814488888887), (290.564453125, 1673.4581155555557), (1413.773193359375, 1673.4581155555557), (1413.773193359375, 1615.4814488888887))",application/pdf,['eng'],8,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.773726165,,,,,,e2419bce5b975c583d9c172cea72bdc8
101,Title,Title,Title,TRUE,5 Related Work,"This text block is a sectional heading, indicating the start of a section related to previous work or literature review.",,"((294.8809814453125, 1753.953991111111), (294.8809814453125, 1787.1628799999999), (547.47264, 1787.1628799999999), (547.47264, 1753.953991111111))",application/pdf,['eng'],8,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.906581938,,,,,,b593e50451af4d77bde95e15c1362e6a
102,NarrativeText,NarrativeText,NarrativeText,TRUE,"Single-Task Retrieval Prior work has shown that retrieval improves performance across a variety of NLP tasks when considered in isolation. Such tasks include open-domain question answering [5, 29], fact checking [56], fact completion [48], long-form question answering [12], Wikipedia article generation [36], dialogue [41, 65, 9, 13], translation [17], and language modeling [19, 27]. Our work uniﬁes previous successes in incorporating retrieval into individual tasks, showing that a single retrieval-based architecture is capable of achieving strong performance across several tasks.",The text discusses the benefits of retrieval in various NLP tasks and highlights the unification of these benefits into a single retrieval-based architecture capable of strong performance across multiple tasks.,,"((299.0027777777778, 1826.5960649999997), (299.0027777777778, 2005.97756), (1408.35107421875, 2005.97756), (1408.35107421875, 1826.5960649999997))",application/pdf,['eng'],8,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.943341613,b593e50451af4d77bde95e15c1362e6a,,,,,79229041787fe5b33041f012437509ef
103,Footer,UncategorizedText,UncategorizedText,FALSE,8,The text '8' does not provide enough context or information to be classified into any specific category.,,"((842.8639526367188, 2061.325893333333), (842.8639526367188, 2088.999782222222), (857.8801879882812, 2088.999782222222), (857.8801879882812, 2061.325893333333))",application/pdf,['eng'],8,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.724442959,,,,,,7c9e222e4488da52ff86dd2bf14ee0aa
104,NarrativeText,NarrativeText,NarrativeText,TRUE,"General-Purpose Architectures for NLP Prior work on general-purpose architectures for NLP tasks has shown great success without the use of retrieval. A single, pre-trained language model has been shown to achieve strong performance on various classiﬁcation tasks in the GLUE bench- marks [60, 61] after ﬁne-tuning [49, 8]. GPT-2 [50] later showed that a single, left-to-right, pre-trained language model could achieve strong performance across both discriminative and generative tasks. For further improvement, BART [32] and T5 [51, 52] propose a single, pre-trained encoder-decoder model that leverages bi-directional attention to achieve stronger performance on discriminative and generative tasks. Our work aims to expand the space of possible tasks with a single, uniﬁed architecture, by learning a retrieval module to augment pre-trained, generative language models.","The text discusses the success of general-purpose architectures for NLP tasks, mentioning specific models like GPT-2, BART, and T5, and their performance on various tasks. It also introduces the idea of expanding task capabilities with a unified architecture that includes a retrieval module.",,"((300.0, 205.78495388888882), (300.0, 476.0747822222223), (1409.71826171875, 476.0747822222223), (1409.71826171875, 205.78495388888882))",application/pdf,['eng'],9,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.95221287,,,,,,7bfba462430aa5fefb8902bd59217fe0
105,NarrativeText,NarrativeText,NarrativeText,TRUE,"Learned Retrieval There is signiﬁcant work on learning to retrieve documents in information retrieval, more recently with pre-trained, neural language models [44, 26] similar to ours. Some work optimizes the retrieval module to aid in a speciﬁc, downstream task such as question answering, using search [46], reinforcement learning [6, 63, 62], or a latent variable approach [31, 20] as in our work. These successes leverage different retrieval-based architectures and optimization techniques to achieve strong performance on a single task, while we show that a single retrieval-based architecture can be ﬁne-tuned for strong performance on a variety of tasks.","The text discusses various approaches to learning retrieval in information retrieval, particularly with pre-trained neural language models. It compares different optimization techniques and highlights the versatility of a single retrieval-based architecture for multiple tasks.",,"((299.0027777777778, 512.4127316666668), (299.0027777777778, 722.0970044444446), (1406.478759765625, 722.0970044444446), (1406.478759765625, 512.4127316666668))",application/pdf,['eng'],9,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.950012207,,,,,,35cff91a130a2f390908b0125dd63205
106,NarrativeText,NarrativeText,NarrativeText,TRUE,"Memory-based Architectures Our document index can be seen as a large external memory for neural networks to attend to, analogous to memory networks [64, 55]. Concurrent work [14] learns to retrieve a trained embedding for each entity in the input, rather than to retrieve raw text as in our work. Other work improves the ability of dialog models to generate factual text by attending over fact embeddings [15, 13]. A key feature of our memory is that it is comprised of raw text rather distributed representations, which makes the memory both (i) human-readable, lending a form of interpretability to our model, and (ii) human-writable, enabling us to dynamically update the model’s memory by editing the document index. This approach has also been used in knowledge-intensive dialog, where generators have been conditioned on retrieved text directly, albeit obtained via TF-IDF rather than end-to-end learnt retrieval [9].","The text discusses memory-based architectures in neural networks, comparing different approaches to retrieving and utilizing text and embeddings for improving dialog models. It highlights the advantages of using raw text for memory, such as interpretability and dynamic updates.",,"((299.0027777777778, 758.432176111111), (299.0027777777778, 1059.02756), (1411.41845703125, 1059.02756), (1411.41845703125, 758.432176111111))",application/pdf,['eng'],9,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.951969266,,,,,,8e02079ef88cf0d4b19b98c83a2511c8
107,NarrativeText,NarrativeText,NarrativeText,TRUE,"Retrieve-and-Edit approaches Our method shares some similarities with retrieve-and-edit style approaches, where a similar training input-output pair is retrieved for a given input, and then edited to provide a ﬁnal output. These approaches have proved successful in a number of domains including Machine Translation [18, 22] and Semantic Parsing [21]. Our approach does have several differences, including less of emphasis on lightly editing a retrieved item, but on aggregating content from several pieces of retrieved content, as well as learning latent retrieval, and retrieving evidence documents rather than related training pairs. This said, RAG techniques may work well in these settings, and could represent promising future work.","The text discusses the similarities and differences between retrieve-and-edit approaches and the method being described. It mentions the success of these approaches in various domains and highlights the unique aspects of the method, such as aggregating content from multiple sources and learning latent retrieval.",,"((300.0, 1095.3655094444443), (300.0, 1335.3525599999998), (1409.8197021484375, 1335.3525599999998), (1409.8197021484375, 1095.3655094444443))",application/pdf,['eng'],9,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.951734841,,,,,,9dd5106d2251efcc339c09ff897a69a4
108,Title,Title,Title,TRUE,6 Discussion,"This text block is a sectional heading, indicating the start of a discussion section in a document.",,"((296.7771301269531, 1381.978991111111), (296.7771301269531, 1415.18788), (504.4747009277344, 1415.18788), (504.4747009277344, 1381.978991111111))",application/pdf,['eng'],9,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.890085876,,,,,,7143db81765b278e3b8719b6380cf860
109,NarrativeText,NarrativeText,NarrativeText,TRUE,"In this work, we presented hybrid generation models with access to parametric and non-parametric memory. We showed that our RAG models obtain state of the art results on open-domain QA. We found that people prefer RAG’s generation over purely parametric BART, ﬁnding RAG more factual and speciﬁc. We conducted an thorough investigation of the learned retrieval component, validating its effectiveness, and we illustrated how the retrieval index can be hot-swapped to update the model without requiring any retraining. In future work, it may be fruitful to investigate if the two components can be jointly pre-trained from scratch, either with a denoising objective similar to BART or some another objective. Our work opens up new research directions on how parametric and non-parametric memories interact and how to most effectively combine them, showing promise in being applied to a wide variety of NLP tasks.","This text block discusses the presentation and evaluation of hybrid generation models with parametric and non-parametric memory, specifically focusing on RAG models and their performance in open-domain QA. It also explores the effectiveness of the retrieval component and suggests future research directions.",,"((299.0027777777778, 1450.7536711111109), (299.0027777777778, 1751.155337777778), (1407.99365234375, 1751.155337777778), (1407.99365234375, 1450.7536711111109))",application/pdf,['eng'],9,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.95172298,7143db81765b278e3b8719b6380cf860,,,,,695e700de4af533badc3c445fbd508a8
110,UncategorizedText,UncategorizedText,UncategorizedText,TRUE,9,"The text block contains a single digit '9', which does not provide enough context to classify it into any specific category.",,"((843.0805555555555, 2061.325893333333), (843.0805555555555, 2088.999782222222), (856.9174999999999, 2088.999782222222), (856.9174999999999, 2061.325893333333))",application/pdf,['eng'],9,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,,7143db81765b278e3b8719b6380cf860,,,,,58397819a201093f807f4658bde1d678
111,Title,Title,Title,TRUE,Broader Impact,"The text 'Broader Impact' serves as a sectional heading, likely introducing a section that discusses the wider implications or effects of the subject matter.",,"((299.4444274902344, 201.40676888888876), (299.4444274902344, 234.61565777777764), (530.3853759765625, 234.61565777777764), (530.3853759765625, 201.40676888888876))",application/pdf,['eng'],10,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.908457637,,,,,,38950c55b426fe24a0238a827ea5f7de
112,NarrativeText,NarrativeText,NarrativeText,TRUE,"This work offers several positive societal beneﬁts over previous work: the fact that it is more strongly grounded in real factual knowledge (in this case Wikipedia) makes it “hallucinate” less with generations that are more factual, and offers more control and interpretability. RAG could be employed in a wide variety of scenarios with direct beneﬁt to society, for example by endowing it with a medical index and asking it open-domain questions on that topic, or by helping people be more effective at their jobs.","This text discusses the societal benefits of a work that is grounded in factual knowledge, specifically mentioning its potential applications in various scenarios such as medical indexing and job efficiency.",,"((299.0027777777778, 270.4064488888889), (299.0027777777778, 449.59700444444445), (1409.6839599609375, 449.59700444444445), (1409.6839599609375, 270.4064488888889))",application/pdf,['eng'],10,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.945370793,38950c55b426fe24a0238a827ea5f7de,,,,,ddcb777ad390262805d87a7baffa3fe9
113,NarrativeText,NarrativeText,NarrativeText,TRUE,"With these advantages also come potential downsides: Wikipedia, or any potential external knowledge source, will probably never be entirely factual and completely devoid of bias. Since RAG can be employed as a language model, similar concerns as for GPT-2 [50] are valid here, although arguably to a lesser extent, including that it might be used to generate abuse, faked or misleading content in the news or on social media; to impersonate others; or to automate the production of spam/phishing content [54]. Advanced language models may also lead to the automation of various jobs in the coming decades [16]. In order to mitigate these risks, AI systems could be employed to ﬁght against misleading content and automated spam/phishing.","The text discusses the potential downsides of using external knowledge sources like Wikipedia and advanced language models like RAG. It highlights concerns about factual accuracy, bias, and the potential for misuse in generating misleading content, impersonation, and spam. It also mentions the possibility of job automation and suggests using AI systems to mitigate these risks.",,"((298.7, 467.4453377777777), (298.7, 707.2414488888891), (1406.630859375, 707.2414488888891), (1406.630859375, 467.4453377777777))",application/pdf,['eng'],10,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.950609148,38950c55b426fe24a0238a827ea5f7de,,,,,2ed3efe05f45c1693d42b1f52ba2a22e
114,Title,Title,Title,TRUE,Acknowledgments,The text 'Acknowledgments' is a sectional heading typically found in documents to denote a section where the author expresses gratitude to those who contributed to the work.,,"((300.0, 754.24288), (300.0, 787.451768888889), (563.100341796875, 787.451768888889), (563.100341796875, 754.24288))",application/pdf,['eng'],10,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.911894858,,,,,,996418f52e07b55d5db0c3442b1ce386
115,NarrativeText,NarrativeText,NarrativeText,TRUE,"The authors would like to thank the reviewers for their thoughtful and constructive feedback on this paper, as well as HuggingFace for their help in open-sourcing code to run RAG models. The authors would also like to thank Kyunghyun Cho and Sewon Min for productive discussions and advice. EP thanks supports from the NSF Graduate Research Fellowship. PL is supported by the FAIR PhD program.","Acknowledgements section where the authors thank reviewers, collaborators, and funding sources.",,"((297.1380310058594, 823.2425599999999), (297.1380310058594, 972.12756), (1411.6591796875, 972.12756), (1411.6591796875, 823.2425599999999))",application/pdf,['eng'],10,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.942962646,996418f52e07b55d5db0c3442b1ce386,,,,,fb4bfffbd33fdbf8ccd70dd49d82a103
116,Title,Title,Title,TRUE,References,The text 'References' is a sectional heading typically used to denote the start of a bibliography or citation section in a document.,,"((300.0, 1019.1289911111111), (300.0, 1052.33788), (457.0539245605469, 1052.33788), (457.0539245605469, 1019.1289911111111))",application/pdf,['eng'],10,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.8841151,,,,,,951982b33987f89d920603f4bca9502a
117,ListItem,Bibliography,Bibliography,TRUE,"[1] Payal Bajaj, Daniel Campos, Nick Craswell, Li Deng, Jianfeng Gao, Xiaodong Liu, Rangan Majumder, Andrew McNamara, Bhaskar Mitra, Tri Nguyen, Mir Rosenberg, Xia Song, Alina Stoica, Saurabh Tiwary, and Tong Wang. MS MARCO: A Human Generated MAchine Reading COmprehension Dataset. arXiv:1611.09268 [cs], November 2016. URL http: //arxiv.org/abs/1611.09268. arXiv: 1611.09268.",This text block is a bibliographic citation for a paper titled 'MS MARCO: A Human Generated MAchine Reading COmprehension Dataset' authored by multiple individuals and published on arXiv in November 2016.,,"((301.74755859375, 1072.9092266666664), (301.74755859375, 1221.9630477777778), (1416.9937744140625, 1221.9630477777778), (1416.9937744140625, 1072.9092266666664))",application/pdf,['eng'],10,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.936985493,951982b33987f89d920603f4bca9502a,,,,,0b9defbbdf6ec38cb23225bc0a81f68e
118,ListItem,Bibliography,Bibliography,TRUE,"[2] Petr Baudiš and Jan Šediv`y. Modeling of the question answering task in the yodaqa system. In International Conference of the Cross-Language Evaluation Forum for European Languages, pages 222–228. Springer, 2015. URL https://link.springer.com/chapter/10.1007% 2F978-3-319-24027-5_20.","This text block is a bibliographic citation for a conference paper by Petr Baudiš and Jan Šedivý, including the title, conference details, page numbers, publisher, year, and URL.",,"((308.7306213378906, 1250.4758933333335), (308.7306213378906, 1369.4602699999998), (1415.131591796875, 1369.4602699999998), (1415.131591796875, 1250.4758933333335))",application/pdf,['eng'],10,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.941792548,951982b33987f89d920603f4bca9502a,,,,,ea80ce1c60febf832f71fac05d1e52a9
119,ListItem,Bibliography,Bibliography,TRUE,"[3] Jonathan Berant, Andrew Chou, Roy Frostig, and Percy Liang. Semantic Parsing on Freebase from Question-Answer Pairs. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1533–1544, Seattle, Washington, USA, October 2013. Association for Computational Linguistics. URL http://www.aclweb.org/anthology/ D13-1160.",This text block is a bibliographic citation for a paper presented at the 2013 Conference on Empirical Methods in Natural Language Processing.,,"((303.06732177734375, 1394.728671111111), (303.06732177734375, 1543.7824922222221), (1414.0047607421875, 1543.7824922222221), (1414.0047607421875, 1394.728671111111))",application/pdf,['eng'],10,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.93730545,951982b33987f89d920603f4bca9502a,,,,,dc755574d4dfc6612adb1b8e45fc66db
120,ListItem,Bibliography,Bibliography,TRUE,"[4] Bin Bi, Chenliang Li, Chen Wu, Ming Yan, and Wei Wang. Palm: Pre-training an autoencod- ing&autoregressive language model for context-conditioned generation. ArXiv, abs/2004.07159, 2020. URL https://arxiv.org/abs/2004.07159.","This text block is a bibliographic citation for a paper titled 'Palm: Pre-training an autoencoding&autoregressive language model for context-conditioned generation' by authors Bin Bi, Chenliang Li, Chen Wu, Ming Yan, and Wei Wang, published on ArXiv in 2020.",,"((305.01519775390625, 1569.0536711111108), (305.01519775390625, 1657.4991588888886), (1416.242431640625, 1657.4991588888886), (1416.242431640625, 1569.0536711111108))",application/pdf,['eng'],10,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.941745818,951982b33987f89d920603f4bca9502a,,,,,755812a8913697c090d6e002bbd37a58
121,ListItem,Bibliography,Bibliography,TRUE,"[5] Danqi Chen, Adam Fisch, Jason Weston, and Antoine Bordes. Reading Wikipedia to Answer Open-Domain Questions. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1870–1879, Vancouver, Canada, July 2017. Association for Computational Linguistics. doi: 10.18653/v1/P17-1171. URL https://www.aclweb.org/anthology/P17-1171.",This text block is a bibliographic citation for a paper presented at the 55th Annual Meeting of the Association for Computational Linguistics.,,"((305.27001953125, 1682.7703377777777), (305.27001953125, 1831.8213811111111), (1416.7315673828125, 1831.8213811111111), (1416.7315673828125, 1682.7703377777777))",application/pdf,['eng'],10,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.933512568,951982b33987f89d920603f4bca9502a,,,,,c0295956538df42de59886295656c1f9
122,ListItem,Bibliography,Bibliography,TRUE,"[6] Eunsol Choi, Daniel Hewlett, Jakob Uszkoreit, Illia Polosukhin, Alexandre Lacoste, and Jonathan Berant. Coarse-to-ﬁne question answering for long documents. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 209–220, Vancouver, Canada, July 2017. Association for Computational Linguistics. doi: 10.18653/v1/P17-1020. URL https://www.aclweb.org/anthology/P17-1020.","This text block is a bibliographic citation for a paper presented at the 55th Annual Meeting of the Association for Computational Linguistics. It includes the authors, title, publication venue, page numbers, location, date, publisher, DOI, and URL.",,"((306.9996032714844, 1857.09256), (306.9996032714844, 2006.1436033333332), (1416.7484130859375, 2006.1436033333332), (1416.7484130859375, 1857.09256))",application/pdf,['eng'],10,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.933971524,951982b33987f89d920603f4bca9502a,,,,,88f7eb4260a9a61e65a8d2b369f1f816
123,Footer,UncategorizedText,UncategorizedText,FALSE,10,The text '10' does not provide enough context or information to be classified into any specific category.,,"((836.1638888888889, 2061.325893333333), (836.1638888888889, 2088.999782222222), (865.3172607421875, 2088.999782222222), (865.3172607421875, 2061.325893333333))",application/pdf,['eng'],10,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.786098778,,,,,,f3fee13aa01f01e091e1959b4bf12f07
124,ListItem,Bibliography,Bibliography,TRUE,"[7] Christopher Clark and Matt Gardner. Simple and Effective Multi-Paragraph Reading Compre- hension. arXiv:1710.10723 [cs], October 2017. URL http://arxiv.org/abs/1710.10723. arXiv: 1710.10723.","This text block is a bibliographic citation for a paper by Christopher Clark and Matt Gardner titled 'Simple and Effective Multi-Paragraph Reading Comprehension,' published on arXiv in October 2017.",,"((307.6064453125, 205.97867111111094), (307.6064453125, 294.2581155555555), (1414.817626953125, 294.2581155555555), (1414.817626953125, 205.97867111111094))",application/pdf,['eng'],11,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.937167048,,,,,,425770fcc9dc87bef1523bd6112d8243
125,ListItem,Bibliography,Bibliography,TRUE,"[8] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In Proceedings of the 2019 Con- ference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 4171–4186, Minneapolis, Minnesota, June 2019. Association for Computational Linguistics. doi: 10.18653/v1/N19-1423. URL https://www.aclweb.org/anthology/N19-1423.","This text block is a bibliographic citation for a paper titled 'BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding' by Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova, published in the Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics.",,"((311.015869140625, 320.8425599999998), (311.015869140625, 500.1991588888889), (1408.14013671875, 500.1991588888889), (1408.14013671875, 320.8425599999998))",application/pdf,['eng'],11,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.95191747,,,,,,c43d18bf273915bc9ff6a0335049650a
126,ListItem,Bibliography,Bibliography,TRUE,"[9] Emily Dinan, Stephen Roller, Kurt Shuster, Angela Fan, Michael Auli, and Jason Weston. Wiz- ard of wikipedia: Knowledge-powered conversational agents. In International Conference on Learning Representations, 2019. URL https://openreview.net/forum?id=r1l73iRqKm.","This text block is a bibliographic citation for a paper presented at the International Conference on Learning Representations in 2019, authored by Emily Dinan, Stephen Roller, Kurt Shuster, Angela Fan, Michael Auli, and Jason Weston.",,"((308.9830017089844, 526.61756), (308.9830017089844, 615.0630477777778), (1414.0797119140625, 615.0630477777778), (1414.0797119140625, 526.61756))",application/pdf,['eng'],11,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.937503934,,,,,,d56539fe76bd08654502f5c48aa71883
127,ListItem,Bibliography,Bibliography,TRUE,"[10] Matthew Dunn, Levent Sagun, Mike Higgins, V. Ugur Guney, Volkan Cirik, and Kyunghyun Cho. SearchQA: A New Q&A Dataset Augmented with Context from a Search Engine. arXiv:1704.05179 [cs], April 2017. URL http://arxiv.org/abs/1704.05179. arXiv: 1704.05179.","This text block is a bibliographic citation for a paper titled 'SearchQA: A New Q&A Dataset Augmented with Context from a Search Engine' authored by Matthew Dunn, Levent Sagun, Mike Higgins, V. Ugur Guney, Volkan Cirik, and Kyunghyun Cho, published on arXiv in April 2017.",,"((297.7619323730469, 641.4842266666666), (297.7619323730469, 760.0664488888889), (1414.9630126953125, 760.0664488888889), (1414.9630126953125, 641.4842266666666))",application/pdf,['eng'],11,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.94153583,,,,,,a91af638a7e7086c3f8de580296416d8
128,ListItem,Bibliography,Bibliography,TRUE,"[11] Angela Fan, Mike Lewis, and Yann Dauphin. Hierarchical neural story generation. In Proceed- ings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 889–898, Melbourne, Australia, July 2018. Association for Computational Linguistics. doi: 10.18653/v1/P18-1082. URL https://www.aclweb.org/anthology/ P18-1082.","This text block is a bibliographic citation for a paper titled 'Hierarchical neural story generation' by Angela Fan, Mike Lewis, and Yann Dauphin, published in the Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics in July 2018.",,"((297.69525146484375, 786.0143938888888), (297.69525146484375, 935.7047144444444), (1416.7442626953125, 935.7047144444444), (1416.7442626953125, 786.0143938888888))",application/pdf,['eng'],11,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.934091568,,,,,,b9ce1fdcc4b5c4a1a1b2016f7f0c02e5
129,ListItem,Bibliography,Bibliography,TRUE,"[12] Angela Fan, Yacine Jernite, Ethan Perez, David Grangier, Jason Weston, and Michael Auli. ELI5: Long form question answering. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 3558–3567, Florence, Italy, July 2019. Association for Computational Linguistics. doi: 10.18653/v1/P19-1346. URL https://www.aclweb.org/ anthology/P19-1346.",This text block is a bibliographic citation for a paper titled 'ELI5: Long form question answering' presented at the 57th Annual Meeting of the Association for Computational Linguistics in 2019.,,"((299.51190185546875, 962.1231155555556), (299.51190185546875, 1111.1769366666667), (1416.8175048828125, 1111.1769366666667), (1416.8175048828125, 962.1231155555556))",application/pdf,['eng'],11,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.933576882,,,,,,bae1b5c8fe9217e729f82a0b1bac9563
130,ListItem,Bibliography,Bibliography,TRUE,"[13] Angela Fan, Claire Gardent, Chloe Braud, and Antoine Bordes. Augmenting transformers with KNN-based composite memory, 2020. URL https://openreview.net/forum?id= H1gx1CNKPH.","This text block is a bibliographic citation of a paper, including the authors' names, title of the work, year of publication, and a URL for accessing the paper.",,"((300.00000000000006, 1137.5953377777778), (300.00000000000006, 1226.0408255555556), (1415.3114013671875, 1226.0408255555556), (1415.3114013671875, 1137.5953377777778))",application/pdf,['eng'],11,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.942200661,,,,,,37bd601c2d2934eef58f49d5d22f3041
131,ListItem,Bibliography,Bibliography,TRUE,"[14] Thibault Févry, Livio Baldini Soares, Nicholas FitzGerald, Eunsol Choi, and Tom Kwiatkowski. Entities as experts: Sparse memory access with entity supervision. ArXiv, abs/2004.07202, 2020. URL https://arxiv.org/abs/2004.07202.","This text block is a bibliographic citation of an academic paper, including the authors, title, publication source, and URL.",,"((300.0, 1252.4620044444443), (300.0, 1340.9074922222221), (1418.5889892578125, 1340.9074922222221), (1418.5889892578125, 1252.4620044444443))",application/pdf,['eng'],11,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.93868798,,,,,,28989f5ccb379d69290904c8de007caf
132,ListItem,Bibliography,Bibliography,TRUE,"[15] Marjan Ghazvininejad, Chris Brockett, Ming-Wei Chang, Bill Dolan, Jianfeng Gao, Wen tau Yih, and Michel Galley. A knowledge-grounded neural conversation model. In AAAI Conference on Artiﬁcial Intelligence, 2018. URL https://www.aaai.org/ocs/index.php/ AAAI/AAAI18/paper/view/16710.",This text block is a bibliographic citation for a paper titled 'A knowledge-grounded neural conversation model' presented at the AAAI Conference on Artificial Intelligence in 2018.,,"((299.5888977050781, 1367.3258933333332), (299.5888977050781, 1486.0741588888889), (1414.836669921875, 1486.0741588888889), (1414.836669921875, 1367.3258933333332))",application/pdf,['eng'],11,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.942127883,,,,,,0dd6526cb09fbeb9f413fd977957bc0b
133,ListItem,Bibliography,Bibliography,TRUE,"[16] Katja Grace, John Salvatier, Allan Dafoe, Baobao Zhang, and Owain Evans. When will AI exceed human performance? evidence from AI experts. CoRR, abs/1705.08807, 2017. URL http://arxiv.org/abs/1705.08807.","This text block is a bibliographic citation for a paper titled 'When will AI exceed human performance? evidence from AI experts' by Katja Grace, John Salvatier, Allan Dafoe, Baobao Zhang, and Owain Evans, published in 2017.",,"((298.5525817871094, 1512.4953377777776), (298.5525817871094, 1600.9408255555556), (1417.054443359375, 1600.9408255555556), (1417.054443359375, 1512.4953377777776))",application/pdf,['eng'],11,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.940299034,,,,,,e391b8a6882fdb68f83bef5c3bc299bd
134,ListItem,Bibliography,Bibliography,TRUE,"[17] Jiatao Gu, Yong Wang, Kyunghyun Cho, and Victor O.K. Li. Search engine guided neural In AAAI Conference on Artiﬁcial Intelligence, 2018. URL https: machine translation. //www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17282.","This text block is a citation from a bibliography section, referencing a paper presented at the AAAI Conference on Artificial Intelligence in 2018.",,"((300.00000000000006, 1627.3592266666665), (300.00000000000006, 1715.807492222222), (1414.225830078125, 1715.807492222222), (1414.225830078125, 1627.3592266666665))",application/pdf,['eng'],11,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.937484384,,,,,,7a822751432f4477ccdf62a557d90cf3
135,ListItem,Bibliography,Bibliography,TRUE,"[18] Jiatao Gu, Yong Wang, Kyunghyun Cho, and Victor O.K. Li. Search engine guided neural machine translation. In 32nd AAAI Conference on Artiﬁcial Intelligence, AAAI 2018, 32nd AAAI Conference on Artiﬁcial Intelligence, AAAI 2018, pages 5133–5140. AAAI press, 2018. 32nd AAAI Conference on Artiﬁcial Intelligence, AAAI 2018 ; Conference date: 02-02-2018 Through 07-02-2018.",This text block is a bibliographic citation for a conference paper presented at the 32nd AAAI Conference on Artificial Intelligence in 2018.,,"((299.6081237792969, 1742.2258933333333), (299.6081237792969, 1891.110893333333), (1416.175048828125, 1891.110893333333), (1416.175048828125, 1742.2258933333333))",application/pdf,['eng'],11,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.934353113,,,,,,5e1ce5623a5ed15cb2819f951063e65d
136,ListItem,,Bibliography,,"[19] Kelvin Guu, Tatsunori B. Hashimoto, Yonatan Oren, and Percy Liang. Generating sentences by editing prototypes. Transactions of the Association for Computational Linguistics, 6:437–450, 2018. doi: 10.1162/tacl_a_00030. URL https://www.aclweb.org/anthology/Q18-1031.",,,"((300.00000000000006, 1917.6981155555554), (300.00000000000006, 2006.1436033333332), (1409.8304443359375, 2006.1436033333332), (1409.8304443359375, 1917.6981155555554))",application/pdf,['eng'],11,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.940179884,,,,,,7a74bb531db41f8bd81c5f8169cdef54
137,Footer,UncategorizedText,UncategorizedText,FALSE,11,The text '11' does not provide enough context or information to be classified into any specific category.,,"((836.1638888888889, 2061.325893333333), (836.1638888888889, 2088.999782222222), (863.8377777777777, 2088.999782222222), (863.8377777777777, 2061.325893333333))",application/pdf,['eng'],11,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.787228405,,,,,,a327968707acbd64bd15ac8cda2c7e77
138,ListItem,Bibliography,Bibliography,TRUE,"[20] Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, and Ming-Wei Chang. REALM: Retrieval-augmented language model pre-training. ArXiv, abs/2002.08909, 2020. URL https: //arxiv.org/abs/2002.08909.","This text block is a bibliographic citation for a paper titled 'REALM: Retrieval-augmented language model pre-training' authored by Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, and Ming-Wei Chang, published on ArXiv in 2020.",,"((300.0, 205.97867111111094), (300.0, 294.42415888888877), (1413.401123046875, 294.42415888888877), (1413.401123046875, 205.97867111111094))",application/pdf,['eng'],12,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.934605598,,,,,,e2e445b5f6a136a07be9337d261c0e37
139,ListItem,Bibliography,Bibliography,TRUE,"A In S. Bengio, retrieve-and-edit H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett, ed- itors, Advances pages 10052– 10062. Curran Associates, URL http://papers.nips.cc/paper/ 8209-a-retrieve-and-edit-framework-for-predicting-structured-outputs. pdf.","This text block is a citation from a bibliography section, referencing a paper titled 'A Retrieve-and-Edit Framework for Predicting Structured Outputs' published in Advances by Curran Associates.",,"((299.9999999999999, 320.26755999999983), (299.9999999999999, 529.924158888889), (1415.966796875, 529.924158888889), (1415.966796875, 320.26755999999983))",application/pdf,['eng'],12,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.950760543,,,,,,f443b3a6f1bb1d591099327fdd21afda
140,ListItem,Bibliography,Bibliography,TRUE,"[22] Nabil Hossain, Marjan Ghazvininejad, and Luke Zettlemoyer. Simple and effective retrieve- edit-rerank text generation. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 2532–2538, Online, July 2020. Association for Computa- tional Linguistics. doi: 10.18653/v1/2020.acl-main.228. URL https://www.aclweb.org/ anthology/2020.acl-main.228.",This text block is a bibliographic citation for a paper presented at the 58th Annual Meeting of the Association for Computational Linguistics.,,"((296.1883850097656, 555.7675599999998), (296.1883850097656, 704.8186033333334), (1419.547607421875, 704.8186033333334), (1419.547607421875, 555.7675599999998))",application/pdf,['eng'],12,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.935949087,,,,,,af13f16c42071f87c398190e58c52d8d
141,ListItem,Bibliography,Bibliography,TRUE,"[23] Jeff Johnson, Matthijs Douze, and Hervé Jégou. Billion-scale similarity search with gpus. arXiv preprint arXiv:1702.08734, 2017. URL https://arxiv.org/abs/1702.08734.","This text block is a bibliographic citation for a paper titled 'Billion-scale similarity search with gpus' by Jeff Johnson, Matthijs Douze, and Hervé Jégou, published as an arXiv preprint in 2017.",,"((300.00000000000006, 730.0255050000001), (300.00000000000006, 788.8047144444444), (1410.3035888671875, 788.8047144444444), (1410.3035888671875, 730.0255050000001))",application/pdf,['eng'],12,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.932455003,,,,,,52f89320a94732cc135a27c29f25d51c
142,ListItem,Bibliography,Bibliography,TRUE,"[24] Mandar Joshi, Eunsol Choi, Daniel Weld, and Luke Zettlemoyer. TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1601–1611, Vancouver, Canada, July 2017. Association for Computational Linguistics. doi: 10.18653/v1/P17-1147. URL https://www.aclweb.org/anthology/P17-1147.","This text block is a bibliographic citation for a paper titled 'TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension' by Mandar Joshi, Eunsol Choi, Daniel Weld, and Luke Zettlemoyer, published in the Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics.",,"((297.2787170410156, 814.6481155555556), (297.2787170410156, 963.699158888889), (1418.163330078125, 963.699158888889), (1418.163330078125, 814.6481155555556))",application/pdf,['eng'],12,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.936085761,,,,,,efdbc77b7569e2069fd0313f356a4282
143,ListItem,Bibliography,Bibliography,TRUE,"Inferring algorithmic patterns with stack- the 28th International Conference on augmented recurrent nets. Neural Information Processing Systems - Volume 1, NIPS’15, page 190–198, Cam- bridge, MA, USA, 2015. MIT Press. URL https://papers.nips.cc/paper/ 5857-inferring-algorithmic-patterns-with-stack-augmented-recurrent-nets.","This text block is a citation from a bibliography section, referencing a paper presented at the 28th International Conference on Neural Information Processing Systems in 2015.",,"((298.3515625, 989.54256), (298.3515625, 1138.5936033333332), (1417.2613525390625, 1138.5936033333332), (1417.2613525390625, 989.54256))",application/pdf,['eng'],12,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.93591547,,,,,,2cdc89a4faf7ddd20900721eb6a099c7
144,ListItem,,Bibliography,,"[26] Vladimir Karpukhin, Barlas Oguz, Sewon Min, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih. Dense passage retrieval for open-domain question answering. arXiv preprint arXiv:2004.04906, 2020. URL https://arxiv.org/abs/2004.04906.",,,"((300.0, 1164.4370044444445), (300.0, 1252.8824922222223), (1413.8370361328125, 1252.8824922222223), (1413.8370361328125, 1164.4370044444445))",application/pdf,['eng'],12,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.936874628,,,,,,3dbc6ce3702760f3ed78e6a97570f1bf
145,ListItem,Bibliography,Bibliography,TRUE,"[27] Urvashi Khandelwal, Omer Levy, Dan Jurafsky, Luke Zettlemoyer, and Mike Lewis. Generaliza- tion through memorization: Nearest neighbor language models. In International Conference on Learning Representations, 2020. URL https://openreview.net/forum?id=HklBjCEKvH.","This text block is a bibliographic citation for a paper presented at the International Conference on Learning Representations in 2020, authored by Urvashi Khandelwal, Omer Levy, Dan Jurafsky, Luke Zettlemoyer, and Mike Lewis.",,"((300.0, 1278.7258933333333), (300.0, 1367.1713811111113), (1411.29248046875, 1367.1713811111113), (1411.29248046875, 1278.7258933333333))",application/pdf,['eng'],12,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.935660899,,,,,,68c60234637393ef3f5d961c7538a0df
146,ListItem,,Bibliography,,"[28] Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In Yoshua Bengio and Yann LeCun, editors, 3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings, 2015. URL http://arxiv.org/abs/1412.6980.",,,"((298.5367431640625, 1393.0147822222223), (298.5367431640625, 1511.7630477777777), (1414.0994873046875, 1511.7630477777777), (1414.0994873046875, 1393.0147822222223))",application/pdf,['eng'],12,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.939314127,,,,,,41652bcf99b648106014cf8c0a17dbda
147,ListItem,Bibliography,Bibliography,TRUE,"[29] Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redﬁeld, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Matthew Kelcey, Jacob Devlin, Ken- ton Lee, Kristina N. Toutanova, Llion Jones, Ming-Wei Chang, Andrew Dai, Jakob Uszkoreit, Quoc Le, and Slav Petrov. Natural Questions: a Benchmark for Ques- the Association of Computational Lin- tion Answering Research. guistics, 2019. URL https://tomkwiat.users.x20web.corp.google.com/papers/ natural-questions/main-1455-kwiatkowski.pdf.",This text block is a bibliographic citation for a research paper titled 'Natural Questions: a Benchmark for Question Answering Research' authored by multiple individuals and published by the Association of Computational Linguistics in 2019.,,"((300.0, 1537.606448888889), (300.0, 1747.2630477777777), (1411.2957763671875, 1747.2630477777777), (1411.2957763671875, 1537.606448888889))",application/pdf,['eng'],12,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.950042903,,,,,,38040b6bff9aea88b9dc4c1b3073b4a0
148,ListItem,Bibliography,Bibliography,TRUE,"[30] Guillaume Lample, Alexandre Sablayrolles, Marc’ Aurelio Ranzato, Ludovic Denoyer, and Herve Jegou. Large memory layers with product keys. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d’ Alché-Buc, E. Fox, and R. Garnett, editors, Advances in Neural In- formation Processing Systems 32, pages 8548–8559. Curran Associates, Inc., 2019. URL http: //papers.nips.cc/paper/9061-large-memory-layers-with-product-keys.pdf.","This text block is a bibliographic citation for a paper titled 'Large memory layers with product keys' authored by Guillaume Lample, Alexandre Sablayrolles, Marc’ Aurelio Ranzato, Ludovic Denoyer, and Herve Jegou, published in Advances in Neural Information Processing Systems 32 in 2019.",,"((300.0, 1773.1064488888887), (300.0, 1922.1574922222221), (1416.6514892578125, 1922.1574922222221), (1416.6514892578125, 1773.1064488888887))",application/pdf,['eng'],12,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.936604261,,,,,,a10e12dba343405c89dc6c21775a8584
149,ListItem,Bibliography,Bibliography,TRUE,"[31] Kenton Lee, Ming-Wei Chang, and Kristina Toutanova. Latent retrieval for weakly supervised open domain question answering. In Proceedings of the 57th Annual Meeting of the Association","This text block is a citation from the bibliography section, referencing a work by Kenton Lee, Ming-Wei Chang, and Kristina Toutanova presented at the 57th Annual Meeting of the Association.",,"((298.0550537109375, 1948.0008933333331), (298.0550537109375, 2005.97756), (1410.1134033203125, 2005.97756), (1410.1134033203125, 1948.0008933333331))",application/pdf,['eng'],12,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.933910191,,,,,,c0eb1a5916b34f4af6a089bb8ca9aa43
150,Footer,UncategorizedText,UncategorizedText,FALSE,12,The text '12' does not provide enough context or information to be classified into any specific category.,,"((836.1157836914062, 2061.325893333333), (836.1157836914062, 2088.999782222222), (864.6591796875, 2088.999782222222), (864.6591796875, 2061.325893333333))",application/pdf,['eng'],12,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.774707615,,,,,,7d1dd7a40820e2b94cd1608f760124f1
151,NarrativeText,Bibliography,Bibliography,TRUE,"for Computational Linguistics, pages 6086–6096, Florence, Italy, July 2019. Association for Computational Linguistics. doi: 10.18653/v1/P19-1612. URL https://www.aclweb.org/ anthology/P19-1612.","This text block is a citation from the bibliography section, providing details about a publication including the title, page numbers, location, date, publisher, DOI, and URL.",,"((353.7281494140625, 205.34217166666653), (353.7281494140625, 294.42415888888877), (1413.0234375, 294.42415888888877), (1413.0234375, 205.34217166666653))",application/pdf,['eng'],13,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.940353334,,,,,,58311e33d829fba85c3c028aae53c0c6
152,ListItem,Bibliography,Bibliography,TRUE,"[32] Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer. BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. arXiv preprint arXiv:1910.13461, 2019. URL https://arxiv.org/abs/1910.13461.","This text block is a bibliographic citation for a research paper on BART, a denoising sequence-to-sequence pre-training model for natural language generation, translation, and comprehension.",,"((300.00000000000006, 318.31755999999984), (300.00000000000006, 437.0658255555554), (1416.248046875, 437.0658255555554), (1416.248046875, 318.31755999999984))",application/pdf,['eng'],13,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.941326201,,,,,,887c9f03b1b337f6c052137d8aa636bb
153,ListItem,Bibliography,Bibliography,TRUE,"[33] Jiwei Li, Michel Galley, Chris Brockett, Jianfeng Gao, and Bill Dolan. A diversity-promoting objective function for neural conversation models. In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 110–119, San Diego, California, June 2016. Association for Computational Linguistics. doi: 10.18653/v1/N16-1014. URL https://www.aclweb.org/anthology/ N16-1014.",This text block is a bibliographic citation for a paper presented at the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies.,,"((300.0, 460.9620044444442), (300.0, 640.3158255555556), (1402.9005717222224, 640.3158255555556), (1402.9005717222224, 460.9620044444442))",application/pdf,['eng'],13,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.94873786,,,,,,b51be60b8f2a33ede783737c182f0c5d
154,ListItem,Bibliography,Bibliography,TRUE,"[34] Margaret Li, Jason Weston, and Stephen Roller. Acute-eval: Improved dialogue evaluation with optimized questions and multi-turn comparisons. ArXiv, abs/1909.03087, 2019. URL https://arxiv.org/abs/1909.03087.","This text block is a bibliographic citation of a paper titled 'Acute-eval: Improved dialogue evaluation with optimized questions and multi-turn comparisons' by Margaret Li, Jason Weston, and Stephen Roller, published on ArXiv in 2019.",,"((299.3094482421875, 664.2092266666667), (299.3094482421875, 752.6574922222222), (1416.4989013671875, 752.6574922222222), (1416.4989013671875, 664.2092266666667))",application/pdf,['eng'],13,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.944129705,,,,,,5a1ee2b339eca2b4ee8abdfb22edb422
155,ListItem,Bibliography,Bibliography,TRUE,"[35] Hairong Liu, Mingbo Ma, Liang Huang, Hao Xiong, and Zhongjun He. Robust neural machine translation with joint textual and phonetic embedding. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 3044–3049, Florence, Italy, July 2019. Association for Computational Linguistics. doi: 10.18653/v1/P19-1291. URL https://www.aclweb.org/anthology/P19-1291.","This text block is a bibliographic citation for a paper presented at the 57th Annual Meeting of the Association for Computational Linguistics, including details such as authors, title, conference, location, date, publisher, DOI, and URL.",,"((299.9999999999999, 776.5508933333333), (299.9999999999999, 925.6019366666666), (1415.8846435546875, 925.6019366666666), (1415.8846435546875, 776.5508933333333))",application/pdf,['eng'],13,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.935290098,,,,,,854c4db594f8c13ff921d88ab8d70442
156,ListItem,Bibliography,Bibliography,TRUE,"[36] Peter J. Liu*, Mohammad Saleh*, Etienne Pot, Ben Goodrich, Ryan Sepassi, Lukasz Kaiser, and Noam Shazeer. Generating wikipedia by summarizing long sequences. In International Conference on Learning Representations, 2018. URL https://openreview.net/forum? id=Hyg0vbWC-.","This text block is a citation from a bibliography section, listing authors, title, conference, year, and URL.",,"((297.9649353027344, 949.4981155555554), (297.9649353027344, 1068.246381111111), (1416.4095458984375, 1068.246381111111), (1416.4095458984375, 949.4981155555554))",application/pdf,['eng'],13,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.941131651,,,,,,6feaf4596a7d24f0c03622853b2776f9
157,ListItem,Bibliography,Bibliography,TRUE,"[37] Yury A. Malkov and D. A. Yashunin. Efﬁcient and robust approximate nearest neighbor search using hierarchical navigable small world graphs. IEEE Transactions on Pattern Analysis and Machine Intelligence, 42:824–836, 2016. URL https://arxiv.org/abs/1603.09320.","This text block is a citation from the bibliography section, referencing a paper by Yury A. Malkov and D. A. Yashunin on approximate nearest neighbor search using hierarchical navigable small world graphs.",,"((300.00000000000006, 1092.139782222222), (300.00000000000006, 1180.5852699999998), (1414.2403564453125, 1180.5852699999998), (1414.2403564453125, 1092.139782222222))",application/pdf,['eng'],13,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.93818146,,,,,,44971c27e5ec96ad2b8a74bef61d5ebe
158,ListItem,Bibliography,Bibliography,TRUE,"[38] Gary Marcus. The next decade in ai: four steps towards robust artiﬁcial intelligence. arXiv preprint arXiv:2002.06177, 2020. URL https://arxiv.org/abs/2002.06177.","This text block is a citation entry from a bibliography section, referencing a work by Gary Marcus on artificial intelligence.",,"((299.99999999999983, 1203.8449494444444), (299.99999999999983, 1262.6241588888888), (1410.10302734375, 1262.6241588888888), (1410.10302734375, 1203.8449494444444))",application/pdf,['eng'],13,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.929800451,,,,,,71b7cc9a0a69478636b9bc83029b94e3
159,ListItem,Bibliography,Bibliography,TRUE,"[39] Luca Massarelli, Fabio Petroni, Aleksandra Piktus, Myle Ott, Tim Rocktäschel, Vassilis Plachouras, Fabrizio Silvestri, and Sebastian Riedel. How decoding strategies affect the arXiv preprint arXiv:1911.03587, 2019. URL https: veriﬁability of generated text. //arxiv.org/abs/1911.03587.","This text block is a bibliographic citation of a paper, listing the authors, title, and publication details.",,"((298.9150695800781, 1286.5175599999998), (298.9150695800781, 1405.2686033333332), (1416.149169921875, 1405.2686033333332), (1416.149169921875, 1286.5175599999998))",application/pdf,['eng'],13,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.939948022,,,,,,13b501e4a6a4ed2f4ba7b0a14c9f9865
160,ListItem,Bibliography,Bibliography,TRUE,"[40] Paulius Micikevicius, Sharan Narang, Jonah Alben, Gregory Diamos, Erich Elsen, David Garcia, Boris Ginsburg, Michael Houston, Oleksii Kuchaiev, Ganesh Venkatesh, and Hao Wu. Mixed precision training. In ICLR, 2018. URL https://openreview.net/forum?id=r1gs9JgRZ.","This text block is a citation from a bibliography section, listing authors, title, conference, year, and URL.",,"((299.9999999999999, 1429.1620044444446), (299.9999999999999, 1517.6074922222224), (1415.118408203125, 1517.6074922222224), (1415.118408203125, 1429.1620044444446))",application/pdf,['eng'],13,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.938260913,,,,,,5e38e9371a0c774e061b67af86301642
161,ListItem,Bibliography,Bibliography,TRUE,"[41] Nikita Moghe, Siddhartha Arora, Suman Banerjee, and Mitesh M. Khapra. Towards exploit- ing background knowledge for building conversation systems. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 2322–2332, Brus- sels, Belgium, October-November 2018. Association for Computational Linguistics. doi: 10.18653/v1/D18-1255. URL https://www.aclweb.org/anthology/D18-1255.",This text block is a bibliographic citation for a paper presented at the 2018 Conference on Empirical Methods in Natural Language Processing.,,"((295.6016845703125, 1541.5008933333334), (295.6016845703125, 1690.5547144444445), (1418.832763671875, 1690.5547144444445), (1418.832763671875, 1541.5008933333334))",application/pdf,['eng'],13,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.931551099,,,,,,c0fa1443458ae8e2b1aa23798c490e94
162,ListItem,Bibliography,Bibliography,TRUE,"[42] Preksha Nema and Mitesh M. Khapra. Towards a better metric for evaluating question generation systems. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 3950–3959, Brussels, Belgium, October-November 2018. Association for Computational Linguistics. doi: 10.18653/v1/D18-1429. URL https://www.aclweb.org/ anthology/D18-1429.","This text block is a bibliographic citation for a paper presented at the 2018 Conference on Empirical Methods in Natural Language Processing, including details such as authors, title, conference, location, date, publisher, DOI, and URL.",,"((298.8258361816406, 1714.4481155555557), (298.8258361816406, 1863.4991588888888), (1414.226806640625, 1863.4991588888888), (1414.226806640625, 1714.4481155555557))",application/pdf,['eng'],13,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.935848951,,,,,,a83dfc27a69ab77449d660052ddf4806
163,ListItem,Bibliography,Bibliography,TRUE,"[43] Tri Nguyen, Mir Rosenberg, Xia Song, Jianfeng Gao, Saurabh Tiwary, Rangan Majumder, and Li Deng. MS MARCO: A human generated machine reading comprehension dataset. In Tarek Richard Besold, Antoine Bordes, Artur S. d’Avila Garcez, and Greg Wayne, editors, Proceedings of the Workshop on Cognitive Computation: Integrating neural and symbolic","This text block is a citation from the bibliography section, listing authors and the title of a work along with publication details.",,"((298.9276428222656, 1887.3953377777777), (298.9276428222656, 2005.3410605555553), (1413.8192138671875, 2005.3410605555553), (1413.8192138671875, 1887.3953377777777))",application/pdf,['eng'],13,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.939275563,,,,,,03954df1802919923beed04ff99a4ad6
164,Footer,UncategorizedText,UncategorizedText,FALSE,13,The text '13' does not provide enough context or information to be classified into any specific category.,,"((836.1638888888889, 2061.325893333333), (836.1638888888889, 2088.999782222222), (864.382568359375, 2088.999782222222), (864.382568359375, 2061.325893333333))",application/pdf,['eng'],13,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.810477018,,,,,,03c314b003af73c4a69d671b1e8b6bda
165,NarrativeText,Bibliography,Bibliography,TRUE,"approaches 2016 co-located with the 30th Annual Conference on Neural Information Processing Systems (NIPS 2016), Barcelona, Spain, December 9, 2016, volume 1773 of CEUR Workshop Proceedings. CEUR-WS.org, 2016. URL http://ceur-ws.org/Vol-1773/CoCoNIPS_ 2016_paper9.pdf.","This text block is a bibliographic citation for a workshop proceeding associated with the 30th Annual Conference on Neural Information Processing Systems (NIPS 2016). It includes details such as the event location, date, volume number, and a URL to the paper.",,"((356.933837890625, 205.34217166666653), (356.933837890625, 324.7269366666665), (1407.330322265625, 324.7269366666665), (1407.330322265625, 205.34217166666653))",application/pdf,['eng'],14,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.93961817,,,,,,aa1a6ebf75248f4c01aa9d51825ba482
166,ListItem,Bibliography,Bibliography,TRUE,"[44] Rodrigo Nogueira and Kyunghyun Cho. Passage re-ranking with BERT. arXiv preprint arXiv:1901.04085, 2019. URL https://arxiv.org/abs/1901.04085.","This text block is a citation entry from a bibliography, referencing a preprint article on passage re-ranking with BERT by Rodrigo Nogueira and Kyunghyun Cho.",,"((296.2549743652344, 345.45883833333323), (296.2549743652344, 404.2380477777777), (1408.833251953125, 404.2380477777777), (1408.833251953125, 345.45883833333323))",application/pdf,['eng'],14,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.928945184,,,,,,10e9c27ed15fe219ab8ea3eeec17c0d2
167,ListItem,Bibliography,Bibliography,TRUE,"[45] Myle Ott, Sergey Edunov, Alexei Baevski, Angela Fan, Sam Gross, Nathan Ng, David Grangier, and Michael Auli. fairseq: A fast, extensible toolkit for sequence modeling. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics (Demonstrations), pages 48–53, Minneapolis, Minnesota, June 2019. Association for Computational Linguistics. doi: 10.18653/v1/N19-4009. URL https://www.aclweb. org/anthology/N19-4009.",This text block is a bibliographic citation for a paper presented at the 2019 Conference of the North American Chapter of the Association for Computational Linguistics.,,"((300.0, 425.6064488888888), (300.0, 604.9630477777779), (1410.1805723888888, 604.9630477777779), (1410.1805723888888, 425.6064488888888))",application/pdf,['eng'],14,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.947126269,,,,,,0624a179fd5ecca8858b089499d6a698
168,ListItem,Bibliography,Bibliography,TRUE,"[46] Ethan Perez, Siddharth Karamcheti, Rob Fergus, Jason Weston, Douwe Kiela, and Kyunghyun Cho. Finding generalizable evidence by learning to convince q&a models. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 2402–2411, Hong Kong, China, November 2019. Association for Computational Linguistics. doi: 10.18653/v1/D19-1244. URL https://www.aclweb.org/anthology/D19-1244.","This text block is a bibliographic citation for a paper presented at the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing. It includes the authors, title, conference details, page numbers, location, publisher, DOI, and URL.",,"((297.9759521484375, 626.3314488888886), (297.9759521484375, 805.6880477777778), (1408.7723388671875, 805.6880477777778), (1408.7723388671875, 626.3314488888886))",application/pdf,['eng'],14,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.953890741,,,,,,1d849705b3eff3b2735a32ed56447ff9
169,ListItem,Bibliography,Bibliography,TRUE,"[47] Fabio Petroni, Tim Rocktäschel, Sebastian Riedel, Patrick Lewis, Anton Bakhtin, Yuxiang Wu, and Alexander Miller. Language models as knowledge bases? In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 2463–2473, Hong Kong, China, November 2019. Association for Computational Linguistics. doi: 10.18653/v1/ D19-1250. URL https://www.aclweb.org/anthology/D19-1250.","This text block is a bibliographic citation for a paper presented at the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). It includes the authors, title, conference details, page numbers, location, publisher, DOI, and URL.",,"((298.3315734863281, 827.0564488888889), (298.3315734863281, 1006.41027), (1410.204345703125, 1006.41027), (1410.204345703125, 827.0564488888889))",application/pdf,['eng'],14,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.953430057,,,,,,68111e5f80dddd7d5f7580b1d12f1c71
170,ListItem,Bibliography,Bibliography,TRUE,"[48] Fabio Petroni, Patrick Lewis, Aleksandra Piktus, Tim Rocktäschel, Yuxiang Wu, Alexander H. Miller, and Sebastian Riedel. How context affects language models’ factual predictions. In Automated Knowledge Base Construction, 2020. URL https://openreview.net/forum? id=025X0zPfn.","This text block is a bibliographic citation of a paper presented at the Automated Knowledge Base Construction conference in 2020, including the authors' names, title of the paper, and a URL to the paper.",,"((297.2217712402344, 1027.781448888889), (297.2217712402344, 1146.5297144444444), (1416.984619140625, 1146.5297144444444), (1416.984619140625, 1027.781448888889))",application/pdf,['eng'],14,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.943241358,,,,,,b91931eb96b5c2525813af3791d2d9f1
171,ListItem,Bibliography,Bibliography,TRUE,"[49] Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. proving Language Understanding https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/ language-unsupervised/language_understanding_paper.pdf. by Generative Pre-Training, 2018. Im- URL","This text block is a bibliographic citation for a paper by Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever titled 'proving Language Understanding by Generative Pre-Training' published in 2018, with a URL link to the paper.",,"((294.1904602050781, 1167.8981155555555), (294.1904602050781, 1286.6463811111112), (1422.5682373046875, 1286.6463811111112), (1422.5682373046875, 1167.8981155555555))",application/pdf,['eng'],14,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.936072707,,,,,,380867625e2702199e2a0bf66c233156
172,ListItem,Bibliography,Bibliography,TRUE,"[50] Alec Radford, Sutskever. https://d4mucfpksywv.cloudfront.net/better-language-models/language_ models_are_unsupervised_multitask_learners.pdf.","This text block is a citation entry, listing an author and a URL to a document, which is typical of a bibliography section.",,"((295.03369140625, 1308.0175599999998), (295.03369140625, 1426.7658255555555), (1416.3662109375, 1426.7658255555555), (1416.3662109375, 1308.0175599999998))",application/pdf,['eng'],14,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.937374175,,,,,,d9832b49f38872620a075b4e1ade0f00
173,ListItem,Bibliography,Bibliography,TRUE,"[51] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. Exploring the limits of transfer learning with a uniﬁed text-to-text transformer. arXiv e-prints, 2019. URL https://arxiv.org/abs/1910.10683.","This text block is a bibliographic citation for a paper titled 'Exploring the limits of transfer learning with a unified text-to-text transformer' by Colin Raffel and co-authors, published on arXiv in 2019.",,"((300.0, 1448.1342266666666), (300.0, 1536.5797144444443), (1413.648193359375, 1536.5797144444443), (1413.648193359375, 1448.1342266666666))",application/pdf,['eng'],14,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.937902153,,,,,,0a43a4538e2a1d5e6005334fd093161d
174,ListItem,Bibliography,Bibliography,TRUE,"[52] Adam Roberts, Colin Raffel, and Noam Shazeer. How much knowledge can you pack into the parameters of a language model? arXiv e-prints, 2020. URL https://arxiv.org/abs/ 2002.08910.","This text block is a bibliographic citation for a paper by Adam Roberts, Colin Raffel, and Noam Shazeer, including the title of the paper, the publication source (arXiv e-prints), the year (2020), and a URL to the paper.",,"((300.0, 1557.9481155555554), (300.0, 1646.396381111111), (1413.8369140625, 1646.396381111111), (1413.8369140625, 1557.9481155555554))",application/pdf,['eng'],14,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.938097179,,,,,,20cde21f81cee4a8838b3b8b19931988
175,ListItem,Bibliography,Bibliography,TRUE,"[53] Stephen Robertson and Hugo Zaragoza. The probabilistic relevance framework: Bm25 and beyond. Found. Trends Inf. Retr., 3(4):333–389, April 2009. ISSN 1554-0669. doi: 10.1561/ 1500000019. URL https://doi.org/10.1561/1500000019.","This text block is a bibliographic citation for a publication by Stephen Robertson and Hugo Zaragoza, detailing the probabilistic relevance framework and BM25.",,"((300.0, 1667.764782222222), (300.0, 1756.21027), (1417.06298828125, 1756.21027), (1417.06298828125, 1667.764782222222))",application/pdf,['eng'],14,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.938012421,,,,,,71207e11eaed5979f818090ba4a98211
176,ListItem,Bibliography,Bibliography,TRUE,"[54] Irene Solaiman, Miles Brundage, Jack Clark, Amanda Askell, Ariel Herbert-Voss, Jeff Wu, Alec Radford, and Jian-Bing Wang. Release strategies and the social impacts of language models. ArXiv, abs/1908.09203, 2019.","This text block is a citation from a bibliography section, listing authors, title, source, and publication year.",,"((300.0, 1777.5786711111111), (300.0, 1865.8581155555553), (1414.8797607421875, 1865.8581155555553), (1414.8797607421875, 1777.5786711111111))",application/pdf,['eng'],14,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.942325652,,,,,,b3a0760984b9a922938d9f5d3c008b13
177,ListItem,Bibliography,Bibliography,TRUE,"[55] Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, and Rob Fergus. End-to-end memory net- works. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, editors, Advances in Neural Information Processing Systems 28, pages 2440–2448. Curran Associates, Inc., 2015. URL http://papers.nips.cc/paper/5846-end-to-end-memory-networks.pdf.","This text block is a bibliographic citation for a paper titled 'End-to-end memory networks' authored by Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, and Rob Fergus, published in the Advances in Neural Information Processing Systems 28 in 2015.",,"((295.6671447753906, 1887.3953377777777), (295.6671447753906, 2006.1436033333332), (1417.437744140625, 2006.1436033333332), (1417.437744140625, 1887.3953377777777))",application/pdf,['eng'],14,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.940594494,,,,,,4a1132af3ab532c0a005260034a300e3
178,UncategorizedText,UncategorizedText,UncategorizedText,FALSE,14,The text '14' does not provide enough context or information to be classified into any specific category.,,"((836.1638888888889, 2061.325893333333), (836.1638888888889, 2088.999782222222), (863.8377777777777, 2088.999782222222), (863.8377777777777, 2061.325893333333))",application/pdf,['eng'],14,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,,,,,,,7895318d28c07e69489c90120621d803
179,ListItem,Bibliography,Bibliography,TRUE,"[56] James Thorne, Andreas Vlachos, Christos Christodoulopoulos, and Arpit Mittal. FEVER: a large-scale dataset for fact extraction and VERiﬁcation. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), pages 809–819, New Orleans, Louisiana, June 2018. Association for Computational Linguistics. doi: 10.18653/v1/N18-1074. URL https://www.aclweb.org/anthology/N18-1074.","This text block is a bibliographic citation for a paper titled 'FEVER: a large-scale dataset for fact extraction and verification' by James Thorne, Andreas Vlachos, Christos Christodoulopoulos, and Arpit Mittal, published in the Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies.",,"((299.94488525390625, 205.97867111111094), (299.94488525390625, 385.3324922222223), (1406.533447265625, 385.3324922222223), (1406.533447265625, 205.97867111111094))",application/pdf,['eng'],15,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.951364934,,,,,,57e13f369be175292083aa1d217da7f1
180,ListItem,Bibliography,Bibliography,TRUE,"[57] James H. Thorne and Andreas Vlachos. Avoiding catastrophic forgetting in mitigating model biases in sentence-pair classiﬁcation with elastic weight consolidation. ArXiv, abs/2004.14366, 2020. URL https://arxiv.org/abs/2004.14366.","This text block is a bibliographic citation of a paper by James H. Thorne and Andreas Vlachos, including the title, publication source, and URL.",,"((299.48577880859375, 415.5647822222221), (299.48577880859375, 504.01026999999993), (1412.90625, 504.01026999999993), (1412.90625, 415.5647822222221))",application/pdf,['eng'],15,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.940316498,,,,,,fcd208b54baeb509507d7fd204dff046
181,ListItem,Bibliography,Bibliography,TRUE,"[58] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Ł ukasz Kaiser, and Illia Polosukhin. Attention is all you need. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, editors, Advances in Neural Information Processing Systems 30, pages 5998–6008. Curran Associates, Inc., 2017. URL http://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf.","This text block is a bibliographic citation for a paper titled 'Attention is all you need' by Ashish Vaswani et al., published in Advances in Neural Information Processing Systems 30 in 2017.",,"((299.46392822265625, 534.2425599999997), (299.46392822265625, 683.2936033333333), (1417.28271484375, 683.2936033333333), (1417.28271484375, 534.2425599999997))",application/pdf,['eng'],15,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.935773432,,,,,,5291372ede6b6f2a5ac16716b67a20b2
182,ListItem,Bibliography,Bibliography,TRUE,"[59] Ashwin Vijayakumar, Michael Cogswell, Ramprasaath Selvaraju, Qing Sun, Stefan Lee, David Crandall, and Dhruv Batra. Diverse beam search for improved description of complex scenes. AAAI Conference on Artiﬁcial Intelligence, 2018. URL https://www.aaai.org/ocs/index. php/AAAI/AAAI18/paper/view/17329.","This text block is a bibliographic citation for a paper presented at the AAAI Conference on Artificial Intelligence in 2018, authored by Ashwin Vijayakumar, Michael Cogswell, Ramprasaath Selvaraju, Qing Sun, Stefan Lee, David Crandall, and Dhruv Batra.",,"((299.92840576171875, 713.5258933333331), (299.92840576171875, 832.297607421875), (1414.12744140625, 832.297607421875), (1414.12744140625, 713.5258933333331))",application/pdf,['eng'],15,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.942059755,,,,,,7875d2255a54d11b0be4eb77ef8490cb
183,ListItem,Bibliography,Bibliography,TRUE,"[60] Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel Bowman. GLUE: A multi-task benchmark and analysis platform for natural language understanding. In Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP, pages 353–355, Brussels, Belgium, November 2018. Association for Computational Linguistics. doi: 10.18653/v1/W18-5446. URL https://www.aclweb.org/ anthology/W18-5446.","This text block is a bibliographic citation for a paper titled 'GLUE: A multi-task benchmark and analysis platform for natural language understanding' by Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel Bowman, published in the Proceedings of the 2018 EMNLP Workshop BlackboxNLP.",,"((295.9344482421875, 862.5036711111111), (295.9344482421875, 1041.86027), (1419.5819091796875, 1041.86027), (1419.5819091796875, 862.5036711111111))",application/pdf,['eng'],15,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.929790556,,,,,,560a0116537698d9daf7db115239c7af
184,ListItem,Bibliography,Bibliography,TRUE,"[61] Alex Wang, Yada Pruksachatkun, Nikita Nangia, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel Bowman. SuperGLUE: A Stickier Benchmark for General- Purpose Language Understanding Systems. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d\textquotesingle Alché-Buc, E. Fox, and R. Garnett, editors, Advances in Neural Information Processing Systems 32, pages 3261–3275. Curran Associates, Inc., 2019. URL https:// arxiv.org/abs/1905.00537.","This text block is a bibliographic citation for a paper titled 'SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems' authored by Alex Wang, Yada Pruksachatkun, Nikita Nangia, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel Bowman, published in Advances in Neural Information Processing Systems 32 in 2019.",,"((293.4065856933594, 1070.078125), (293.4065856933594, 1252.6361083984375), (1414.6490478515625, 1252.6361083984375), (1414.6490478515625, 1070.078125))",application/pdf,['eng'],15,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.942475021,,,,,,bc89f2c54967c64caf13eadf79277158
185,ListItem,Bibliography,Bibliography,TRUE,"[62] Shuohang Wang, Mo Yu, Xiaoxiao Guo, Zhiguo Wang, Tim Klinger, Wei Zhang, Shiyu Chang, Gerry Tesauro, Bowen Zhou, and Jing Jiang. R3: Reinforced ranker-reader for open-domain question answering. In Sheila A. McIlraith and Kilian Q. Weinberger, editors, Proceedings of the Thirty-Second AAAI Conference on Artiﬁcial Intelligence, (AAAI-18), the 30th innovative Applications of Artiﬁcial Intelligence (IAAI-18), and the 8th AAAI Symposium on Educational Advances in Artiﬁcial Intelligence (EAAI-18), New Orleans, Louisiana, USA, February 2-7, 2018, pages 5981–5988. AAAI Press, 2018. URL https://www.aaai.org/ocs/index. php/AAAI/AAAI18/paper/view/16712.","This text block is a citation from a bibliography section, referencing a paper presented at the AAAI Conference on Artificial Intelligence in 2018.",,"((300.0, 1279.53955078125), (300.0, 1528.899158888889), (1416.887939453125, 1528.899158888889), (1416.887939453125, 1279.53955078125))",application/pdf,['eng'],15,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.95241636,,,,,,469388040f96c40753047cb882f601fd
186,ListItem,Bibliography,Bibliography,TRUE,"[63] Shuohang Wang, Mo Yu, Jing Jiang, Wei Zhang, Xiaoxiao Guo, Shiyu Chang, Zhiguo Wang, Tim Klinger, Gerald Tesauro, and Murray Campbell. Evidence aggregation for answer re- ranking in open-domain question answering. In ICLR, 2018. URL https://openreview. net/forum?id=rJl3yM-Ab.","This text block is a citation entry from a bibliography section, listing authors, title, conference, year, and URL.",,"((298.36297607421875, 1559.131448888889), (298.36297607421875, 1677.8797144444443), (1415.603515625, 1677.8797144444443), (1415.603515625, 1559.131448888889))",application/pdf,['eng'],15,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.938764274,,,,,,88cf03e04d37151d23b6814db7000177
187,ListItem,,Bibliography,,"[64] Jason Weston, Sumit Chopra, and Antoine Bordes. Memory networks. In Yoshua Bengio and Yann LeCun, editors, 3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings, 2015. URL http://arxiv.org/abs/1410.3916.",,,"((299.4870910644531, 1708.1120044444442), (299.4870910644531, 1826.86027), (1414.4901123046875, 1826.86027), (1414.4901123046875, 1708.1120044444442))",application/pdf,['eng'],15,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.942630529,,,,,,229576ddb7089034a78b93abe0f7f446
188,ListItem,Bibliography,Bibliography,TRUE,"[65] Jason Weston, Emily Dinan, and Alexander Miller. Retrieve and reﬁne: Improved sequence generation models for dialogue. In Proceedings of the 2018 EMNLP Workshop SCAI: The 2nd International Workshop on Search-Oriented Conversational AI, pages 87–92, Brussels, Belgium, October 2018. Association for Computational Linguistics. doi: 10.18653/v1/W18-5713. URL https://www.aclweb.org/anthology/W18-5713.","This text block is a bibliographic citation for a paper presented at the 2018 EMNLP Workshop SCAI, including details such as authors, title, publication venue, pages, location, date, publisher, DOI, and URL.",,"((299.7644958496094, 1857.09256), (299.7644958496094, 2006.1436033333332), (1417.6087646484375, 2006.1436033333332), (1417.6087646484375, 1857.09256))",application/pdf,['eng'],15,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.934974909,,,,,,cff038423400db9ec136e598c4f6fe9b
189,Footer,UncategorizedText,UncategorizedText,FALSE,15,The text '15' does not provide enough context or information to be classified into any specific category.,,"((836.1638888888889, 2061.325893333333), (836.1638888888889, 2088.999782222222), (864.3115844726562, 2088.999782222222), (864.3115844726562, 2061.325893333333))",application/pdf,['eng'],15,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.723661244,,,,,,383982974a51825d2ab922ddc6644236
190,ListItem,Bibliography,Bibliography,TRUE,"[66] Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, and Alexander M. Rush. Huggingface’s transformers: State-of-the-art natural language processing. ArXiv, abs/1910.03771, 2019.",This text block is a bibliographic citation for a paper titled 'Huggingface’s transformers: State-of-the-art natural language processing' authored by multiple individuals and published on ArXiv in 2019.,,"((296.787841796875, 205.97867111111094), (296.787841796875, 354.86367111111133), (1417.551025390625, 354.86367111111133), (1417.551025390625, 205.97867111111094))",application/pdf,['eng'],16,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.940019906,,,,,,e58e59972c7de8f30452d0fbf2b4d63a
191,ListItem,Bibliography,Bibliography,TRUE,"[67] Shiyue Zhang and Mohit Bansal. Addressing semantic drift in question generation for semi- supervised question answering. In Proceedings of the 2019 Conference on Empirical Meth- ods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 2495–2509, Hong Kong, China, Novem- ber 2019. Association for Computational Linguistics. doi: 10.18653/v1/D19-1253. URL https://www.aclweb.org/anthology/D19-1253.","This text block is a bibliographic citation for a paper by Shiyue Zhang and Mohit Bansal, presented at the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing.",,"((298.005615234375, 379.63144888888866), (298.005615234375, 558.9880477777778), (1414.4412841796875, 558.9880477777778), (1414.4412841796875, 379.63144888888866))",application/pdf,['eng'],16,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.949857533,,,,,,4e598272fd40d2d6e2d1324be5b9b4ed
192,ListItem,Bibliography,Bibliography,TRUE,"[68] Wanjun Zhong, Jingjing Xu, Duyu Tang, Zenan Xu, Nan Duan, Ming Zhou, Jiahai Wang, and Jian Yin. Reasoning over semantic-level graph for fact checking. ArXiv, abs/1909.03745, 2019. URL https://arxiv.org/abs/1909.03745.","This text block is a bibliographic citation of an academic paper, including the authors, title, publication venue, and URL.",,"((300.0, 583.5897822222222), (300.0, 672.03527), (1416.34521484375, 672.03527), (1416.34521484375, 583.5897822222222))",application/pdf,['eng'],16,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.935450435,,,,,,4cf897485e9488d23d33f61638dd8616
193,Header,UncategorizedText,UncategorizedText,FALSE,16,The text '16' does not provide enough context or information to be classified into any specific category.,,"((836.1638888888889, 2061.325893333333), (836.1638888888889, 2088.999782222222), (864.7047119140625, 2088.999782222222), (864.7047119140625, 2061.325893333333))",application/pdf,['eng'],16,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.629420161,,,,,,af75d356c9ff314f5607256f0d46f445
194,Title,Title,Title,TRUE,Appendices for Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks,The text is a title for appendices related to Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.,,"((431.43333333333334, 195.51560166666647), (431.43333333333334, 280.56049777777775), (1281.2685546875, 280.56049777777775), (1281.2685546875, 195.51560166666647))",application/pdf,['eng'],17,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.683530033,af75d356c9ff314f5607256f0d46f445,,,,,6365630c787ea226d5538c50fd0c7fea
195,Title,,Title,,A Implementation Details,,,"((297.7856750488281, 344.9512133333333), (297.7856750488281, 378.1601022222222), (691.1458740234375, 378.1601022222222), (691.1458740234375, 344.9512133333333))",application/pdf,['eng'],17,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.869279861,af75d356c9ff314f5607256f0d46f445,,,,,1f1bcb40f670bfb6dd159f69bb4acc24
196,NarrativeText,NarrativeText,NarrativeText,TRUE,"For Open-domain QA we report test numbers using 15 retrieved documents for RAG-Token models. For RAG-Sequence models, we report test results using 50 retrieved documents, and we use the Thorough Decoding approach since answers are generally short. We use greedy decoding for QA as we did not ﬁnd beam search improved results. For Open-MSMarco and Jeopardy question generation, we report test numbers using ten retrieved documents for both RAG-Token and RAG-Sequence, and we also train a BART-large model as a baseline. We use a beam size of four, and use the Fast Decoding approach for RAG-Sequence models, as Thorough Decoding did not improve performance.","The text block provides detailed information about the evaluation methodology for Open-domain QA, Open-MSMarco, and Jeopardy question generation using RAG-Token and RAG-Sequence models. It includes specifics on the number of retrieved documents, decoding approaches, and baseline models used.",,"((299.0027777777778, 414.2481155555556), (299.0027777777778, 623.7386711111112), (1409.736328125, 623.7386711111112), (1409.736328125, 414.2481155555556))",application/pdf,['eng'],17,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.948492527,1f1bcb40f670bfb6dd159f69bb4acc24,,,,,a4921fa230223ebf9c410ec23f89ffcd
197,Title,Title,Title,TRUE,B Human Evaluation,"The text 'B Human Evaluation' appears to be a title or heading, likely indicating a section or subsection of a document related to human evaluation.",,"((297.7243957519531, 671.231768888889), (297.7243957519531, 704.4406577777778), (627.048828125, 704.4406577777778), (627.048828125, 671.231768888889))",application/pdf,['eng'],17,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.801856756,af75d356c9ff314f5607256f0d46f445,,,,,729003d230149df3fce4b13d24b4c43b
198,Image,,,,"View full instructions Which sentence is more factually true? View tool guide Select an option Subject : Hemingway P Note: Some questions are Sentence Aismore 1 control questions. We reqire Sentence A : “The Sun Also Rises” s a novel by this author of 'A true good accuracy on our control Farewell to Arms” Sentence Bismore 2 questions to accept true responses. Sentence B : This author of ""The Sun Also Rises"" was bom in Both sentences are 8 Havana, Cubs, the son of Spanish immigrants true Indicate which one of the P < following sentences is more Both sentences are factually true with respect to completely untrue the subject. Using the internet to check whether the sentences are true is encouraged.",,,"((300.0, 751.0743055555555), (300.0, 1172.5555555555554), (1400.0140277777778, 1172.5555555555554), (1400.0140277777778, 751.0743055555555))",application/pdf,['eng'],17,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,,,./images/Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf/figure-17-5.jpg,,,,7f955f3f059713d13ba3431922717227
199,NarrativeText,,FigureCaption,,"Figure 4: Annotation interface for human evaluation of factuality. A pop-out for detailed instructions and a worked example appear when clicking ""view tool guide"".",,,"((297.7723388671875, 1191.44256), (297.7723388671875, 1249.4220044444444), (1403.66748046875, 1249.4220044444444), (1403.66748046875, 1191.44256))",application/pdf,['eng'],17,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.93634218,,,,,,a948740d13bcce55d19d5c7abbfc39bc
200,NarrativeText,NarrativeText,NarrativeText,TRUE,"Figure 4 shows the user interface for human evaluation. To avoid any biases for screen position, which model corresponded to sentence A and sentence B was randomly selected for each example. Annotators were encouraged to research the topic using the internet, and were given detailed instruc- tions and worked examples in a full instructions tab. We included some gold sentences in order to assess the accuracy of the annotators. Two annotators did not perform well on these examples and their annotations were removed from the results.","The text describes the user interface for human evaluation, including measures to avoid bias, instructions for annotators, and the removal of annotations from underperforming annotators.",,"((299.0027777777778, 1294.7231155555555), (299.0027777777778, 1473.9108933333334), (1407.0882568359375, 1473.9108933333334), (1407.0882568359375, 1294.7231155555555))",application/pdf,['eng'],17,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.947598934,,,,,,104977db7eaf622f65db17dabee6026d
201,Title,Title,Title,TRUE,C Training setup Details,"The text 'C Training setup Details' appears to be a sectional heading or title, likely indicating a section of a document that provides details about the training setup.",,"((297.3269348144531, 1521.403991111111), (297.3269348144531, 1554.61288), (673.4508056640625, 1554.61288), (673.4508056640625, 1521.403991111111))",application/pdf,['eng'],17,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.897296906,,,,,,3dafc9831434cc496911183d3443f954
202,NarrativeText,NarrativeText,NarrativeText,TRUE,"We train all RAG models and BART baselines using Fairseq [45].2 We train with mixed precision ﬂoating point arithmetic [40], distributing training across 8, 32GB NVIDIA V100 GPUs, though training and inference can be run on one GPU. We ﬁnd that doing Maximum Inner Product Search with FAISS is sufﬁciently fast on CPU, so we store document index vectors on CPU, requiring ∼ 100 GB of CPU memory for all of Wikipedia. After submission, We have ported our code to HuggingFace Transformers [66]3, which achieves equivalent performance to the previous version but is a cleaner and easier to use implementation. This version is also open-sourced. We also compress the document index using FAISS’s compression tools, reducing the CPU memory requirement to 36GB. Scripts to run experiments with RAG can be found at https://github.com/huggingface/transformers/ blob/master/examples/rag/README.md and an interactive demo of a RAG model can be found at https://huggingface.co/rag/","The text describes the training setup and implementation details for RAG models and BART baselines, including the use of Fairseq, mixed precision floating point arithmetic, and FAISS for document indexing. It also mentions the porting of the code to HuggingFace Transformers and provides links to scripts and an interactive demo.",,"((298.7, 1587.165391111111), (298.7, 1921.5686033333332), (1406.955810546875, 1921.5686033333332), (1406.955810546875, 1587.165391111111))",application/pdf,['eng'],17,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.950214505,3dafc9831434cc496911183d3443f954,,,,,178294825a0a78d90fb079256868245e
203,NarrativeText,,Bibliography,,2https://github.com/pytorch/fairseq 3https://github.com/huggingface/transformers,,,"((332.56268310546875, 1946.2598933333331), (332.56268310546875, 2005.5292799999997), (925.1810302734375, 2005.5292799999997), (925.1810302734375, 1946.2598933333331))",application/pdf,['eng'],17,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.659904838,3dafc9831434cc496911183d3443f954,,,,,ce99fc3442528bdb6e92015f123aa219
204,Footer,UncategorizedText,UncategorizedText,FALSE,17,The text '17' does not provide enough context or information to be classified into any specific category.,,"((836.1638888888889, 2061.325893333333), (836.1638888888889, 2088.999782222222), (864.5515747070312, 2088.999782222222), (864.5515747070312, 2061.325893333333))",application/pdf,['eng'],17,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.640131235,,,,,,ff4feac62f9cb8f3f80d493839da54f4
205,Title,Title,Title,TRUE,D Further Details on Open-Domain QA,"This text block serves as a sectional heading, likely for a subsection providing further details on open-domain question answering.",,"((299.7496337890625, 201.40676888888876), (299.7496337890625, 234.61565777777764), (888.1438598632812, 234.61565777777764), (888.1438598632812, 201.40676888888876))",application/pdf,['eng'],18,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.922058463,,,,,,743e0c97d50217549789e52c6410d1c3
206,NarrativeText,NarrativeText,NarrativeText,TRUE,"For open-domain QA, multiple answer annotations are often available for a given question. These answer annotations are exploited by extractive models during training as typically all the answer annotations are used to ﬁnd matches within documents when preparing training data. For RAG, we also make use of multiple annotation examples for Natural Questions and WebQuestions by training the model with each (q, a) pair separately, leading to a small increase in accuracy. For TriviaQA, there are often many valid answers to a given question, some of which are not suitable training targets, such as emoji or spelling variants. For TriviaQA, we ﬁlter out answer candidates if they do not occur in top 1000 documents for the query.","The text discusses the use of multiple answer annotations in open-domain QA models, specifically mentioning how different datasets like Natural Questions, WebQuestions, and TriviaQA are handled during training to improve accuracy.",,"((300.0, 270.06755999999984), (300.0, 509.8636711111112), (1409.453857421875, 509.8636711111112), (1409.453857421875, 270.06755999999984))",application/pdf,['eng'],18,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.952280223,743e0c97d50217549789e52c6410d1c3,,,,,327ba7a3b0953581047a6630fa46685e
207,NarrativeText,NarrativeText,NarrativeText,TRUE,"CuratedTrec preprocessing The answers for CuratedTrec are given in the form of regular expres- sions, which has been suggested as a reason why it is unsuitable for answer-generation models [20]. To overcome this, we use a pre-processing step where we ﬁrst retrieve the top 1000 documents for each query, and use the answer that most frequently matches the regex pattern as the supervision target. If no matches are found, we resort to a simple heuristic: generate all possible permutations for each regex, replacing non-deterministic symbols in the regex nested tree structure with a whitespace.","The text describes a preprocessing method for the CuratedTrec dataset, where answers are given as regular expressions. It explains the steps taken to retrieve documents and generate answers that match the regex patterns.",,"((299.14166666666665, 546.0849538888889), (299.14166666666665, 725.4664488888889), (1412.5635986328125, 725.4664488888889), (1412.5635986328125, 546.0849538888889))",application/pdf,['eng'],18,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.945955276,743e0c97d50217549789e52c6410d1c3,,,,,3f3a7fd592a460b66e7321d298665b3d
208,NarrativeText,NarrativeText,NarrativeText,TRUE,"TriviaQA Evaluation setups The open-domain QA community customarily uses public develop- ment datasets as test datasets, as test data for QA datasets is often restricted and dedicated to reading compehension purposes. We report our results using the datasets splits used in DPR [26], which are consistent with common practice in Open-domain QA. For TriviaQA, this test dataset is the public TriviaQA Web Development split. Roberts et al. [52] used the TriviaQA ofﬁcial Wikipedia test set instead. Févry et al. [14] follow this convention in order to compare with Roberts et al. [52] (See appendix of [14]). We report results on both test sets to enable fair comparison to both approaches. We ﬁnd that our performance is much higher using the ofﬁcial Wiki test set, rather than the more conventional open-domain test set, which we attribute to the ofﬁcial Wiki test set questions being simpler to answer from Wikipedia.","The text discusses the evaluation setups for TriviaQA in the context of open-domain QA, comparing different test datasets and reporting results to enable fair comparison between approaches.",,"((298.7, 761.6905094444443), (298.7, 1062.2858933333332), (1411.473876953125, 1062.2858933333332), (1411.473876953125, 761.6905094444443))",application/pdf,['eng'],18,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.949837863,743e0c97d50217549789e52c6410d1c3,,,,,9929f91fe3ae745354ced6b82b064be2
209,Title,Title,Title,TRUE,E Further Details on FEVER,The text appears to be a title or heading for a section providing further details on FEVER.,,"((300.0, 1108.7956577777777), (300.0, 1142.0045466666666), (738.15808, 1142.0045466666666), (738.15808, 1108.7956577777777))",application/pdf,['eng'],18,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.920394361,,,,,,ab0d42fa1433ef05d1577c648123092a
210,NarrativeText,NarrativeText,NarrativeText,TRUE,"For FEVER classiﬁcation, we follow the practice from [32], and ﬁrst re-generate the claim, and then classify using the representation of the ﬁnal hidden state, before ﬁnally marginalizing across documents to obtain the class probabilities. The FEVER task traditionally has two sub-tasks. The ﬁrst is to classify the claim as either ""Supported"", ""Refuted"" or ""Not Enough Info"", which is the task we explore in the main paper. FEVER’s other sub-task involves extracting sentences from Wikipedia as evidence supporting the classiﬁcation prediction. As FEVER uses a different Wikipedia dump to us, directly tackling this task is not straightforward. We hope to address this in future work.","The text discusses the methodology for FEVER classification, including the process of re-generating claims, classifying them, and marginalizing across documents. It also mentions the two sub-tasks of the FEVER task: classifying claims and extracting supporting evidence from Wikipedia.",,"((299.0027777777778, 1177.4592266666666), (299.0027777777778, 1386.949782222222), (1411.2562255859375, 1386.949782222222), (1411.2562255859375, 1177.4592266666666))",application/pdf,['eng'],18,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.950925708,ab0d42fa1433ef05d1577c648123092a,,,,,19c039a20c25d6daa8af532cf6b258ca
211,Title,UncategorizedText,Title,FALSE,F Null Document Probabilities,The text 'F Null Document Probabilities' does not make sense by itself and does not clearly fit into any of the specified categories.,,"((298.1177062988281, 1433.4623244444444), (298.1177062988281, 1466.671213333333), (759.536865234375, 1466.671213333333), (759.536865234375, 1433.4623244444444))",application/pdf,['eng'],18,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.915513694,,,,,,7b94920f67bb7800a18a871e136b1ed0
212,NarrativeText,NarrativeText,NarrativeText,TRUE,"We experimented with adding ""Null document"" mechanism to RAG, similar to REALM [20] in order to model cases where no useful information could be retrieved for a given input. Here, if k documents were retrieved, we would additionally ""retrieve"" an empty document and predict a logit for the null document, before marginalizing over k + 1 predictions. We explored modelling this null document logit by learning (i) a document embedding for the null document, (ii) a static learnt bias term, or (iii) a neural network to predict the logit. We did not ﬁnd that these improved performance, so in the interests of simplicity, we omit them. For Open MS-MARCO, where useful retrieved documents cannot always be retrieved, we observe that the model learns to always retrieve a particular set of documents for questions that are less likely to beneﬁt from retrieval, suggesting that null document mechanisms may not be necessary for RAG.","The text discusses an experiment with adding a 'Null document' mechanism to RAG, similar to REALM, to handle cases where no useful information is retrieved. It explains the methods explored for modeling the null document logit and concludes that these methods did not improve performance, thus they were omitted for simplicity. It also notes observations from the Open MS-MARCO dataset regarding the retrieval of documents.",,"((298.7, 1502.1231155555556), (298.7, 1802.524782222222), (1408.9925537109375, 1802.524782222222), (1408.9925537109375, 1502.1231155555556))",application/pdf,['eng'],18,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.953433573,7b94920f67bb7800a18a871e136b1ed0,,,,,c378d3d42c4c1c2c80e0b2c3080bf78c
213,Title,Title,Title,TRUE,G Parameters,"The text 'G Parameters' appears to be a heading or title, likely indicating a section or subsection in a document.",,"((296.3894958496094, 1849.0345466666668), (296.3894958496094, 1882.2434355555556), (527.2184448242188, 1882.2434355555556), (527.2184448242188, 1849.0345466666668))",application/pdf,['eng'],18,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.900629699,,,,,,0a96175e8fd9c2d46b2be09b38f045d3
214,NarrativeText,NarrativeText,NarrativeText,TRUE,"Our RAG models contain the trainable parameters for the BERT-base query and document encoder of DPR, with 110M parameters each (although we do not train the document encoder ourselves) and 406M trainable parameters from BART-large, 406M parameters, making a total of 626M trainable","The text describes the trainable parameters of RAG models, including the BERT-base query and document encoder of DPR and BART-large, totaling 626M trainable parameters.",,"((298.3764343261719, 1917.6981155555554), (298.3764343261719, 2005.97756), (1409.25830078125, 2005.97756), (1409.25830078125, 1917.6981155555554))",application/pdf,['eng'],18,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.944669127,0a96175e8fd9c2d46b2be09b38f045d3,,,,,446e6e901781dca12a4bbf57b99b5e2a
215,Footer,UncategorizedText,UncategorizedText,FALSE,18,The text '18' does not provide enough context or information to be classified into any specific category.,,"((836.1638888888889, 2061.325893333333), (836.1638888888889, 2088.999782222222), (865.0907592773438, 2088.999782222222), (865.0907592773438, 2061.325893333333))",application/pdf,['eng'],18,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.760522485,,,,,,7510fd846b9d3578459aec4a9f5e9579
216,FigureCaption,FigureCaption,FigureCaption,TRUE,Table 7: Number of instances in the datasets used. *A hidden subset of this data is used for evaluation,"This text block is a caption for Table 7, indicating the number of instances in the datasets used and mentioning that a hidden subset of this data is used for evaluation.",,"((299.14166666666665, 218.8870044444444), (299.14166666666665, 246.56089333333347), (1399.9862740777774, 246.56089333333347), (1399.9862740777774, 218.8870044444444))",application/pdf,['eng'],19,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.878635406,,,,,,ee09fc019c02aecaa01e0485a0deb215
217,Table,,,,Task Train Development Test Natural Questions TriviaQA WebQuestions CuratedTrec Jeopardy Question Generation MS-MARCO FEVER-3-way FEVER-2-way 79169 78786 3418 635 97392 153726 145450 96966 8758 8838 362 134 13714 12468 10000 6666 3611 11314 2033 635 26849 101093* 10000 6666,,,"((484.2055358886719, 268.2554626464844), (484.2055358886719, 542.59326171875), (1221.9962158203125, 542.59326171875), (1221.9962158203125, 268.2554626464844))",application/pdf,['eng'],19,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.934923053,,./images/Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf/table-19-5.jpg,,,,00769717a3e087a8df85452c617ca67d
218,NarrativeText,NarrativeText,NarrativeText,TRUE,"parameters. The best performing ""closed-book"" (parametric only) open-domain QA model is T5-11B with 11 Billion trainable parameters. The T5 model with the closest number of parameters to our models is T5-large (770M parameters), which achieves a score of 28.9 EM on Natural Questions [52], substantially below the 44.5 that RAG-Sequence achieves, indicating that hybrid parametric/non- parametric models require far fewer trainable parameters for strong open-domain QA performance. The non-parametric memory index does not consist of trainable parameters, but does consists of 21M 728 dimensional vectors, consisting of 15.3B values. These can be easily be stored at 8-bit ﬂoating point precision to manage memory and disk footprints.","This text block discusses the performance of different open-domain QA models, comparing the T5-11B model with 11 billion parameters to the T5-large model with 770 million parameters. It highlights the efficiency of hybrid parametric/non-parametric models, specifically mentioning the RAG-Sequence model and its performance. The text also details the non-parametric memory index and its storage requirements.",,"((299.0027777777778, 605.8675599999999), (299.0027777777778, 845.6608933333332), (1407.8076171875, 845.6608933333332), (1407.8076171875, 605.8675599999999))",application/pdf,['eng'],19,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.949197888,,,,,,92275503f7c4d1704d9a92d4b08f2e88
219,Title,UncategorizedText,Title,FALSE,H Retrieval Collapse,The text 'H Retrieval Collapse' does not provide enough context or information to be classified into any specific category.,,"((297.9806823730469, 892.2873244444444), (297.9806823730469, 925.4962133333332), (622.2971801757812, 925.4962133333332), (622.2971801757812, 892.2873244444444))",application/pdf,['eng'],19,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.907250464,,,,,,8cc9db04a2f4cc220f257af592fffe8a
220,NarrativeText,NarrativeText,NarrativeText,TRUE,"In preliminary experiments, we observed that for some tasks such as story generation [11], the retrieval component would “collapse” and learn to retrieve the same documents regardless of the input. In these cases, once retrieval had collapsed, the generator would learn to ignore the documents, and the RAG model would perform equivalently to BART. The collapse could be due to a less-explicit requirement for factual knowledge in some tasks, or the longer target sequences, which could result in less informative gradients for the retriever. Perez et al. [46] also found spurious retrieval results when optimizing a retrieval component in order to improve performance on downstream tasks.","The text discusses the behavior of a retrieval component in preliminary experiments, particularly its tendency to 'collapse' and retrieve the same documents regardless of input in certain tasks like story generation. It also mentions the impact of this collapse on the generator and the overall model performance, comparing it to BART. Additionally, it references a study by Perez et al. that found similar issues with spurious retrieval results.",,"((299.0027777777778, 961.0620044444444), (299.0027777777778, 1170.5553377777776), (1409.17724609375, 1170.5553377777776), (1409.17724609375, 961.0620044444444))",application/pdf,['eng'],19,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.947708249,8cc9db04a2f4cc220f257af592fffe8a,,,,,2468b5236da66343df583c9d870c41f3
221,Title,Title,Title,TRUE,I Number of instances per dataset,This text block serves as a sectional heading indicating the number of instances per dataset.,,"((298.6259765625, 1217.178991111111), (298.6259765625, 1250.3878799999998), (805.666748046875, 1250.3878799999998), (805.666748046875, 1217.178991111111))",application/pdf,['eng'],19,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.911698043,,,,,,7f10efb85a3fe1e47acc1d058e6c9591
222,NarrativeText,FigureCaption,NarrativeText,TRUE,"The number of training, development and test datapoints in each of our datasets is shown in Table 7.","This text describes the contents of Table 7, which shows the number of training, development, and test datapoints in each dataset.",,"((299.14166666666665, 1285.9536711111111), (299.14166666666665, 1313.62756), (1395.6666259765625, 1313.62756), (1395.6666259765625, 1285.9536711111111))",application/pdf,['eng'],19,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.881190896,7f10efb85a3fe1e47acc1d058e6c9591,,,,,a3a2969e742677c71e137666dcca51ba
223,Header,UncategorizedText,UncategorizedText,FALSE,19,The text '19' does not provide enough context or information to be classified into any specific category.,,"((836.1638888888889, 2061.325893333333), (836.1638888888889, 2088.999782222222), (864.5360717773438, 2088.999782222222), (864.5360717773438, 2061.325893333333))",application/pdf,['eng'],19,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf,0.622305274,,,,,,80299957d63e5473aca4b1f6529f8263

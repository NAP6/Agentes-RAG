{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T21:32:58.343088Z",
     "start_time": "2024-09-05T21:32:58.335056Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Importante para usar llama Index en Jupyter Notebook\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n"
   ],
   "id": "2939f7ad5b8c974c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-05T21:33:06.339526Z",
     "start_time": "2024-09-05T21:32:58.690598Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from llama_index.core import VectorStoreIndex, Settings\n",
    "from llama_index.core.schema import Document, NodeRelationship, RelatedNodeInfo\n",
    "from GCP.lib.LlamaIndex_custom.VertexIEmbeddings import VertexIEmbeddings\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "from llama_index.core.node_parser import SemanticSplitterNodeParser\n",
    "from llama_index.core.extractors import QuestionsAnsweredExtractor\n",
    "from llama_index.llms.vertex import Vertex\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T21:33:06.384581Z",
     "start_time": "2024-09-05T21:33:06.368043Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(\n",
    "    './data/Metadata/Bloques_y_tablas_v2-Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.csv',\n",
    "    index_col=0)\n",
    "df"
   ],
   "id": "3eec9c26e5b9a0f7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        block_type                                               text  \\\n",
       "4     Author Names                     Patrick Lewis'?, Ethan Perez*,   \n",
       "5     Author Names  Aleksandra Piktus†, Fabio Petroni†, Vladimir K...   \n",
       "6     Author Names  Mike Lewis†, Wen-tau Yih†, Tim Rocktäschel†‡, ...   \n",
       "9    NarrativeText  Large pre-trained language models have been sh...   \n",
       "11   NarrativeText  Pre-trained neural language models have been s...   \n",
       "..             ...                                                ...   \n",
       "216  FigureCaption  Table 7: Number of instances in the datasets u...   \n",
       "217          Table  | Task | Train | Development | Test |\\r\\n|---|...   \n",
       "218  NarrativeText  parameters. The best performing \"closed-book\" ...   \n",
       "220  NarrativeText  In preliminary experiments, we observed that f...   \n",
       "222  NarrativeText  The number of training, development and test d...   \n",
       "\n",
       "           file_type languages  page_number  \\\n",
       "4    application/pdf   ['eng']            1   \n",
       "5    application/pdf   ['eng']            1   \n",
       "6    application/pdf   ['eng']            1   \n",
       "9    application/pdf   ['eng']            1   \n",
       "11   application/pdf   ['eng']            1   \n",
       "..               ...       ...          ...   \n",
       "216  application/pdf   ['eng']           19   \n",
       "217  application/pdf   ['eng']           19   \n",
       "218  application/pdf   ['eng']           19   \n",
       "220  application/pdf   ['eng']           19   \n",
       "222  application/pdf   ['eng']           19   \n",
       "\n",
       "                                              filename  \\\n",
       "4    Retrieval-Augmented Generation for Knowledge-I...   \n",
       "5    Retrieval-Augmented Generation for Knowledge-I...   \n",
       "6    Retrieval-Augmented Generation for Knowledge-I...   \n",
       "9    Retrieval-Augmented Generation for Knowledge-I...   \n",
       "11   Retrieval-Augmented Generation for Knowledge-I...   \n",
       "..                                                 ...   \n",
       "216  Retrieval-Augmented Generation for Knowledge-I...   \n",
       "217  Retrieval-Augmented Generation for Knowledge-I...   \n",
       "218  Retrieval-Augmented Generation for Knowledge-I...   \n",
       "220  Retrieval-Augmented Generation for Knowledge-I...   \n",
       "222  Retrieval-Augmented Generation for Knowledge-I...   \n",
       "\n",
       "                                           description  \\\n",
       "4    Lists the names of authors, potentially with a...   \n",
       "5    Lists the names of authors, potentially affili...   \n",
       "6             Lists the authors of the research paper.   \n",
       "9    This paragraph discusses the capabilities and ...   \n",
       "11   This block discusses the advantages and disadv...   \n",
       "..                                                 ...   \n",
       "216  Describes the content of Table 7, indicating t...   \n",
       "217  Table 7: Number of instances in the datasets u...   \n",
       "218  This block discusses the performance of differ...   \n",
       "220  This block discusses challenges encountered du...   \n",
       "222  This sentence describes the content of Table 7...   \n",
       "\n",
       "                                               authors  \\\n",
       "4    Patrick Lewis,Ethan Perez,Aleksandra Piktus,Fa...   \n",
       "5    Patrick Lewis,Ethan Perez,Aleksandra Piktus,Fa...   \n",
       "6    Patrick Lewis,Ethan Perez,Aleksandra Piktus,Fa...   \n",
       "9    Patrick Lewis,Ethan Perez,Aleksandra Piktus,Fa...   \n",
       "11   Patrick Lewis,Ethan Perez,Aleksandra Piktus,Fa...   \n",
       "..                                                 ...   \n",
       "216  Patrick Lewis,Ethan Perez,Aleksandra Piktus,Fa...   \n",
       "217  Patrick Lewis,Ethan Perez,Aleksandra Piktus,Fa...   \n",
       "218  Patrick Lewis,Ethan Perez,Aleksandra Piktus,Fa...   \n",
       "220  Patrick Lewis,Ethan Perez,Aleksandra Piktus,Fa...   \n",
       "222  Patrick Lewis,Ethan Perez,Aleksandra Piktus,Fa...   \n",
       "\n",
       "                                          research_lab  publication_year  \\\n",
       "4    Facebook AI Research,University College London...              2020   \n",
       "5    Facebook AI Research,University College London...              2020   \n",
       "6    Facebook AI Research,University College London...              2020   \n",
       "9    Facebook AI Research,University College London...              2020   \n",
       "11   Facebook AI Research,University College London...              2020   \n",
       "..                                                 ...               ...   \n",
       "216  Facebook AI Research,University College London...              2020   \n",
       "217  Facebook AI Research,University College London...              2020   \n",
       "218  Facebook AI Research,University College London...              2020   \n",
       "220  Facebook AI Research,University College London...              2020   \n",
       "222  Facebook AI Research,University College London...              2020   \n",
       "\n",
       "                                                 title  \\\n",
       "4    Retrieval-Augmented Generation for Knowledge-I...   \n",
       "5    Retrieval-Augmented Generation for Knowledge-I...   \n",
       "6    Retrieval-Augmented Generation for Knowledge-I...   \n",
       "9    Retrieval-Augmented Generation for Knowledge-I...   \n",
       "11   Retrieval-Augmented Generation for Knowledge-I...   \n",
       "..                                                 ...   \n",
       "216  Retrieval-Augmented Generation for Knowledge-I...   \n",
       "217  Retrieval-Augmented Generation for Knowledge-I...   \n",
       "218  Retrieval-Augmented Generation for Knowledge-I...   \n",
       "220  Retrieval-Augmented Generation for Knowledge-I...   \n",
       "222  Retrieval-Augmented Generation for Knowledge-I...   \n",
       "\n",
       "                                         section_title  \n",
       "4    Retrieval-Augmented Generation for Knowledge-I...  \n",
       "5    Retrieval-Augmented Generation for Knowledge-I...  \n",
       "6    Retrieval-Augmented Generation for Knowledge-I...  \n",
       "9                                             Abstract  \n",
       "11                                      1 Introduction  \n",
       "..                                                 ...  \n",
       "216                                       G Parameters  \n",
       "217                                       G Parameters  \n",
       "218                                       G Parameters  \n",
       "220                               H Retrieval Collapse  \n",
       "222                  I Number of instances per dataset  \n",
       "\n",
       "[159 rows x 12 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>block_type</th>\n",
       "      <th>text</th>\n",
       "      <th>file_type</th>\n",
       "      <th>languages</th>\n",
       "      <th>page_number</th>\n",
       "      <th>filename</th>\n",
       "      <th>description</th>\n",
       "      <th>authors</th>\n",
       "      <th>research_lab</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>title</th>\n",
       "      <th>section_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Author Names</td>\n",
       "      <td>Patrick Lewis'?, Ethan Perez*,</td>\n",
       "      <td>application/pdf</td>\n",
       "      <td>['eng']</td>\n",
       "      <td>1</td>\n",
       "      <td>Retrieval-Augmented Generation for Knowledge-I...</td>\n",
       "      <td>Lists the names of authors, potentially with a...</td>\n",
       "      <td>Patrick Lewis,Ethan Perez,Aleksandra Piktus,Fa...</td>\n",
       "      <td>Facebook AI Research,University College London...</td>\n",
       "      <td>2020</td>\n",
       "      <td>Retrieval-Augmented Generation for Knowledge-I...</td>\n",
       "      <td>Retrieval-Augmented Generation for Knowledge-I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Author Names</td>\n",
       "      <td>Aleksandra Piktus†, Fabio Petroni†, Vladimir K...</td>\n",
       "      <td>application/pdf</td>\n",
       "      <td>['eng']</td>\n",
       "      <td>1</td>\n",
       "      <td>Retrieval-Augmented Generation for Knowledge-I...</td>\n",
       "      <td>Lists the names of authors, potentially affili...</td>\n",
       "      <td>Patrick Lewis,Ethan Perez,Aleksandra Piktus,Fa...</td>\n",
       "      <td>Facebook AI Research,University College London...</td>\n",
       "      <td>2020</td>\n",
       "      <td>Retrieval-Augmented Generation for Knowledge-I...</td>\n",
       "      <td>Retrieval-Augmented Generation for Knowledge-I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Author Names</td>\n",
       "      <td>Mike Lewis†, Wen-tau Yih†, Tim Rocktäschel†‡, ...</td>\n",
       "      <td>application/pdf</td>\n",
       "      <td>['eng']</td>\n",
       "      <td>1</td>\n",
       "      <td>Retrieval-Augmented Generation for Knowledge-I...</td>\n",
       "      <td>Lists the authors of the research paper.</td>\n",
       "      <td>Patrick Lewis,Ethan Perez,Aleksandra Piktus,Fa...</td>\n",
       "      <td>Facebook AI Research,University College London...</td>\n",
       "      <td>2020</td>\n",
       "      <td>Retrieval-Augmented Generation for Knowledge-I...</td>\n",
       "      <td>Retrieval-Augmented Generation for Knowledge-I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NarrativeText</td>\n",
       "      <td>Large pre-trained language models have been sh...</td>\n",
       "      <td>application/pdf</td>\n",
       "      <td>['eng']</td>\n",
       "      <td>1</td>\n",
       "      <td>Retrieval-Augmented Generation for Knowledge-I...</td>\n",
       "      <td>This paragraph discusses the capabilities and ...</td>\n",
       "      <td>Patrick Lewis,Ethan Perez,Aleksandra Piktus,Fa...</td>\n",
       "      <td>Facebook AI Research,University College London...</td>\n",
       "      <td>2020</td>\n",
       "      <td>Retrieval-Augmented Generation for Knowledge-I...</td>\n",
       "      <td>Abstract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NarrativeText</td>\n",
       "      <td>Pre-trained neural language models have been s...</td>\n",
       "      <td>application/pdf</td>\n",
       "      <td>['eng']</td>\n",
       "      <td>1</td>\n",
       "      <td>Retrieval-Augmented Generation for Knowledge-I...</td>\n",
       "      <td>This block discusses the advantages and disadv...</td>\n",
       "      <td>Patrick Lewis,Ethan Perez,Aleksandra Piktus,Fa...</td>\n",
       "      <td>Facebook AI Research,University College London...</td>\n",
       "      <td>2020</td>\n",
       "      <td>Retrieval-Augmented Generation for Knowledge-I...</td>\n",
       "      <td>1 Introduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>FigureCaption</td>\n",
       "      <td>Table 7: Number of instances in the datasets u...</td>\n",
       "      <td>application/pdf</td>\n",
       "      <td>['eng']</td>\n",
       "      <td>19</td>\n",
       "      <td>Retrieval-Augmented Generation for Knowledge-I...</td>\n",
       "      <td>Describes the content of Table 7, indicating t...</td>\n",
       "      <td>Patrick Lewis,Ethan Perez,Aleksandra Piktus,Fa...</td>\n",
       "      <td>Facebook AI Research,University College London...</td>\n",
       "      <td>2020</td>\n",
       "      <td>Retrieval-Augmented Generation for Knowledge-I...</td>\n",
       "      <td>G Parameters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>Table</td>\n",
       "      <td>| Task | Train | Development | Test |\\r\\n|---|...</td>\n",
       "      <td>application/pdf</td>\n",
       "      <td>['eng']</td>\n",
       "      <td>19</td>\n",
       "      <td>Retrieval-Augmented Generation for Knowledge-I...</td>\n",
       "      <td>Table 7: Number of instances in the datasets u...</td>\n",
       "      <td>Patrick Lewis,Ethan Perez,Aleksandra Piktus,Fa...</td>\n",
       "      <td>Facebook AI Research,University College London...</td>\n",
       "      <td>2020</td>\n",
       "      <td>Retrieval-Augmented Generation for Knowledge-I...</td>\n",
       "      <td>G Parameters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>NarrativeText</td>\n",
       "      <td>parameters. The best performing \"closed-book\" ...</td>\n",
       "      <td>application/pdf</td>\n",
       "      <td>['eng']</td>\n",
       "      <td>19</td>\n",
       "      <td>Retrieval-Augmented Generation for Knowledge-I...</td>\n",
       "      <td>This block discusses the performance of differ...</td>\n",
       "      <td>Patrick Lewis,Ethan Perez,Aleksandra Piktus,Fa...</td>\n",
       "      <td>Facebook AI Research,University College London...</td>\n",
       "      <td>2020</td>\n",
       "      <td>Retrieval-Augmented Generation for Knowledge-I...</td>\n",
       "      <td>G Parameters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>NarrativeText</td>\n",
       "      <td>In preliminary experiments, we observed that f...</td>\n",
       "      <td>application/pdf</td>\n",
       "      <td>['eng']</td>\n",
       "      <td>19</td>\n",
       "      <td>Retrieval-Augmented Generation for Knowledge-I...</td>\n",
       "      <td>This block discusses challenges encountered du...</td>\n",
       "      <td>Patrick Lewis,Ethan Perez,Aleksandra Piktus,Fa...</td>\n",
       "      <td>Facebook AI Research,University College London...</td>\n",
       "      <td>2020</td>\n",
       "      <td>Retrieval-Augmented Generation for Knowledge-I...</td>\n",
       "      <td>H Retrieval Collapse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>NarrativeText</td>\n",
       "      <td>The number of training, development and test d...</td>\n",
       "      <td>application/pdf</td>\n",
       "      <td>['eng']</td>\n",
       "      <td>19</td>\n",
       "      <td>Retrieval-Augmented Generation for Knowledge-I...</td>\n",
       "      <td>This sentence describes the content of Table 7...</td>\n",
       "      <td>Patrick Lewis,Ethan Perez,Aleksandra Piktus,Fa...</td>\n",
       "      <td>Facebook AI Research,University College London...</td>\n",
       "      <td>2020</td>\n",
       "      <td>Retrieval-Augmented Generation for Knowledge-I...</td>\n",
       "      <td>I Number of instances per dataset</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159 rows × 12 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T21:33:06.403402Z",
     "start_time": "2024-09-05T21:33:06.386093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Crear el ID utilizando el índice y el nombre del archivo\n",
    "df['node_id'] = df.apply(lambda row: f\"{row.name}_{row['filename']}\", axis=1)\n",
    "\n",
    "# Crear la columna 'previous_node_id' desplazando el ID hacia abajo\n",
    "df['previous_node_id'] = df['node_id'].shift(1)\n",
    "\n",
    "# Crear la columna 'next_node_id' desplazando el ID hacia arriba\n",
    "df['next_node_id'] = df['node_id'].shift(-1)\n",
    "\n",
    "df"
   ],
   "id": "9d3946569757af86",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        block_type                                               text  \\\n",
       "4     Author Names                     Patrick Lewis'?, Ethan Perez*,   \n",
       "5     Author Names  Aleksandra Piktus†, Fabio Petroni†, Vladimir K...   \n",
       "6     Author Names  Mike Lewis†, Wen-tau Yih†, Tim Rocktäschel†‡, ...   \n",
       "9    NarrativeText  Large pre-trained language models have been sh...   \n",
       "11   NarrativeText  Pre-trained neural language models have been s...   \n",
       "..             ...                                                ...   \n",
       "216  FigureCaption  Table 7: Number of instances in the datasets u...   \n",
       "217          Table  | Task | Train | Development | Test |\\r\\n|---|...   \n",
       "218  NarrativeText  parameters. The best performing \"closed-book\" ...   \n",
       "220  NarrativeText  In preliminary experiments, we observed that f...   \n",
       "222  NarrativeText  The number of training, development and test d...   \n",
       "\n",
       "           file_type languages  page_number  \\\n",
       "4    application/pdf   ['eng']            1   \n",
       "5    application/pdf   ['eng']            1   \n",
       "6    application/pdf   ['eng']            1   \n",
       "9    application/pdf   ['eng']            1   \n",
       "11   application/pdf   ['eng']            1   \n",
       "..               ...       ...          ...   \n",
       "216  application/pdf   ['eng']           19   \n",
       "217  application/pdf   ['eng']           19   \n",
       "218  application/pdf   ['eng']           19   \n",
       "220  application/pdf   ['eng']           19   \n",
       "222  application/pdf   ['eng']           19   \n",
       "\n",
       "                                              filename  \\\n",
       "4    Retrieval-Augmented Generation for Knowledge-I...   \n",
       "5    Retrieval-Augmented Generation for Knowledge-I...   \n",
       "6    Retrieval-Augmented Generation for Knowledge-I...   \n",
       "9    Retrieval-Augmented Generation for Knowledge-I...   \n",
       "11   Retrieval-Augmented Generation for Knowledge-I...   \n",
       "..                                                 ...   \n",
       "216  Retrieval-Augmented Generation for Knowledge-I...   \n",
       "217  Retrieval-Augmented Generation for Knowledge-I...   \n",
       "218  Retrieval-Augmented Generation for Knowledge-I...   \n",
       "220  Retrieval-Augmented Generation for Knowledge-I...   \n",
       "222  Retrieval-Augmented Generation for Knowledge-I...   \n",
       "\n",
       "                                           description  \\\n",
       "4    Lists the names of authors, potentially with a...   \n",
       "5    Lists the names of authors, potentially affili...   \n",
       "6             Lists the authors of the research paper.   \n",
       "9    This paragraph discusses the capabilities and ...   \n",
       "11   This block discusses the advantages and disadv...   \n",
       "..                                                 ...   \n",
       "216  Describes the content of Table 7, indicating t...   \n",
       "217  Table 7: Number of instances in the datasets u...   \n",
       "218  This block discusses the performance of differ...   \n",
       "220  This block discusses challenges encountered du...   \n",
       "222  This sentence describes the content of Table 7...   \n",
       "\n",
       "                                               authors  \\\n",
       "4    Patrick Lewis,Ethan Perez,Aleksandra Piktus,Fa...   \n",
       "5    Patrick Lewis,Ethan Perez,Aleksandra Piktus,Fa...   \n",
       "6    Patrick Lewis,Ethan Perez,Aleksandra Piktus,Fa...   \n",
       "9    Patrick Lewis,Ethan Perez,Aleksandra Piktus,Fa...   \n",
       "11   Patrick Lewis,Ethan Perez,Aleksandra Piktus,Fa...   \n",
       "..                                                 ...   \n",
       "216  Patrick Lewis,Ethan Perez,Aleksandra Piktus,Fa...   \n",
       "217  Patrick Lewis,Ethan Perez,Aleksandra Piktus,Fa...   \n",
       "218  Patrick Lewis,Ethan Perez,Aleksandra Piktus,Fa...   \n",
       "220  Patrick Lewis,Ethan Perez,Aleksandra Piktus,Fa...   \n",
       "222  Patrick Lewis,Ethan Perez,Aleksandra Piktus,Fa...   \n",
       "\n",
       "                                          research_lab  publication_year  \\\n",
       "4    Facebook AI Research,University College London...              2020   \n",
       "5    Facebook AI Research,University College London...              2020   \n",
       "6    Facebook AI Research,University College London...              2020   \n",
       "9    Facebook AI Research,University College London...              2020   \n",
       "11   Facebook AI Research,University College London...              2020   \n",
       "..                                                 ...               ...   \n",
       "216  Facebook AI Research,University College London...              2020   \n",
       "217  Facebook AI Research,University College London...              2020   \n",
       "218  Facebook AI Research,University College London...              2020   \n",
       "220  Facebook AI Research,University College London...              2020   \n",
       "222  Facebook AI Research,University College London...              2020   \n",
       "\n",
       "                                                 title  \\\n",
       "4    Retrieval-Augmented Generation for Knowledge-I...   \n",
       "5    Retrieval-Augmented Generation for Knowledge-I...   \n",
       "6    Retrieval-Augmented Generation for Knowledge-I...   \n",
       "9    Retrieval-Augmented Generation for Knowledge-I...   \n",
       "11   Retrieval-Augmented Generation for Knowledge-I...   \n",
       "..                                                 ...   \n",
       "216  Retrieval-Augmented Generation for Knowledge-I...   \n",
       "217  Retrieval-Augmented Generation for Knowledge-I...   \n",
       "218  Retrieval-Augmented Generation for Knowledge-I...   \n",
       "220  Retrieval-Augmented Generation for Knowledge-I...   \n",
       "222  Retrieval-Augmented Generation for Knowledge-I...   \n",
       "\n",
       "                                         section_title  \\\n",
       "4    Retrieval-Augmented Generation for Knowledge-I...   \n",
       "5    Retrieval-Augmented Generation for Knowledge-I...   \n",
       "6    Retrieval-Augmented Generation for Knowledge-I...   \n",
       "9                                             Abstract   \n",
       "11                                      1 Introduction   \n",
       "..                                                 ...   \n",
       "216                                       G Parameters   \n",
       "217                                       G Parameters   \n",
       "218                                       G Parameters   \n",
       "220                               H Retrieval Collapse   \n",
       "222                  I Number of instances per dataset   \n",
       "\n",
       "                                               node_id  \\\n",
       "4    4_Retrieval-Augmented Generation for Knowledge...   \n",
       "5    5_Retrieval-Augmented Generation for Knowledge...   \n",
       "6    6_Retrieval-Augmented Generation for Knowledge...   \n",
       "9    9_Retrieval-Augmented Generation for Knowledge...   \n",
       "11   11_Retrieval-Augmented Generation for Knowledg...   \n",
       "..                                                 ...   \n",
       "216  216_Retrieval-Augmented Generation for Knowled...   \n",
       "217  217_Retrieval-Augmented Generation for Knowled...   \n",
       "218  218_Retrieval-Augmented Generation for Knowled...   \n",
       "220  220_Retrieval-Augmented Generation for Knowled...   \n",
       "222  222_Retrieval-Augmented Generation for Knowled...   \n",
       "\n",
       "                                      previous_node_id  \\\n",
       "4                                                 None   \n",
       "5    4_Retrieval-Augmented Generation for Knowledge...   \n",
       "6    5_Retrieval-Augmented Generation for Knowledge...   \n",
       "9    6_Retrieval-Augmented Generation for Knowledge...   \n",
       "11   9_Retrieval-Augmented Generation for Knowledge...   \n",
       "..                                                 ...   \n",
       "216  214_Retrieval-Augmented Generation for Knowled...   \n",
       "217  216_Retrieval-Augmented Generation for Knowled...   \n",
       "218  217_Retrieval-Augmented Generation for Knowled...   \n",
       "220  218_Retrieval-Augmented Generation for Knowled...   \n",
       "222  220_Retrieval-Augmented Generation for Knowled...   \n",
       "\n",
       "                                          next_node_id  \n",
       "4    5_Retrieval-Augmented Generation for Knowledge...  \n",
       "5    6_Retrieval-Augmented Generation for Knowledge...  \n",
       "6    9_Retrieval-Augmented Generation for Knowledge...  \n",
       "9    11_Retrieval-Augmented Generation for Knowledg...  \n",
       "11   12_Retrieval-Augmented Generation for Knowledg...  \n",
       "..                                                 ...  \n",
       "216  217_Retrieval-Augmented Generation for Knowled...  \n",
       "217  218_Retrieval-Augmented Generation for Knowled...  \n",
       "218  220_Retrieval-Augmented Generation for Knowled...  \n",
       "220  222_Retrieval-Augmented Generation for Knowled...  \n",
       "222                                               None  \n",
       "\n",
       "[159 rows x 15 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>block_type</th>\n",
       "      <th>text</th>\n",
       "      <th>file_type</th>\n",
       "      <th>languages</th>\n",
       "      <th>page_number</th>\n",
       "      <th>filename</th>\n",
       "      <th>description</th>\n",
       "      <th>authors</th>\n",
       "      <th>research_lab</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>title</th>\n",
       "      <th>section_title</th>\n",
       "      <th>node_id</th>\n",
       "      <th>previous_node_id</th>\n",
       "      <th>next_node_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Author Names</td>\n",
       "      <td>Patrick Lewis'?, Ethan Perez*,</td>\n",
       "      <td>application/pdf</td>\n",
       "      <td>['eng']</td>\n",
       "      <td>1</td>\n",
       "      <td>Retrieval-Augmented Generation for Knowledge-I...</td>\n",
       "      <td>Lists the names of authors, potentially with a...</td>\n",
       "      <td>Patrick Lewis,Ethan Perez,Aleksandra Piktus,Fa...</td>\n",
       "      <td>Facebook AI Research,University College London...</td>\n",
       "      <td>2020</td>\n",
       "      <td>Retrieval-Augmented Generation for Knowledge-I...</td>\n",
       "      <td>Retrieval-Augmented Generation for Knowledge-I...</td>\n",
       "      <td>4_Retrieval-Augmented Generation for Knowledge...</td>\n",
       "      <td>None</td>\n",
       "      <td>5_Retrieval-Augmented Generation for Knowledge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Author Names</td>\n",
       "      <td>Aleksandra Piktus†, Fabio Petroni†, Vladimir K...</td>\n",
       "      <td>application/pdf</td>\n",
       "      <td>['eng']</td>\n",
       "      <td>1</td>\n",
       "      <td>Retrieval-Augmented Generation for Knowledge-I...</td>\n",
       "      <td>Lists the names of authors, potentially affili...</td>\n",
       "      <td>Patrick Lewis,Ethan Perez,Aleksandra Piktus,Fa...</td>\n",
       "      <td>Facebook AI Research,University College London...</td>\n",
       "      <td>2020</td>\n",
       "      <td>Retrieval-Augmented Generation for Knowledge-I...</td>\n",
       "      <td>Retrieval-Augmented Generation for Knowledge-I...</td>\n",
       "      <td>5_Retrieval-Augmented Generation for Knowledge...</td>\n",
       "      <td>4_Retrieval-Augmented Generation for Knowledge...</td>\n",
       "      <td>6_Retrieval-Augmented Generation for Knowledge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Author Names</td>\n",
       "      <td>Mike Lewis†, Wen-tau Yih†, Tim Rocktäschel†‡, ...</td>\n",
       "      <td>application/pdf</td>\n",
       "      <td>['eng']</td>\n",
       "      <td>1</td>\n",
       "      <td>Retrieval-Augmented Generation for Knowledge-I...</td>\n",
       "      <td>Lists the authors of the research paper.</td>\n",
       "      <td>Patrick Lewis,Ethan Perez,Aleksandra Piktus,Fa...</td>\n",
       "      <td>Facebook AI Research,University College London...</td>\n",
       "      <td>2020</td>\n",
       "      <td>Retrieval-Augmented Generation for Knowledge-I...</td>\n",
       "      <td>Retrieval-Augmented Generation for Knowledge-I...</td>\n",
       "      <td>6_Retrieval-Augmented Generation for Knowledge...</td>\n",
       "      <td>5_Retrieval-Augmented Generation for Knowledge...</td>\n",
       "      <td>9_Retrieval-Augmented Generation for Knowledge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NarrativeText</td>\n",
       "      <td>Large pre-trained language models have been sh...</td>\n",
       "      <td>application/pdf</td>\n",
       "      <td>['eng']</td>\n",
       "      <td>1</td>\n",
       "      <td>Retrieval-Augmented Generation for Knowledge-I...</td>\n",
       "      <td>This paragraph discusses the capabilities and ...</td>\n",
       "      <td>Patrick Lewis,Ethan Perez,Aleksandra Piktus,Fa...</td>\n",
       "      <td>Facebook AI Research,University College London...</td>\n",
       "      <td>2020</td>\n",
       "      <td>Retrieval-Augmented Generation for Knowledge-I...</td>\n",
       "      <td>Abstract</td>\n",
       "      <td>9_Retrieval-Augmented Generation for Knowledge...</td>\n",
       "      <td>6_Retrieval-Augmented Generation for Knowledge...</td>\n",
       "      <td>11_Retrieval-Augmented Generation for Knowledg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NarrativeText</td>\n",
       "      <td>Pre-trained neural language models have been s...</td>\n",
       "      <td>application/pdf</td>\n",
       "      <td>['eng']</td>\n",
       "      <td>1</td>\n",
       "      <td>Retrieval-Augmented Generation for Knowledge-I...</td>\n",
       "      <td>This block discusses the advantages and disadv...</td>\n",
       "      <td>Patrick Lewis,Ethan Perez,Aleksandra Piktus,Fa...</td>\n",
       "      <td>Facebook AI Research,University College London...</td>\n",
       "      <td>2020</td>\n",
       "      <td>Retrieval-Augmented Generation for Knowledge-I...</td>\n",
       "      <td>1 Introduction</td>\n",
       "      <td>11_Retrieval-Augmented Generation for Knowledg...</td>\n",
       "      <td>9_Retrieval-Augmented Generation for Knowledge...</td>\n",
       "      <td>12_Retrieval-Augmented Generation for Knowledg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>FigureCaption</td>\n",
       "      <td>Table 7: Number of instances in the datasets u...</td>\n",
       "      <td>application/pdf</td>\n",
       "      <td>['eng']</td>\n",
       "      <td>19</td>\n",
       "      <td>Retrieval-Augmented Generation for Knowledge-I...</td>\n",
       "      <td>Describes the content of Table 7, indicating t...</td>\n",
       "      <td>Patrick Lewis,Ethan Perez,Aleksandra Piktus,Fa...</td>\n",
       "      <td>Facebook AI Research,University College London...</td>\n",
       "      <td>2020</td>\n",
       "      <td>Retrieval-Augmented Generation for Knowledge-I...</td>\n",
       "      <td>G Parameters</td>\n",
       "      <td>216_Retrieval-Augmented Generation for Knowled...</td>\n",
       "      <td>214_Retrieval-Augmented Generation for Knowled...</td>\n",
       "      <td>217_Retrieval-Augmented Generation for Knowled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>Table</td>\n",
       "      <td>| Task | Train | Development | Test |\\r\\n|---|...</td>\n",
       "      <td>application/pdf</td>\n",
       "      <td>['eng']</td>\n",
       "      <td>19</td>\n",
       "      <td>Retrieval-Augmented Generation for Knowledge-I...</td>\n",
       "      <td>Table 7: Number of instances in the datasets u...</td>\n",
       "      <td>Patrick Lewis,Ethan Perez,Aleksandra Piktus,Fa...</td>\n",
       "      <td>Facebook AI Research,University College London...</td>\n",
       "      <td>2020</td>\n",
       "      <td>Retrieval-Augmented Generation for Knowledge-I...</td>\n",
       "      <td>G Parameters</td>\n",
       "      <td>217_Retrieval-Augmented Generation for Knowled...</td>\n",
       "      <td>216_Retrieval-Augmented Generation for Knowled...</td>\n",
       "      <td>218_Retrieval-Augmented Generation for Knowled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>NarrativeText</td>\n",
       "      <td>parameters. The best performing \"closed-book\" ...</td>\n",
       "      <td>application/pdf</td>\n",
       "      <td>['eng']</td>\n",
       "      <td>19</td>\n",
       "      <td>Retrieval-Augmented Generation for Knowledge-I...</td>\n",
       "      <td>This block discusses the performance of differ...</td>\n",
       "      <td>Patrick Lewis,Ethan Perez,Aleksandra Piktus,Fa...</td>\n",
       "      <td>Facebook AI Research,University College London...</td>\n",
       "      <td>2020</td>\n",
       "      <td>Retrieval-Augmented Generation for Knowledge-I...</td>\n",
       "      <td>G Parameters</td>\n",
       "      <td>218_Retrieval-Augmented Generation for Knowled...</td>\n",
       "      <td>217_Retrieval-Augmented Generation for Knowled...</td>\n",
       "      <td>220_Retrieval-Augmented Generation for Knowled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>NarrativeText</td>\n",
       "      <td>In preliminary experiments, we observed that f...</td>\n",
       "      <td>application/pdf</td>\n",
       "      <td>['eng']</td>\n",
       "      <td>19</td>\n",
       "      <td>Retrieval-Augmented Generation for Knowledge-I...</td>\n",
       "      <td>This block discusses challenges encountered du...</td>\n",
       "      <td>Patrick Lewis,Ethan Perez,Aleksandra Piktus,Fa...</td>\n",
       "      <td>Facebook AI Research,University College London...</td>\n",
       "      <td>2020</td>\n",
       "      <td>Retrieval-Augmented Generation for Knowledge-I...</td>\n",
       "      <td>H Retrieval Collapse</td>\n",
       "      <td>220_Retrieval-Augmented Generation for Knowled...</td>\n",
       "      <td>218_Retrieval-Augmented Generation for Knowled...</td>\n",
       "      <td>222_Retrieval-Augmented Generation for Knowled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>NarrativeText</td>\n",
       "      <td>The number of training, development and test d...</td>\n",
       "      <td>application/pdf</td>\n",
       "      <td>['eng']</td>\n",
       "      <td>19</td>\n",
       "      <td>Retrieval-Augmented Generation for Knowledge-I...</td>\n",
       "      <td>This sentence describes the content of Table 7...</td>\n",
       "      <td>Patrick Lewis,Ethan Perez,Aleksandra Piktus,Fa...</td>\n",
       "      <td>Facebook AI Research,University College London...</td>\n",
       "      <td>2020</td>\n",
       "      <td>Retrieval-Augmented Generation for Knowledge-I...</td>\n",
       "      <td>I Number of instances per dataset</td>\n",
       "      <td>222_Retrieval-Augmented Generation for Knowled...</td>\n",
       "      <td>220_Retrieval-Augmented Generation for Knowled...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159 rows × 15 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T21:33:06.410447Z",
     "start_time": "2024-09-05T21:33:06.404408Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_document(row):\n",
    "    # Crear el nodo de texto con el ID, texto y metadatos\n",
    "    node = Document(\n",
    "        id=row['node_id'],\n",
    "        text=row['text'],  # Usar la columna 'text' para el contenido del nodo\n",
    "        metadata={\n",
    "            'block_type': row['block_type'],\n",
    "            'section_title': row['section_title'],\n",
    "            'description': row['description'],\n",
    "            'file_type': row['file_type'],\n",
    "            'languages': row['languages'],\n",
    "            'page_number': row['page_number'],\n",
    "            'filename': row['filename'],\n",
    "            'authors': row['authors'],\n",
    "            'research_lab': row['research_lab'],\n",
    "            'publication_year': row['publication_year'],\n",
    "            'title_of_the_document': row['title']\n",
    "        },\n",
    "        excluded_llm_metadata_keys=['authors', 'research_lab', 'file_type'],\n",
    "        excluded_embed_metadata_keys=['block_type', 'file']\n",
    "    )\n",
    "    if pd.notna(row['previous_node_id']):\n",
    "        node.relationships[NodeRelationship.PREVIOUS] = RelatedNodeInfo(\n",
    "            node_id=row['previous_node_id']\n",
    "        )\n",
    "    if pd.notna(row['next_node_id']):\n",
    "        node.relationships[NodeRelationship.NEXT] = RelatedNodeInfo(\n",
    "            node_id=row['next_node_id']\n",
    "        )\n",
    "    return node"
   ],
   "id": "5a0b19ce4277c063",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T21:33:09.654359Z",
     "start_time": "2024-09-05T21:33:09.637986Z"
    }
   },
   "cell_type": "code",
   "source": "df['documents'] = df.apply(create_document, axis=1)",
   "id": "9c47a3cf88ef4f6a",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T21:33:11.638941Z",
     "start_time": "2024-09-05T21:33:11.631852Z"
    }
   },
   "cell_type": "code",
   "source": [
    "documents = df['documents'].tolist()\n",
    "documents[0]"
   ],
   "id": "86cd439207c931a5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(id_='fda69868-2c0a-404d-8a76-97e4b57a8a0b', embedding=None, metadata={'block_type': 'Author Names', 'section_title': 'Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks', 'description': 'Lists the names of authors, potentially with affiliations indicated by symbols.', 'file_type': 'application/pdf', 'languages': \"['eng']\", 'page_number': 1, 'filename': 'Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf', 'authors': 'Patrick Lewis,Ethan Perez,Aleksandra Piktus,Fabio Petroni,Vladimir Karpukhin,Naman Goyal,Heinrich KÃ¼ttler,Mike Lewis,Wen-tau Yih,Tim RocktÃ¤schel,Sebastian Riedel,Douwe Kiela', 'research_lab': 'Facebook AI Research,University College London,New York University', 'publication_year': 2020, 'title_of_the_document': 'Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks'}, excluded_embed_metadata_keys=['block_type', 'file'], excluded_llm_metadata_keys=['authors', 'research_lab', 'file_type'], relationships={<NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5_Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf', node_type=None, metadata={}, hash=None)}, text=\"Patrick Lewis'?, Ethan Perez*,\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T21:34:35.555971Z",
     "start_time": "2024-09-05T21:34:35.550460Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "credentials_path = os.getenv('GCP_CREDENTIALS_PATH')\n",
    "if credentials_path is None:\n",
    "    raise ValueError(\"La variable de entorno 'GCP_CREDENTIALS_PATH' no está definida.\")\n"
   ],
   "id": "1327a280f8405d31",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T21:51:46.117774Z",
     "start_time": "2024-09-05T21:34:37.031683Z"
    }
   },
   "cell_type": "code",
   "source": [
    "embedding = VertexIEmbeddings(credentials_path=credentials_path)\n",
    "Settings.llm = Vertex(model=\"gemini-1.5-pro-001\")\n",
    "Settings.embed_model = embedding\n",
    "\n",
    "semantic_spliter = SemanticSplitterNodeParser(\n",
    "    buffer_size=1,\n",
    "    embed_model=embedding,\n",
    "    include_metadata=True,\n",
    "    include_prev_next_rel=True\n",
    ")\n",
    "\n",
    "qa_extractor = QuestionsAnsweredExtractor(questions=3)\n",
    "\n",
    "transformation = [\n",
    "    semantic_spliter,\n",
    "    qa_extractor,\n",
    "    embedding\n",
    "]\n",
    "\n",
    "pipeline = IngestionPipeline(transformations=transformation)\n",
    "\n",
    "\n",
    "\n",
    "nodes = pipeline.run(documents=documents, in_place=True, show_progress=True)\n",
    "\n",
    "\n"
   ],
   "id": "755f66532d067097",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parsing nodes:   0%|          | 0/159 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "da8745a8136343d99fa147cfc85e6f72"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bca9ca38f1c740a0b5b8433a66c869ee"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d9ec41de104f461eb48cfb2145f20610"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "99ef9cefd6cf40e2bfeccccf86fb1549"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/9 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "56ede14c9e744cd39561cf3394521832"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d914293da0004a9a8a92361383a09cf9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/13 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7a87f8634c354266b45bd1b78870be10"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c5f90caece154784adf411afb22b4d7a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/3 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e8001e6a00c34795938fee7e40829e29"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/7 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "61967df36f7149eeb297230d8ee37753"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bddf5bda03d9478587dd1c8c14b0947c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/6 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3c220c6149a74f2ca1705aaf642e48d4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c10a1a05565f45f5b532dab93563ec09"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8b4560fd0efc423cb7f4495fb04df550"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e7417664f0e94ceca90b6327dc7827e5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "68eaba02230444198cc1c40b240836c4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/3 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3d91abb95abc48699455e3b3875d07d1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b2438b2bfb534b0f874aa3f9b04b719d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/3 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9dd394345a4a4da2aff691e910e82101"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "242dd3680d804192be46d594c6ab46f1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "95b786751b864bf889978c5d1d53cf36"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2be5e863cafd42d9a3a1d4c7e76a4d30"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e3e30c5771d84746a329e00f296ddf1d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/6 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "65ace116edb84e4385cf9608b1d88556"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9c46e72dd65140f2be1e13d09ec1e5c2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/3 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6909acf03ae04fecbdbfad092b606be8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "feada2fdbee9438a9f716be6e243e0c5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c8099a9143e34d8e9f896c92af8e6dd2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/8 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "de852bccbc744d5dbdf382bd54728422"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/10 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c18e38923419466eb4796ac44c448110"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/9 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "924a019b2f754606a94fe11cf8a48a21"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b2586a96b6954f868e1be9182f1735d2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7c16462893e649a590e042b938e6553b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1a3eca08dcf54c49a598fdc9e859ac45"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/9 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dabb9c787c5f4eedb0944f8614f0b634"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/9 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7d6051da69e44b53b1d343a977797e4d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/7 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "07b2b5f021114212bdb75f4f595a46cb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0f8344a7d78541d7a04afad9a4a0836a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/6 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ebf6565b79a5413a82ffeac1f8e63b69"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5d1825b6cef24530a0058c81bd3898c8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "08eb5a9e1bd44019adf0520722e98984"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3e548403187547b6ba73386fb5fd7418"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9a3441882b2b4420aadecdbe4a429082"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/11 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a52a548a29c8468a9903b4990af553b4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d29f930f9d2f4eb79e4490943b7a4ecc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/7 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4d506a21e25246ebacc7a6c8c24b0bda"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/3 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "63c0defb2443439cadd86b0ab74e02a1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7d7592d804cf4a8c9cb1c43597fdf51e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/3 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1c9ef3e0aa914363919c85d916658548"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/10 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3f45a63dbf764b6dab4b263cad0b318b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2274cfc32d0f44709270025b8e78f947"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/3 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a6e65e1f84074858a0a028081130b595"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/3 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a264f8c903014e19a1265f6fc3ba4062"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4ab7debfebfc4900baf6ec33e51defb6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9e87cd14720944feb23fcd706d3c68a7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "32cdade624bb49f9b00dcd9d55dde155"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c98d8de161464f118c58c3bb1063d53d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "118f7b7813ee4332b07e0a0584f85bb5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ffe0b45a409b4ad7bd8bf34b16c278f1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c417421c92ed4822b9ca9176f4984de3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3152dc157c33493c99ca3d44e5380f7b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4d1381182d8c48f687420151cee41f2e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/9 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2617970bf2344d7597265a2367218ced"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/3 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8373486da2c6452687945890f2086e00"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/3 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bf68d25516524ffcae075e1b999724e8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "616e0b5eedd64646bddd51d9c5e35038"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/3 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "32a923b735da43f0bc5c6f43c980b152"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "281664b45bd8401bae6bf954b34a0377"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bf45cabca1374a08ae7587bbe9e7d82e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/6 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "edbebf1ba4db419fa55a6c28372f5691"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8e406e5d48374e8e9bbe2ba5847b78f7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5cda600b543c41a79a433c3babcf467f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b045bad8deb74669be65c5b03a8380aa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "14aa723566bb400ea12cd9dd3b2b17ee"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c7a60c621ec646708334dbbc8c6ef076"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "340c3ea27b2244e8b0d332ddd8820815"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "17491f16c2934262a22d3f4aa522a0b8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/6 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b9f483514d3041d1ac8b70fa06bed49c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/6 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a6920ed7c2994d32b21cd5fed874b198"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "04ead2a176e346b39a1f09c50bd5f97c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/6 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3c7cd3b1bd85463f867fa435bc4ff6da"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "faed3fa460d144a6bd75c0a3f3776af9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d00559bf029a4068a62a3fb90a0b4cce"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/6 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3ba18cb0cf384a90997e6780a1e743ff"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/6 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3465e213459b4df381047c07a80078ea"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/3 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ee174642d729483b844490bb9b2e2689"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "96ac9015942a436381a2f84e92e84d7e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "126a695c3e014a4fb3680b364268080d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "22c9cc141cca4083a1cb7f1c41080ce6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5ee74f6a479c465ca9d6c18b9fc00bc9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/6 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ce58490a6d314638b7761162d143b725"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ff3ad58c9a2e4b8db553d18bc57d0432"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c10a37e16ea148f09dbb86cbbb4f97bc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/3 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "49c04bede7b0495a805759e7b62d516e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/6 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "54ce2282fce947b8a35bdfcf60b8463c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e5add3dcc7dd49c58c23ec86240a776c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/6 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "71bb199e8f1c4644af9e4efc599c7f1a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1a548407feff4157822b94e9bf3fdb74"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "12d6fb656f4747078f6731c3febe1a35"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bb0d101e89854b5c955a8d67be487053"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3075063d759e403785844be3c46fe6db"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fe168ef817d34125bf31b01ed3a9ce12"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3066167814bd4184a5a8412205fe4710"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/3 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0dac8ce665074cf0a658f4984711f5aa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2a0fede598b748af8b437c7a32d0d58d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7861f85ae9614e84a7bf9a6270cd62f4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/6 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "41efe77158ed41198a15847bd05f0f89"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7fc2e4d6c5164371989032da88354f6d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/6 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0434f4d405d14878a3bd8754a6989de3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "302adbb1af594da7ae2795eac09abc80"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "34aeccd378bf40e58f8bafb2aca1c42a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5631b71c1e9b44c5ab590535f338bb61"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5012e566c1ae4fb6a7387ce75e797370"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "abbe454d25cb409b88aaa27c0a929b58"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/6 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1612166455c6401b93fcb437f7fae5be"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/6 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eeac947031b747ffa4d31a038d8d1ae2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/3 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e4c3664872434ca89d93c3be8495b8d5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/3 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c8144fea6dc747218956ec889794b817"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c16bccf50af1448da01ffc1f5a9c5578"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/7 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eb40d7dad00446dc85a9027d6e88e233"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/6 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1ba5f2e25b39428daa1bacd2a184a7d5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/6 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eb1b613b6879496d8cc1873beff20b3b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ac5b9bb395a64eee8610856537c87f8e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "85b77542a8934608a481f471502549bd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fd65ed5c825a49a7b742312c0e109c17"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d4fefc48d01041fe8bc0db97c5a7f465"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "201abd0ffcd5436cb490d981fe42cce0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/7 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "525209af8db14c8b8ea46d0d45b358d3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/3 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "59cac1597ec64adcbe69bc20d752a212"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "29a7413507d14961a1918128155220fa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/6 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "268d7449f12a4b1cb5a43c9d9d0b7a24"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "11cd3b4006f64cfdaeb813d79b07bee6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dcf40b8d3be54d10abb47dd5723931ba"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "85c82e49bfe04641861ed035e2539cc0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/6 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "420dd29cf72a483e92549308ec5e50d3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ea17e27f2dfa41f9a8a3b1925ea46009"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/6 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "47ed8e3f39dd4910812886084a06f5d9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "45b3a833d26a4d0a9bb14bbf7a998a84"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "042cac562f154d3889c7c3e439896c8e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/6 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "31aca96fd5d14d7484e83a51cd8f8eb3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/3 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bdebf807aade45fa8a36183a14c45531"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/6 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b65bac082b70491aa5e981c0248de948"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "81f6aa158985406a8ade2a6e109e14a7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2c2791547f72462bacd889e1017c7c8d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/10 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "126504607e724c92b5d0a16ec55552cc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2c3bb382a7d640ba8be4d20ca49a9008"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b0a6a8e1c6574c4e9d9b060c81fe9282"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/6 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1992af8adad04cb08de3ad52b6eecfbb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "15dbb999d7a6407bb0a5ef9d49971740"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "39aa9a1ac1384c1bbdcee36fafe722f5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/3 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1be72b6385194fa3a538160abdb19f69"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/10 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5647f7a5256a410199d5c749d62e523a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/6 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "79aa2dd7f9d0496687369a7f571643c9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f19e35384d324632b23c5b59beb9eefe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8d4f2d2cdd2e497fa9c6d84d405f23b2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "62727215419b445ca1bc6b905ac284d4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1fa13a86e082420f9256af2219b7b183"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7f271eb5caeb4c45a35bccaafc493203"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eccabd625f67492184181b1a50376283"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "20ba3840cc4f4af68aff0486aae1eee1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 27/287 [00:31<04:27,  1.03s/it]Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      " 10%|▉         | 28/287 [00:31<03:31,  1.22it/s]Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      " 10%|█         | 29/287 [00:32<03:46,  1.14it/s]Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      " 16%|█▋        | 47/287 [01:47<05:09,  1.29s/it]  Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      " 17%|█▋        | 48/287 [01:48<04:20,  1.09s/it]Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      " 17%|█▋        | 49/287 [01:48<03:42,  1.07it/s]Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      " 17%|█▋        | 50/287 [01:51<05:55,  1.50s/it]Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      " 24%|██▍       | 69/287 [02:48<04:29,  1.24s/it]Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      " 24%|██▍       | 70/287 [02:48<03:28,  1.04it/s]Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      " 25%|██▍       | 71/287 [02:49<03:20,  1.08it/s]Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      " 31%|███       | 89/287 [03:43<03:57,  1.20s/it]Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      " 31%|███▏      | 90/287 [03:43<03:04,  1.07it/s]Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      " 32%|███▏      | 91/287 [03:45<04:27,  1.36s/it]Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      " 32%|███▏      | 92/287 [03:46<03:43,  1.14s/it]Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      " 38%|███▊      | 110/287 [04:47<04:00,  1.36s/it]Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      " 39%|███▉      | 112/287 [04:50<03:49,  1.31s/it]Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      " 39%|███▉      | 113/287 [04:51<03:14,  1.12s/it]Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      " 46%|████▌     | 131/287 [05:43<03:13,  1.24s/it]Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      " 46%|████▌     | 132/287 [05:45<04:22,  1.69s/it]Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      " 47%|████▋     | 134/287 [05:48<03:45,  1.47s/it]Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      " 53%|█████▎    | 152/287 [06:47<02:54,  1.30s/it]Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      " 53%|█████▎    | 153/287 [06:47<02:16,  1.02s/it]Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      " 54%|█████▎    | 154/287 [06:49<02:39,  1.20s/it]Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      " 54%|█████▍    | 155/287 [06:50<02:40,  1.21s/it]Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      " 60%|██████    | 173/287 [07:47<02:50,  1.49s/it]Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      " 61%|██████    | 174/287 [07:47<02:11,  1.16s/it]Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      " 61%|██████    | 175/287 [07:48<02:02,  1.09s/it]Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      " 61%|██████▏   | 176/287 [07:48<01:41,  1.09it/s]Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      " 68%|██████▊   | 194/287 [08:47<01:38,  1.06s/it]Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      " 68%|██████▊   | 195/287 [08:48<01:20,  1.14it/s]Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      " 68%|██████▊   | 196/287 [08:51<02:36,  1.72s/it]Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      " 69%|██████▊   | 197/287 [08:52<01:58,  1.32s/it]Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      " 75%|███████▍  | 215/287 [09:39<01:34,  1.31s/it]Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      " 75%|███████▌  | 216/287 [09:40<01:27,  1.23s/it]Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      " 76%|███████▌  | 217/287 [09:40<01:13,  1.05s/it]Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      " 76%|███████▌  | 218/287 [09:42<01:21,  1.19s/it]Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      " 82%|████████▏ | 236/287 [10:47<01:03,  1.25s/it]Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      " 83%|████████▎ | 237/287 [10:48<00:57,  1.15s/it]Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      " 83%|████████▎ | 238/287 [10:50<01:10,  1.43s/it]Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      " 83%|████████▎ | 239/287 [10:52<01:18,  1.63s/it]Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      " 90%|████████▉ | 257/287 [11:41<00:35,  1.18s/it]Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      " 90%|████████▉ | 258/287 [11:43<00:43,  1.49s/it]Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      " 90%|█████████ | 259/287 [11:44<00:32,  1.15s/it]Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      " 91%|█████████ | 260/287 [11:45<00:30,  1.13s/it]Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      " 97%|█████████▋| 278/287 [12:49<00:12,  1.43s/it]Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      " 97%|█████████▋| 279/287 [12:49<00:08,  1.12s/it]Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      " 98%|█████████▊| 280/287 [12:50<00:07,  1.13s/it]Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      " 98%|█████████▊| 281/287 [12:52<00:08,  1.37s/it]Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "100%|██████████| 287/287 [13:27<00:00,  2.81s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/287 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "85bff70b603d4776a85a2d264abfa74c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T21:53:14.030359Z",
     "start_time": "2024-09-05T21:53:14.023132Z"
    }
   },
   "cell_type": "code",
   "source": "nodes[0]",
   "id": "82d64369fe7479aa",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextNode(id_='9841e894-8120-4ef5-ba04-33b1fdb56745', embedding=[-0.025246039032936096, -0.003179964842274785, -0.06594706326723099, -8.014733612071723e-05, 0.0015911523951217532, 0.00019661440455820411, 0.024234145879745483, 0.008799227885901928, 0.05155366659164429, -0.006005400791764259, -0.020428717136383057, -0.025113023817539215, 0.025076409801840782, 0.006820478476583958, -0.0062823425978422165, -0.015581350773572922, 0.02629615180194378, 0.06237902119755745, -0.05881671607494354, -0.012944183312356472, -0.01927935518324375, -0.009847882203757763, 0.019640354439616203, -0.03306274488568306, -0.02076777257025242, -0.07714923471212387, 0.05812016874551773, -0.018395598977804184, 0.012749012559652328, -0.00503784092143178, 0.03264058008790016, 0.06509224325418472, 0.028401130810379982, 0.004888472612947226, 0.005833648145198822, 0.060041554272174835, -0.03575453534722328, 0.03037434071302414, 0.03437187522649765, -0.10131872445344925, -0.048668887466192245, 0.0017969397595152259, -0.02738066017627716, 0.030277086421847343, -0.06668154895305634, -0.03488615155220032, -0.012152308598160744, 0.0671609491109848, -0.053850945085287094, 0.07767733931541443, 0.0018422654829919338, 0.011136502027511597, -0.0791667029261589, 0.0152670843526721, -0.035225629806518555, 0.018492933362722397, -0.06711016595363617, -0.016052428632974625, 0.01598551869392395, 0.026083428412675858, 0.0038069700822234154, 0.023271366953849792, -0.03536483272910118, -0.016926469281315804, 0.04442315548658371, -0.05790148675441742, 0.005015723407268524, 0.011439788155257702, -0.0764736458659172, 0.05180927738547325, -0.0028296217788010836, 0.009976305067539215, -0.026269003748893738, 0.049863483756780624, -0.00936953630298376, -0.07015006244182587, 0.024249877780675888, -0.04070163890719414, 0.039409562945365906, 0.048324886709451675, -0.007625476457178593, 0.05191674828529358, 0.10741663724184036, -0.01264184806495905, 0.04840707778930664, 0.020115574821829796, 0.04758001118898392, -0.05035463720560074, -0.03182020038366318, -0.052749957889318466, 0.07183747738599777, -0.03501003608107567, -0.024912578985095024, 0.029746362939476967, 0.048523783683776855, -0.05082603543996811, -0.06757178157567978, -0.059245865792036057, 0.053900182247161865, 0.02762875333428383, -0.032838091254234314, -0.0005200929008424282, 0.00022277062817011029, -0.04133857414126396, 0.052131976932287216, 0.054955266416072845, -0.001580449752509594, -0.009885349310934544, -0.05645337328314781, 0.01827601157128811, -0.008249225094914436, -0.015096532180905342, -0.017706412822008133, -0.005236574914306402, -6.027414929121733e-05, -0.04975561425089836, -0.017253238707780838, -0.026556819677352905, -0.02593211643397808, 0.02035537362098694, -0.024134783074259758, 0.07159987837076187, -0.019742341712117195, 0.08953659981489182, 0.012011108919978142, 0.009149380028247833, 0.00927185732871294, -0.05179202929139137, -0.03646858036518097, -0.02805584855377674, 0.09341878443956375, -0.046603698283433914, -0.04101639240980148, -0.006803604774177074, -0.053231265395879745, -0.025899551808834076, 0.03327273204922676, 0.01729094795882702, -0.004265542607754469, 0.008899210020899773, 0.00029403535882011056, -0.024080388247966766, -0.06132866442203522, -0.016490643844008446, 0.025092294439673424, -0.010943979024887085, 0.0005282234051264822, 0.01293403934687376, 0.03554275259375572, 0.027432851493358612, -0.01362049300223589, -0.04632563516497612, 0.04670844227075577, 0.015254257246851921, -0.04144980385899544, -0.019519580528140068, 0.018319331109523773, -0.052922338247299194, 0.058431487530469894, -0.006091166287660599, 0.0383915901184082, -0.01963333785533905, 0.03029007278382778, -0.012404278852045536, -0.04260396584868431, -0.05609068274497986, 0.02942984364926815, -0.004507829900830984, 0.004894006997346878, 0.03529134392738342, -0.00045673584099859, -0.037514761090278625, -0.05994250625371933, -0.015466749668121338, 0.04279162362217903, 0.024251392111182213, -0.01618499867618084, -0.003629773622378707, 0.007723774760961533, -0.01140483096241951, 0.11210744827985764, -0.0006425657193176448, -0.04093217849731445, -0.045692913234233856, -0.009375466033816338, -0.056948222219944, 0.007953283376991749, 0.022203538566827774, 0.07520543783903122, 0.02801869623363018, 0.0005741037311963737, -0.02622813545167446, 0.04674195498228073, -0.025576209649443626, -0.001038536662235856, -9.580615733284503e-05, 0.02634216472506523, -0.07603774219751358, -0.026917899027466774, -0.03590214625000954, 0.040360596030950546, -0.012538567185401917, 0.022099481895565987, 0.003644087351858616, 0.01674998365342617, 0.01907753385603428, -0.03881087154150009, -0.03097773715853691, 0.028339268639683723, 0.04492468759417534, -0.05339476466178894, -0.029985502362251282, -0.0006847961340099573, -0.07929562777280807, -0.021334102377295494, 0.008881320245563984, 0.04108068346977234, 0.01968742534518242, 0.09052779525518417, -0.04736629128456116, 0.008444510400295258, -0.003629675367847085, -0.02767603099346161, 0.026647523045539856, 0.03312896564602852, 0.020283591002225876, -0.01612226851284504, 0.03459630534052849, 0.0278174951672554, -0.07948334515094757, 0.0041682044975459576, -0.011840504594147205, 0.06527959555387497, 0.029851479455828667, -0.03269708529114723, 0.011114903725683689, 0.03402280807495117, 0.006574074737727642, -0.012252219952642918, 0.006494829896837473, 0.0016436614096164703, 0.06408380717039108, 0.008007421158254147, -0.07373809814453125, 0.0077834222465753555, 0.05629559978842735, 0.05950723588466644, 0.018354348838329315, 0.0012134172720834613, -0.05500296503305435, -0.012427955865859985, -0.01927030459046364, -0.04674682393670082, 0.0009855770040303469, -0.07438284903764725, -0.04214547574520111, -0.011902949772775173, -0.00244288332760334, -0.009221787564456463, -0.03761402890086174, 0.027870217338204384, 0.003432265017181635, -0.0169737096875906, -0.09786558151245117, -0.036594100296497345, -0.03627820685505867, -0.034551043063402176, -0.00623877439647913, 0.05023384094238281, 0.0028330308850854635, 0.03307594358921051, -0.03349602594971657, -0.04468471556901932, -0.03254448622465134, -0.025466518476605415, -0.004006020724773407, 0.010924480855464935, 0.013289335183799267, -0.034244634211063385, -0.040534134954214096, 0.09833250194787979, 0.020419040694832802, -0.05681878328323364, -0.04850582778453827, 0.06447184830904007, -0.08251374214887619, 0.002757175825536251, 0.01314122136682272, -0.013953437097370625, -0.01806972734630108, 0.0372094064950943, 0.014455253258347511, -0.03329480066895485, -0.026396362110972404, 0.04152931645512581, 0.022737978026270866, 0.014886551536619663, 0.027781911194324493, -0.026811696588993073, 0.003965259995311499, 0.003988467622548342, 0.026609785854816437, -0.001858529052697122, 0.08712171018123627, 0.011286010965704918, 0.017477409914135933, -0.051126785576343536, -0.008518575690686703, -0.11622924357652664, 0.0171132180839777, 0.043625734746456146, 0.04494669288396835, -0.0032959673553705215, 0.005143854301422834, 0.012378624640405178, -0.027621297165751457, -0.1678299754858017, 0.024413837119936943, 0.015443122014403343, -0.0151554886251688, -0.013365193270146847, -0.001084530376829207, -0.02442791871726513, 0.018240811303257942, 0.04176986590027809, 0.00733531080186367, 0.023214243352413177, -0.0014276024885475636, 0.03210563212633133, 0.04827631264925003, 0.02173364907503128, -0.024774866178631783, 0.03722906857728958, -0.063560850918293, 7.472782453987747e-05, -0.0035193869844079018, -0.016271203756332397, 0.0448196679353714, 0.08556388318538666, -0.008159494027495384, 0.035780493170022964, 0.037746649235486984, 0.06724372506141663, 0.0378202423453331, -0.025656750425696373, -0.029531365260481834, -0.04018309339880943, -0.03213350847363472, 0.042007606476545334, 0.015177447348833084, 0.02066604606807232, 0.016823705285787582, 0.04933107644319534, -0.04543431103229523, -0.024222493171691895, 0.017895285040140152, 0.03683260455727577, -0.028346385806798935, -0.04261289909482002, -0.0023600119166076183, 0.01484801433980465, 0.009738334454596043, -0.006955977063626051, 0.03972388431429863, -0.03981974348425865, -0.04451701417565346, 0.03251802921295166, 0.02654784917831421, -0.0038280717562884092, -0.0005292081623338163, 0.031583745032548904, 0.0388326570391655, 0.010828692466020584, -0.011351500637829304, 0.019243426620960236, 0.017956817522644997, -0.0016432336997240782, 0.04765147715806961, 0.011429650709033012, -0.0325440838932991, -0.0023583939764648676, -0.11205970495939255, 0.030196737498044968, -0.014644499868154526, -0.042849503457546234, 0.0751040056347847, -0.07868295907974243, 0.01131388358771801, 0.015392574481666088, 0.008931223303079605, -0.014737921766936779, 0.03528166934847832, -0.004524366930127144, 0.034186556935310364, -0.01941791921854019, 0.02265114150941372, -0.0051705422811210155, 0.044278305023908615, -0.004792471881955862, 0.0030232577119022608, 0.014055321924388409, -0.022322973236441612, 0.039766665548086166, -0.020961925387382507, 0.01943803019821644, -0.036986347287893295, 0.05111714079976082, 0.012263656593859196, -0.0005278440658003092, 0.004987558349967003, -0.039045751094818115, -0.02970765344798565, 0.006003096234053373, 0.0020884908735752106, -0.04635835811495781, -0.01000005379319191, 0.05746188387274742, -0.009024416096508503, -0.005690761376172304, 0.033041998744010925, -0.0015789115568622947, -0.0025617775972932577, 0.06617756932973862, 0.039880797266960144, 0.012233843095600605, -0.06000588461756706, 0.005518531426787376, -0.04989723488688469, 0.039870768785476685, -0.0018836728995665908, -0.0367872528731823, 0.061367131769657135, 0.00028345317696221173, 0.023101873695850372, 0.002852995879948139, 0.05723806843161583, 0.03937525302171707, 0.0027070220094174147, 0.005651706364005804, 0.046289000660181046, 0.02572779171168804, -0.023988986387848854, 0.03560754284262657, 0.007252912037074566, -0.01018660981208086, 0.05585120618343353, 0.03769546002149582, -0.006975032389163971, 0.012449432164430618, -0.08334073424339294, 0.039791516959667206, 0.012429975904524326, -0.03043290600180626, -0.060495853424072266, -0.08622941374778748, 0.0042718746699392796, 0.04638969153165817, 0.0027863814029842615, -0.020580722019076347, 0.002075000200420618, -0.035052746534347534, -0.02893642894923687, 0.06816352903842926, 0.01491228211671114, -0.019467700272798538, -0.014793857000768185, -0.00851710606366396, 0.007560563273727894, -0.026252269744873047, 0.03095577098429203, 0.06324998289346695, 0.012428484857082367, 0.023816537111997604, 0.03594709560275078, -0.08082728087902069, 0.024575436487793922, 0.04814664274454117, 0.025379596278071404, 0.06056515872478485, -0.03361237421631813, 0.0014465779531747103, 0.010008694604039192, -0.04122893512248993, 0.030245160683989525, -0.007389900740236044, 0.017192212864756584, -0.03947916254401207, 0.023099184036254883, 0.05120035260915756, 0.020630568265914917, 0.026843236759305, 0.017696315422654152, -0.07106897234916687, 0.01431217323988676, -0.01303072739392519, -0.010793701745569706, 0.043913334608078, -0.06807805597782135, -0.004410449881106615, 0.058089252561330795, 0.007753833197057247, 0.054373849183321, -0.03025832399725914, -0.02402685023844242, -0.06667384505271912, 0.016692835837602615, -0.042429350316524506, -0.019038531929254532, 0.015498549677431583, 0.03444839268922806, 0.07208740711212158, -0.029568077996373177, -0.010263537056744099, -0.014099037274718285, 0.010800580494105816, 0.014871996827423573, -0.048822902143001556, 0.015374301001429558, -0.06985032558441162, 0.02047344483435154, 0.001931191305629909, -0.020666517317295074, 0.02541864849627018, -0.003364395350217819, 0.008078492246568203, -0.017968423664569855, 0.022482289001345634, 0.003232748480513692, 0.005024601239711046, -0.0006595795857720077, -0.04066368192434311, 0.08257529884576797, 0.03619900718331337, 0.0093857916072011, -0.0037157703191041946, 0.06096622720360756, 0.06349007785320282, 0.014672028832137585, 0.016457416117191315, 0.014389542862772942, -0.002745230682194233, 0.006133691873401403, 0.021267225965857506, 0.048493288457393646, 0.0724845677614212, -0.011615161783993244, -0.007300285156816244, 0.04128235951066017, 0.0005200597224757075, 0.06283887475728989, -0.013907796703279018, -0.05271177366375923, -0.0011209206422790885, 0.02066734991967678, 0.03097415901720524, -0.04352002218365669, 0.038298580795526505, 0.004286058712750673, -0.04135546833276749, -0.05086937174201012, -0.005008332896977663, -0.040791064500808716, 0.028139181435108185, -0.025718314573168755, 0.0025299994740635157, -0.015973994508385658, -0.0450354628264904, 0.029359307140111923, -0.050893329083919525, -0.013368921354413033, 0.02087542973458767, -0.0006123426137492061, 0.01926751248538494, 0.005891059525310993, -0.06573525071144104, -0.030695028603076935, -0.00831560231745243, 0.041816335171461105, 0.059391140937805176, -0.018459463492035866, 0.006946877110749483, -0.051993228495121, 0.07117888331413269, -0.027245907112956047, -0.023115644231438637, 0.020366935059428215, 0.031646765768527985, 0.0333072766661644, 0.0054219369776546955, -0.01898762956261635, -0.011587334796786308, -0.005007691215723753, 0.028746020048856735, -0.04239092022180557, 0.04016798362135887, -0.05222048610448837, -0.04996490105986595, -0.018671100959181786, 0.0012763077393174171, 0.006936519872397184, -0.022807108238339424, -0.01443648524582386, 0.06081719323992729, -0.037884052842855453, 0.00042020389810204506, -0.0423721969127655, -0.03533855825662613, -0.030665528029203415, -0.00816076248884201, 0.0044301943853497505, -0.04105056822299957, 0.03900716453790665, 0.012770605273544788, -0.012513270601630211, -0.10398188978433609, -0.0006750900647602975, -0.03504412993788719, -0.021739814430475235, 0.014436570927500725, -0.0022345250472426414, 0.01275144424289465, 0.039043523371219635, 0.009029022417962551, -0.012137227691709995, 0.03014351800084114, 0.01583515666425228, -0.046890247613191605, -0.017831595614552498, 0.06885215640068054, -0.028217706829309464, 0.0017086222069337964, -0.011591088026762009, 0.017130181193351746, -0.04575696960091591, -0.01510907057672739, 0.03623858839273453, 0.015357759781181812, -0.037702079862356186, 0.008061985485255718, -0.017715666443109512, 0.009576181881129742, 0.0373074971139431, 0.015240536071360111, 0.006921959109604359, -0.05193785950541496, 0.016380857676267624, -0.020936308428645134, 0.0058103036135435104, 0.005704711191356182, 0.0503351055085659, 0.018344992771744728, -0.01951863430440426, -0.02579953894019127, 0.009159556590020657, 0.0010443412465974689, -0.04387042298913002, -0.0430036336183548, -0.016642984002828598, 0.021668318659067154, -0.003638559952378273, 0.022352058440446854, -0.06696721911430359, -0.011143947020173073, -0.003666205331683159, -0.019923070445656776, -0.028096847236156464, -0.04092836380004883, 0.044789016246795654, 0.02066993899643421, 0.02404811605811119, -0.003904178040102124, -0.059489283710718155, 0.008315968327224255, 0.042261753231287, 0.019422920420765877, 0.012267527170479298, 0.0056421407498419285, 0.027972055599093437, 0.022576436400413513, 0.0357714481651783, -0.04071216285228729, -0.04827210679650307, 0.025475751608610153, -0.025697918608784676, 0.021283287554979324, 0.005316497292369604, 0.08477606624364853, -0.010929262265563011, 0.01956215687096119, -0.00399235961958766, 0.007200059946626425, -0.04529712721705437, 0.008064944297075272, 0.046086832880973816, -0.04087597504258156, 0.02502596378326416, -0.016521712765097618, 0.015125381760299206, -0.03028719313442707, 0.001479006139561534, -0.02000395581126213, -0.00704524852335453, -0.056138429790735245, -0.010473392903804779, 0.004654572810977697, 0.006357789970934391, -0.0034874016419053078, 0.009230517782270908, -0.04141206294298172, 0.03311644122004509, 0.023170042783021927, 0.0015712033491581678, 0.05880929157137871, 0.008378509432077408, 0.026027807965874672, 0.0027453682851046324, 0.019716894254088402, 0.0323493517935276, 0.01468907855451107, -0.030028341338038445, -0.04179207608103752, -0.024533381685614586, 0.03908543661236763, 0.029079236090183258, -0.02615736797451973, 0.0031796011608093977, -0.052426908165216446, -1.5787452866788954e-05, -0.02008938416838646, 0.006510790437459946, 0.06204861029982567, -0.013923871330916882, -0.01187045220285654, 0.010600976645946503, -0.003099387511610985, -0.047829002141952515, -0.00686412351205945, 0.019003333523869514, -0.04964442923665047, -0.019422603771090508, 0.016817837953567505, 0.007285690400749445, -0.006873891223222017, 0.006687860004603863, 0.019820943474769592, 0.03185061737895012, 0.02565472573041916, -0.017181850969791412, -0.04827382043004036, -0.03470993414521217, -0.08536744117736816, -0.0026312984991818666, -0.006999575532972813, -0.005719415843486786, 0.007152363192290068, -0.016413060948252678, -0.003811714006587863, -0.020414181053638458, -0.01468536164611578, -0.02793639712035656, 0.011117633432149887, 0.04690836742520332, 0.014211530797183514, -0.006763274781405926, -0.019432350993156433, -0.02880329079926014, 0.04271504655480385, 0.02602224424481392], metadata={'block_type': 'Author Names', 'section_title': 'Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks', 'description': 'Lists the names of authors, potentially with affiliations indicated by symbols.', 'file_type': 'application/pdf', 'languages': \"['eng']\", 'page_number': 1, 'filename': 'Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf', 'authors': 'Patrick Lewis,Ethan Perez,Aleksandra Piktus,Fabio Petroni,Vladimir Karpukhin,Naman Goyal,Heinrich KÃ¼ttler,Mike Lewis,Wen-tau Yih,Tim RocktÃ¤schel,Sebastian Riedel,Douwe Kiela', 'research_lab': 'Facebook AI Research,University College London,New York University', 'publication_year': 2020, 'title_of_the_document': 'Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks', 'questions_this_excerpt_can_answer': 'Here are three questions specifically answerable from the provided context:\\n\\n1. **Which authors of the paper \"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\" are affiliated with Facebook AI Research?**  (This leverages the combined information of author names and research labs)\\n2. **Did Patrick Lewis or Douwe Kiela publish \"Retrieval-Augmented Generation...\" while at New York University?** (Combines authors, affiliations, and potentially publication year to require specific knowledge)\\n3. **On what page of the PDF document would I find the author list for \"Retrieval-Augmented Generation...\", given this context?** (This tests a subtle but important detail - that we know the page number of this information)'}, excluded_embed_metadata_keys=['block_type', 'file'], excluded_llm_metadata_keys=['authors', 'research_lab', 'file_type'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='fda69868-2c0a-404d-8a76-97e4b57a8a0b', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'block_type': 'Author Names', 'section_title': 'Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks', 'description': 'Lists the names of authors, potentially with affiliations indicated by symbols.', 'file_type': 'application/pdf', 'languages': \"['eng']\", 'page_number': 1, 'filename': 'Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf', 'authors': 'Patrick Lewis,Ethan Perez,Aleksandra Piktus,Fabio Petroni,Vladimir Karpukhin,Naman Goyal,Heinrich KÃ¼ttler,Mike Lewis,Wen-tau Yih,Tim RocktÃ¤schel,Sebastian Riedel,Douwe Kiela', 'research_lab': 'Facebook AI Research,University College London,New York University', 'publication_year': 2020, 'title_of_the_document': 'Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks'}, hash='53fa9949d7b53ac1778ef1ac954ed90ebb339190f604cc51541fe355ba7cf66a')}, text=\"Patrick Lewis'?, Ethan Perez*,\", mimetype='text/plain', start_char_idx=0, end_char_idx=30, text_template='[Excerpt from document]\\n{metadata_str}\\nExcerpt:\\n-----\\n{content}\\n-----\\n', metadata_template='{key}: {value}', metadata_seperator='\\n')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T21:55:02.584337Z",
     "start_time": "2024-09-05T21:55:02.552792Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Guardar la lista de objetos a un archivo\n",
    "with open('embeded_nodes_v2.pkl', 'wb') as outp:  # 'wb' para escribir en modo binario\n",
    "    pickle.dump(nodes, outp, pickle.HIGHEST_PROTOCOL)"
   ],
   "id": "55b1d3a2b536fbcf",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T20:25:16.146609Z",
     "start_time": "2024-08-31T20:25:16.118352Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Leer la lista de objetos desde un archivo\n",
    "with open('embeded_nodes_v2.pkl', 'rb') as inp:  # 'rb' para leer en modo binario\n",
    "    loaded_objects_list = pickle.load(inp)\n",
    "loaded_objects_list[0]"
   ],
   "id": "2e9e437aaa58fc6c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextNode(id_='8ac390ca-3ea4-4bae-b4a2-16b1de584638', embedding=[-0.040346380323171616, -0.022464128211140633, -0.05197039991617203, 0.0053776707500219345, -0.0019971011206507683, 0.0013902459759265184, 0.017468459904193878, 0.024134838953614235, 0.04877280816435814, -0.010017641820013523, -0.030863329768180847, -0.027494480833411217, 0.023229127749800682, 0.013211933895945549, 0.0018636994063854218, -0.021698765456676483, 0.006273228675127029, 0.053895555436611176, -0.0625259280204773, -0.002528643235564232, 0.0072318012826144695, -0.033708736300468445, 0.006138769444078207, -0.047183841466903687, -0.021933559328317642, -0.04295714572072029, 0.05227678641676903, -0.022620609030127525, -0.004851000849157572, -0.006953277625143528, 0.022087588906288147, 0.0642944946885109, 0.015330696478486061, 0.010571449995040894, -0.004879107233136892, 0.05753064900636673, -0.024754401296377182, 0.027319954708218575, 0.02849961631000042, -0.09810864180326462, -0.053667403757572174, 0.013946483843028545, -0.023741140961647034, 0.03641634061932564, -0.04174719750881195, -0.027934961020946503, -0.01388198509812355, 0.08127208054065704, -0.07511822879314423, 0.07405975461006165, 0.013652411289513111, -0.02185610868036747, -0.0778825432062149, 0.0050972760654985905, -0.030438898131251335, 0.03588292747735977, -0.07231242954730988, -0.022972898557782173, 0.009812179021537304, 0.0032175248488783836, 0.02430065907537937, -0.009072229266166687, -0.04765164479613304, -0.01826561614871025, 0.031714774668216705, -0.06869398802518845, -0.003252992406487465, 0.010030820034444332, -0.06747415661811829, 0.05413248389959335, 0.008437090553343296, 0.015079347416758537, -0.032506342977285385, 0.056741129606962204, -0.024129102006554604, -0.06585395336151123, 0.03053176775574684, -0.039428409188985825, 0.029388757422566414, 0.039926815778017044, -0.016101514920592308, 0.047201212495565414, 0.1108238622546196, 0.0071509480476379395, 0.05272647365927696, 0.027213573455810547, 0.05740169435739517, -0.037218254059553146, -0.02053886093199253, -0.0396103672683239, 0.07039336860179901, -0.031655777245759964, -0.020495064556598663, 0.020990941673517227, 0.06589382886886597, -0.04335278645157814, -0.07627701759338379, -0.05575869604945183, 0.03608550503849983, 0.03254794329404831, -0.03667440637946129, -0.015579425729811192, -0.004232249688357115, -0.04519170522689819, 0.023282790556550026, 0.07401926070451736, -0.00974169559776783, -0.015773165971040726, -0.05948369950056076, 0.022366872057318687, -0.007581687066704035, -0.017674801871180534, -0.004300005733966827, 0.004728598985821009, 0.00895193126052618, -0.03708895295858383, -0.03908363729715347, -0.01952529139816761, -0.0038524281699210405, 0.011964203789830208, -0.03940591588616371, 0.0676717460155487, -0.01485616248100996, 0.08131103962659836, 0.00905646663159132, -0.020458370447158813, 0.01656380109488964, -0.04010756313800812, -0.03577771782875061, -0.02144768089056015, 0.1014602854847908, -0.0445934496819973, -0.041875697672367096, -0.005802696105092764, -0.031707558780908585, -0.04221215844154358, 0.036381401121616364, 0.014158021658658981, -0.0013932406436651945, -0.0131224999204278, 0.016281619668006897, -0.03624675050377846, -0.0567038469016552, -0.010060918517410755, 0.016624659299850464, -0.012755588628351688, -0.011214052326977253, 0.013846540823578835, 0.028678489848971367, 0.03853447362780571, -0.019517363980412483, -0.05831938609480858, 0.05181523412466049, 0.01691153272986412, -0.05022097006440163, -0.010970140807330608, 0.02377348579466343, -0.03475824370980263, 0.04372382536530495, -0.0070103611797094345, 0.037657756358385086, -0.012874303385615349, 0.038207314908504486, -0.024890165776014328, -0.044210873544216156, -0.029001425951719284, 0.038904037326574326, 0.007591357920318842, -0.0026665017940104008, 0.043452899903059006, 0.013202349655330181, -0.025882534682750702, -0.07420384883880615, -0.02398987114429474, 0.0424734391272068, 0.009274059906601906, -0.008732430636882782, -0.007922609336674213, 9.437026164960116e-05, -0.0016382207395508885, 0.1030648797750473, 0.004276365507394075, -0.048384133726358414, -0.058320410549640656, 0.0026879962533712387, -0.05705305188894272, 0.02009851485490799, 0.026869678869843483, 0.07668081670999527, 0.024202575907111168, -0.006494731642305851, -0.039702750742435455, 0.048364948481321335, -0.027749648317694664, -0.007705166004598141, -0.025546731427311897, 0.01784856989979744, -0.08340378850698471, -0.03771720081567764, -0.036941803991794586, 0.04983512684702873, -0.010405536741018295, 0.020824093371629715, 0.0004332906974013895, 0.0026180099230259657, 0.005015309900045395, -0.060431431978940964, -0.04451608657836914, 0.020256182178854942, 0.04166049137711525, -0.04496792331337929, -0.012686270289123058, 0.004191623069345951, -0.09020425379276276, -0.014215070754289627, 0.01126172672957182, 0.031172819435596466, 0.020414821803569794, 0.07566110044717789, -0.053935714066028595, 0.006030006799846888, 0.0037109963595867157, -0.03618071228265762, 0.030985740944743156, 0.03532100468873978, 0.01868627406656742, -0.029075907543301582, 0.034518491476774216, 0.03457771614193916, -0.08302561193704605, 0.00548436027020216, -0.010038445703685284, 0.05509832501411438, 0.021874042227864265, -0.01778200827538967, 0.016977133229374886, 0.03653118386864662, 0.023700891062617302, -0.01606316678225994, 0.003445814363658428, -0.0018862051656469703, 0.0590394102036953, 0.03457990661263466, -0.053979724645614624, 0.015041990205645561, 0.039875902235507965, 0.03670590743422508, 0.009364946745336056, 0.027097435668110847, -0.05994969606399536, -0.01162717305123806, -0.022207463160157204, -0.012987150810658932, 0.004165584687143564, -0.07420895993709564, -0.04797714576125145, 0.002439902862533927, 0.00028696050867438316, -0.03848780691623688, -0.03344261646270752, 0.020943092182278633, 0.010914508253335953, -0.011177648790180683, -0.10778477042913437, -0.03502687066793442, -0.04736921563744545, -0.030315417796373367, 0.0050623249262571335, 0.03595632687211037, 0.01653873361647129, 0.02890900894999504, -0.04524023085832596, -0.0339771993458271, -0.026722991839051247, -0.04065878689289093, 0.001023086253553629, 0.007836557924747467, 0.02169378474354744, -0.013311720453202724, -0.030748559162020683, 0.1032882109284401, 0.012067950330674648, -0.07185068726539612, -0.04379213973879814, 0.05684622377157211, -0.09209179878234863, 0.0057464707642793655, 0.021547537297010422, -0.017398545518517494, -0.033208683133125305, 0.04346026852726936, 0.013534018769860268, -0.024204576388001442, -0.03249487653374672, 0.033600836992263794, 0.012166034430265427, 0.003565909806638956, 0.025025319308042526, -0.03383417800068855, 0.00662766769528389, 0.017618197947740555, 0.03372477367520332, 0.002580697648227215, 0.07620369642972946, 0.015002463944256306, 0.014988971874117851, -0.029801663011312485, -0.03409625217318535, -0.11140833795070648, 0.004758446477353573, 0.04801127687096596, 0.020410925149917603, -0.004577420186251402, -0.02048310823738575, -0.0015089972876012325, -0.029419923201203346, -0.1693873256444931, 0.025942139327526093, 0.02357093058526516, -0.009907890111207962, -0.02361501194536686, 0.018865549936890602, -0.024176573380827904, 0.019905181601643562, 0.01717422530055046, 0.007637356873601675, 0.03161590173840523, 0.016626892611384392, 0.045500826090574265, 0.052822574973106384, 0.0277327261865139, -0.012817682698369026, 0.009723059833049774, -0.05490861460566521, -0.009078333154320717, -0.022759055718779564, -0.0075874789617955685, 0.04295619949698448, 0.07606878131628036, 0.0026503882836550474, 0.026170488446950912, 0.033282119780778885, 0.0676514208316803, 0.030646003782749176, -0.02046320214867592, -0.01969726011157036, -0.05208028107881546, -0.013055127114057541, 0.040157023817300797, 0.02863576076924801, 0.0047695995308458805, 0.01894247718155384, 0.045891642570495605, -0.04652203992009163, -0.02740294300019741, 0.0022879280149936676, 0.03544880822300911, -0.013466248288750648, -0.021987956017255783, -0.003010143293067813, 0.013470910489559174, 0.018652813509106636, -0.012763685546815395, 0.024589885026216507, -0.044856488704681396, -0.037990204989910126, 0.039799559861421585, 0.03833442181348801, -0.018347125500440598, 0.006009772419929504, 0.03147762268781662, 0.042674630880355835, 0.023624848574399948, -0.01587265357375145, 0.02019505761563778, 0.01819581724703312, 0.012425468303263187, 0.040907613933086395, -0.004381678067147732, -0.015522276982665062, 8.891067409422249e-05, -0.1097964495420456, 0.04604632407426834, -0.030623577535152435, -0.01822764426469803, 0.0968053862452507, -0.06867825239896774, -0.004078343510627747, 0.013877253979444504, 0.01037338562309742, -0.013483116403222084, 0.0243926253169775, -0.010896221734583378, 0.05179883539676666, -0.008341263979673386, 0.02851574309170246, -0.011298834346234798, 0.03854560852050781, -0.008206442929804325, 0.005771971773356199, 0.011901339516043663, -0.01103740744292736, 0.03792860731482506, -0.05024239793419838, 0.012945078313350677, -0.04030561447143555, 0.0550733283162117, 0.021223681047558784, 0.010332136414945126, 0.0008514468790963292, -0.02096862904727459, -0.013622966594994068, -0.007013548165559769, 0.006369285751134157, -0.053936269134283066, 0.003488754853606224, 0.055430397391319275, -0.03530656546354294, -0.004487860947847366, 0.02576957270503044, 0.007564403582364321, -1.1044086022593547e-05, 0.05360261723399162, 0.033113993704319, -0.0015659165801480412, -0.06123942881822586, 0.008502421900629997, -0.05354369059205055, 0.024813229218125343, 0.016810446977615356, -0.026379156857728958, 0.07578959316015244, -0.01494402252137661, 0.015418504364788532, 0.009713148698210716, 0.06397689878940582, 0.014738863334059715, 0.003127404721453786, -0.002789450343698263, 0.03497998043894768, 0.027231767773628235, -0.025881102308630943, 0.01421562023460865, 0.01278175599873066, -0.013278867118060589, 0.07700997591018677, 0.05032509192824364, 0.002341928891837597, 0.02039916254580021, -0.08069746196269989, 0.054405730217695236, 0.025958919897675514, -0.013628369197249413, -0.05140289291739464, -0.08915740996599197, 0.007542824372649193, 0.04776078462600708, -0.0012630693381652236, -0.030002472922205925, -0.010305637493729591, -0.05876234546303749, -0.030672123655676842, 0.062169332057237625, 0.014615565538406372, -0.023262040689587593, -0.017632273957133293, -0.011805026791989803, 0.035278260707855225, -0.03668946400284767, 0.020339922979474068, 0.06077810749411583, 0.008011897094547749, 0.035130735486745834, 0.02115464210510254, -0.07756675034761429, -0.00010439883772050962, 0.030515480786561966, 0.021596336737275124, 0.04157150909304619, -0.033110350370407104, 0.022473637014627457, 0.010240715928375721, -0.044022854417562485, 0.04320339858531952, -0.019690999761223793, 0.003047749400138855, -0.050133876502513885, 0.022394387051463127, 0.04541425406932831, 0.004126702900975943, 0.04731275886297226, 0.01850728876888752, -0.07583283632993698, 0.011084807105362415, -0.022254271432757378, 0.018368005752563477, 0.034752584993839264, -0.057686757296323776, 0.0015526886563748121, 0.05732372775673866, -0.0012457029661163688, 0.045536186546087265, -0.02209334634244442, -0.03900773823261261, -0.05742564797401428, 0.018158812075853348, -0.04364898055791855, -0.011929243803024292, 0.0029603743460029364, 0.013616496697068214, 0.08886949717998505, -0.02849755994975567, -0.010816083289682865, -0.0071410187520086765, -0.0011550614144653082, 0.013270695693790913, -0.0397016778588295, 0.016206812113523483, -0.08285003155469894, 0.031188063323497772, -0.004223767202347517, -0.029707815498113632, 0.016446027904748917, -0.0005102457944303751, -0.017287477850914, -0.02423095889389515, 0.016025470569729805, -0.005070585757493973, 0.029628464952111244, -0.020721668377518654, -0.03973573446273804, 0.09132643789052963, 0.045545876026153564, -0.008243134245276451, 0.0032901421654969454, 0.06264570355415344, 0.061493437737226486, -0.010634680278599262, 0.031171446666121483, -0.005122629459947348, 0.01489943079650402, 0.013552119955420494, -0.003717078361660242, 0.04351864010095596, 0.07432903349399567, -0.020958811044692993, -0.019165227189660072, 0.0542696937918663, 0.01701164059340954, 0.05987339839339256, -0.024113968014717102, -0.05591155216097832, 0.003587272483855486, 0.009496699087321758, 0.029396429657936096, -0.04890121892094612, 0.017354454845190048, -0.012556557543575764, -0.027545636519789696, -0.026594677940011024, -0.0203944593667984, -0.034903571009635925, 0.025418782606720924, -0.01925632730126381, 0.01808270998299122, -0.02499423734843731, -0.04915964603424072, 0.03784197196364403, -0.0323764830827713, -0.004042585846036673, 0.001821979763917625, 0.003113704500719905, 0.026164015755057335, 0.013434547930955887, -0.07055550068616867, -0.027589980512857437, -0.00939615536481142, 0.05339379236102104, 0.04948083683848381, -0.031310610473155975, 0.0003857246192637831, -0.05231288820505142, 0.055781297385692596, -0.009836658835411072, -0.027015283703804016, 0.04179362580180168, 0.05318298190832138, 0.05018337070941925, -0.0015936457784846425, 0.001250404748134315, -0.026463264599442482, 0.02037636563181877, 0.023483389988541603, -0.029558459296822548, 0.040035080164670944, -0.04789261147379875, -0.058627091348171234, -0.03116818703711033, -0.00042049758485518396, 0.014603218995034695, -0.03216126933693886, -0.005589958280324936, 0.06628748029470444, -0.04350085183978081, 0.015123574994504452, -0.038549210876226425, -0.03070537932217121, -0.008094116114079952, -0.009396190755069256, 0.012871761806309223, -0.020081201568245888, 0.03145045414566994, -0.006790107116103172, -0.02939341776072979, -0.09662415087223053, -0.003075062995776534, -0.023967815563082695, -0.019627472385764122, 0.009186889044940472, -0.013348300941288471, 0.0011196238920092583, 0.04896671324968338, -0.004806309938430786, -0.020943153649568558, 0.03598214313387871, 0.015399687923491001, -0.05422596260905266, -0.0064698378555476665, 0.07115378230810165, -0.035831939429044724, -0.0005090662743896246, 0.014280525967478752, 0.0066014621406793594, -0.04953097552061081, -0.02169152908027172, 0.03597573935985565, 0.0216925460845232, -0.04392745718359947, 0.007636633701622486, -0.031586162745952606, 0.02064693719148636, 0.028934376314282417, 0.015252231620252132, 0.013684342615306377, -0.05032145604491234, 0.028078241273760796, -0.017125345766544342, -0.0036059957928955555, 0.011734611354768276, 0.047007180750370026, -0.0004738426941912621, -0.015609726309776306, -0.007188375107944012, 0.006994013208895922, 0.01175424549728632, -0.036829739809036255, -0.04468922317028046, -0.030052820220589638, 0.025593549013137817, -0.0019538316410034895, 0.03423525393009186, -0.048280056565999985, -0.009859276935458183, -0.0010208792518824339, -0.007983666844666004, -0.022412870079278946, -0.04129395633935928, 0.06024036183953285, 0.03096303902566433, 0.008749835193157196, -0.012026915326714516, -0.0399201475083828, 0.0036009633913636208, 0.023318657651543617, 0.01868494786322117, 0.005733632016927004, 0.0038209669291973114, 0.042781658470630646, 0.01440686360001564, 0.03702092543244362, -0.03153010085225105, -0.06311022490262985, 0.03028717450797558, -0.023983467370271683, 0.027863172814249992, -0.0017011476447805762, 0.07672853767871857, 0.02611422725021839, -0.008652365766465664, -0.016658669337630272, 0.014680986292660236, -0.03007562831044197, -0.0008840655791573226, 0.03341233730316162, -0.010104898363351822, 0.02856934256851673, 0.0007214432116597891, 0.0295257605612278, -0.04457155615091324, 0.009310383349657059, -0.0043184151872992516, -0.019466528668999672, -0.06953853368759155, -0.019330091774463654, 0.023588471114635468, 0.0008990451460704207, 0.00564507907256484, 0.00401631323620677, -0.04550571367144585, 0.011102322489023209, -0.0109770642593503, -0.011468447744846344, 0.05772193521261215, 0.014596360735595226, 0.030649449676275253, 0.0031101321801543236, 0.012377523817121983, 0.019724052399396896, 0.023073388263583183, -0.026157476007938385, -0.027121800929307938, -0.043501097708940506, 0.03728659823536873, 0.042914338409900665, -0.0279090516269207, 0.016857029870152473, -0.052972014993429184, -0.00945388525724411, -0.01779421791434288, 0.019137946888804436, 0.0626954436302185, -0.008423255756497383, -0.014669857919216156, 0.014916274696588516, -0.012775852344930172, -0.04363936185836792, -0.029945317655801773, 0.028727583587169647, -0.046650826930999756, -0.04216068610548973, 0.01313786767423153, -0.021826863288879395, -0.013682182878255844, -0.0017181875882670283, 0.01152459904551506, 0.027309345081448555, 0.02949300967156887, -0.017996765673160553, -0.04049186408519745, -0.013604221865534782, -0.0653429701924324, 0.01835811138153076, 0.008668401278555393, 0.007242333609610796, 0.01567651703953743, -0.014912376180291176, 0.0032328448724001646, -0.02157232165336609, -0.008288515731692314, -0.004861649125814438, 0.015751395374536514, 0.05159173905849457, 0.00694637093693018, -0.0064337411895394325, -0.01062117051333189, -0.023287510499358177, 0.025689471513032913, 0.021541720256209373], metadata={'block_type': 'Author Names', 'section_title': 'Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks', 'description': 'Lists the names of authors, potentially with affiliations indicated by symbols.', 'file_type': 'application/pdf', 'languages': \"['eng']\", 'page_number': 1, 'filename': 'Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf', 'authors': 'Patrick Lewis,Ethan Perez,Aleksandra Piktus,Fabio Petroni,Vladimir Karpukhin,Naman Goyal,Heinrich KÃ¼ttler,Mike Lewis,Wen-tau Yih,Tim RocktÃ¤schel,Sebastian Riedel,Douwe Kiela', 'research_lab': 'Facebook AI Research,University College London,New York University', 'publication_year': 2020, 'title': 1}, excluded_embed_metadata_keys=['title'], excluded_llm_metadata_keys=['authors', 'research_lab'], relationships={<NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5_Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf', node_type=None, metadata={}, hash=None)}, text=\"Patrick Lewis'?, Ethan Perez*,\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T21:55:18.310374Z",
     "start_time": "2024-09-05T21:55:18.033073Z"
    }
   },
   "cell_type": "code",
   "source": "index = VectorStoreIndex(nodes)",
   "id": "58671a7cd80cab12",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T21:55:30.962395Z",
     "start_time": "2024-09-05T21:55:29.906127Z"
    }
   },
   "cell_type": "code",
   "source": "index.storage_context.persist(persist_dir='./data/index/vector_index_prueba_v2')",
   "id": "9f18907e261be47e",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T08:17:31.835361Z",
     "start_time": "2024-09-01T08:17:31.829777Z"
    }
   },
   "cell_type": "code",
   "source": "index.docstore.get_document('d3fc8886-2d86-40e2-be54-f37422e67c1a')",
   "id": "f83cc7816620728c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextNode(id_='d3fc8886-2d86-40e2-be54-f37422e67c1a', embedding=None, metadata={'block_type': 'NarrativeText', 'section_title': 'I Number of instances per dataset', 'description': 'This sentence describes the content of Table 7, indicating it shows the number of data points for training, development, and testing in each dataset used.', 'file_type': 'application/pdf', 'languages': \"['eng']\", 'page_number': 19, 'filename': 'Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf', 'authors': 'Patrick Lewis,Ethan Perez,Aleksandra Piktus,Fabio Petroni,Vladimir Karpukhin,Naman Goyal,Heinrich KÃ¼ttler,Mike Lewis,Wen-tau Yih,Tim RocktÃ¤schel,Sebastian Riedel,Douwe Kiela', 'research_lab': 'Facebook AI Research,University College London,New York University', 'publication_year': 2020, 'title': 'Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks'}, excluded_embed_metadata_keys=['title'], excluded_llm_metadata_keys=['authors', 'research_lab'], relationships={<NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='220_Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf', node_type=None, metadata={}, hash=None)}, text='The number of training, development and test datapoints in each of our datasets is shown in Table 7.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T21:56:05.885076Z",
     "start_time": "2024-09-05T21:56:05.880059Z"
    }
   },
   "cell_type": "code",
   "source": "retriver = index.as_retriever(similarity_top_k=5)",
   "id": "6dc6f964cb93594e",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T21:56:10.105006Z",
     "start_time": "2024-09-05T21:56:09.295343Z"
    }
   },
   "cell_type": "code",
   "source": [
    "r = retriver.retrieve('what is rag system?')\n",
    "for x in map(lambda x: (x.text, x.score), r):\n",
    "    print(x[0], x[1], sep='\\n', end='\\n\\n')"
   ],
   "id": "8f3830c48c867933",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We also compress the document index using FAISS’s compression tools, reducing the CPU memory requirement to 36GB. Scripts to run experiments with RAG can be found at https://github.com/huggingface/transformers/ blob/master/examples/rag/README.md and an interactive demo of a RAG model can be found at https://huggingface.co/rag/\n",
      "0.58772494529224\n",
      "\n",
      "1). The retriever (Dense Passage Retriever [26], henceforth DPR) provides latent documents conditioned on the input, and the seq2seq model (BART [32]) then conditions on these latent documents together with the input to generate the output. We marginalize the latent documents with a top-K approximation, either on a per-output basis (assuming the same document is responsible for all tokens) or a per-token basis (where different documents are responsible for different tokens). Like T5 [51] or BART, RAG can be ﬁne-tuned on any seq2seq task, whereby both the generator and retriever are jointly learned.\n",
      "0.5668941746042162\n",
      "\n",
      "To train the retriever and generator end-to-end, we treat the retrieved document as a latent variable. We propose two models that marginalize over the latent documents in different ways to produce a distribution over generated text. In one approach, RAG-Sequence, the model uses the same document to predict each target token. \n",
      "0.5660505429925944\n",
      "\n",
      "We explore RAG models, which use the input sequence x to retrieve text documents z and use them as additional context when generating the target sequence y. As shown in Figure 1, our models leverage two components: (i) a retriever pη(z|x) with parameters η that returns (top-K truncated) distributions over text passages given a query x and (ii) a generator pθ(yi|x, z, y1:i−1) parametrized\n",
      "0.5638286867951667\n",
      "\n",
      "1Code to run experiments with RAG has been open-sourced as part of the HuggingFace Transform- ers Library [66] and can be found at https://github.com/huggingface/transformers/blob/master/ examples/rag/. An interactive demo of RAG models can be found at https://huggingface.co/rag/\n",
      "0.5638202406020412\n",
      "\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T21:57:05.712622Z",
     "start_time": "2024-09-05T21:57:02.520434Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llm = Settings.llm\n",
    "llm.complete(\"Hello this is a sample text\").text"
   ],
   "id": "a6280091abdfac9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Please provide me with more context or information about what you would like me to do with the sample text \"Hello this is a sample text\". \\n\\nFor example, do you want me to:\\n\\n* Analyze the sentiment of the text?\\n* Translate it into another language?\\n* Identify the grammatical structure of the sentence?\\n* Use it as a starting point for a story?\\n\\nOnce I know what you\\'d like me to do, I can be more helpful! 😊 \\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T21:57:14.970459Z",
     "start_time": "2024-09-05T21:57:14.965435Z"
    }
   },
   "cell_type": "code",
   "source": "query_engine = index.as_query_engine(verbose=True)",
   "id": "6d27733f560c0a0",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T21:57:19.696836Z",
     "start_time": "2024-09-05T21:57:16.787154Z"
    }
   },
   "cell_type": "code",
   "source": "print(query_engine.query('what is rag system?').response)",
   "id": "f11e50deea198ebf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG, or Retrieval-Augmented Generation, is a method that combines a \"retriever\" and a \"seq2seq model\" to generate text. The retriever selects relevant documents based on the input, and the seq2seq model uses both the input and these documents to produce the output. \n",
      "\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T22:00:36.102856Z",
     "start_time": "2024-09-05T22:00:34.365316Z"
    }
   },
   "cell_type": "code",
   "source": "print(query_engine.query('Que es un sistema rag?').response)",
   "id": "4cb3bd38183d068b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Un sistema RAG combina un modelo de generación de lenguaje pre-entrenado con una memoria no paramétrica, como un índice de documentos, para mejorar sus capacidades de generación de texto. \n",
      "\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T22:00:59.658646Z",
     "start_time": "2024-09-05T22:00:58.229412Z"
    }
   },
   "cell_type": "code",
   "source": "print(query_engine.query('Dame titulos de documentos que tengas?').response)",
   "id": "d128d7d2672c9830",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puedo proporcionarte el título del documento \"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\". \n",
      "\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T22:01:18.500216Z",
     "start_time": "2024-09-05T22:01:17.056071Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(query_engine.query(\n",
    "    'Quienes son los autores de: Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.').response)"
   ],
   "id": "3cbd541686eb3e04",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but I cannot answer that question based on the context provided. \n",
      "\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T08:46:14.331811Z",
     "start_time": "2024-09-01T08:46:08.517052Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(query_engine.query(\n",
    "    'Puedes resumir el articulo: Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.').response)"
   ],
   "id": "8f27ab471cf65b3c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Este artículo explora modelos de lenguaje que combinan memoria paramétrica y no paramétrica para la generación de lenguaje. Se enfoca en modelos RAG que usan un modelo pre-entrenado seq2seq como memoria paramétrica y un índice vectorial denso de Wikipedia como memoria no paramétrica, a la que se accede con un recuperador neuronal pre-entrenado. \n",
      "\n",
      "El artículo compara dos formulaciones RAG: una que se condiciona en los mismos pasajes recuperados a través de toda la secuencia generada y otra que puede usar diferentes pasajes por token. Los modelos RAG se evalúan en una amplia gama de tareas de PNL de uso intensivo de conocimiento, incluyendo tareas de preguntas y respuestas de dominio abierto y tareas de generación de lenguaje. \n",
      "\n",
      "Los resultados muestran que los modelos RAG superan a los modelos seq2seq paramétricos y a las arquitecturas de recuperación y extracción específicas de la tarea en las tareas de preguntas y respuestas. Para las tareas de generación de lenguaje, los modelos RAG generan un lenguaje más específico, diverso y fáctico que una línea de base seq2seq de última generación.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 85
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T22:01:46.045452Z",
     "start_time": "2024-09-05T22:01:44.895509Z"
    }
   },
   "cell_type": "code",
   "source": "chat_engine = index.as_chat_engine(chat_mode=\"react\", verbose=True)",
   "id": "59ad59deb1721ea2",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T22:01:55.585026Z",
     "start_time": "2024-09-05T22:01:50.008932Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = chat_engine.chat(\"Hola soy Nicolas, me puedes dar informacion sobre el sistema RAG?\")\n",
    "print(response)"
   ],
   "id": "a8422be464d9cfb4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 723fc0dd-f8b7-4858-b618-50223c179261. Step input: Hola soy Nicolas, me puedes dar informacion sobre el sistema RAG?\n",
      "\u001B[1;3;38;5;200mThought: The current language of the user is: Spanish. I need to use a tool to help me answer the question.\n",
      "Action: query_engine_tool\n",
      "Action Input: {'input': 'What is RAG?'}\n",
      "\u001B[0m\u001B[1;3;34mObservation: RAG, which stands for Retrieval-Augmented Generation, is a method for enhancing pre-trained language models by incorporating a non-parametric memory component. \n",
      "\n",
      "\u001B[0m> Running step 6aaaffba-54a9-40a1-9fd7-2c072bf86377. Step input: None\n",
      "\u001B[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: RAG, o Generación Aumentada por Recuperación, es un método para mejorar los modelos de lenguaje preentrenados al incorporar un componente de memoria no paramétrico. En términos más sencillos, RAG permite que los modelos de lenguaje accedan y utilicen información externa, como documentos o bases de datos, para generar respuestas más completas y precisas.\n",
      "\u001B[0mRAG, o Generación Aumentada por Recuperación, es un método para mejorar los modelos de lenguaje preentrenados al incorporar un componente de memoria no paramétrico. En términos más sencillos, RAG permite que los modelos de lenguaje accedan y utilicen información externa, como documentos o bases de datos, para generar respuestas más completas y precisas.\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T22:02:24.406701Z",
     "start_time": "2024-09-05T22:02:23.559537Z"
    }
   },
   "cell_type": "code",
   "source": "chat_engine.chat('Recuerdas como me llamo?')",
   "id": "1bf5dddbaae9738e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step e00b68f1-e710-4ee8-b1f3-23f7d1a15c1a. Step input: Recuerdas como me llamo?\n",
      "\u001B[1;3;38;5;200mThought: (Implicit) I can answer without any more tools!\n",
      "Answer: Sí, te llamas Nicolas. \n",
      "\n",
      "\u001B[0m"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AgentChatResponse(response='Sí, te llamas Nicolas. \\n', sources=[], source_nodes=[], is_dummy_stream=False, metadata=None)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T22:03:30.423870Z",
     "start_time": "2024-09-05T22:03:24.729059Z"
    }
   },
   "cell_type": "code",
   "source": [
    "streaming_response = chat_engine.stream_chat(\"Hola soy Nicolas, me puedes dar informacion sobre el sistema RAG?\")\n",
    "for token in streaming_response.response_gen:\n",
    "    print(token, end=\"\")"
   ],
   "id": "b1cd103d42f59f0f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 15cae485-4d67-41f4-8d69-9fe89ed0bd07. Step input: Hola soy Nicolas, me puedes dar informacion sobre el sistema RAG?\n",
      "\u001B[1;3;38;5;200mThought: The current language of the user is: Spanish. I need to use a tool to help me answer the question.\n",
      "Action: query_engine_tool\n",
      "Action Input: {'input': 'What is RAG?'}\n",
      "\u001B[0m\u001B[1;3;34mObservation: RAG, which stands for Retrieval-Augmented Generation, is a method for enhancing pre-trained language models by incorporating a non-parametric memory component. \n",
      "\n",
      "\u001B[0m> Running step 4ffb67c7-18ef-4455-ad3c-2b8c5b26f5fa. Step input: None\n",
      "'s language to answer\n",
      "Answer: RAG, o Generación Aumentada por Recuperación, es un método para mejorar los modelos de lenguaje preentrenados al incorporar un componente de memoria no paramétrico. En términos más sencillos, RAG permite que los modelos de lenguaje accedan y utilicen información externa, como documentos o bases de datos, para generar respuestas más completas y precisas. \n"
     ]
    }
   ],
   "execution_count": 34
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T06:14:27.689937Z",
     "start_time": "2024-09-07T06:14:27.683472Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Importante para usar llama Index en Jupyter Notebook\n",
    "import nest_asyncio\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "nest_asyncio.apply()\n",
    "load_dotenv()\n",
    "\n",
    "credentials_path = os.getenv('GCP_CREDENTIALS_PATH')"
   ],
   "id": "2c5bbd74005e9977",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T05:07:37.933148Z",
     "start_time": "2024-09-07T05:07:31.658322Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from llama_index.core import (\n",
    "    Settings,\n",
    "    VectorStoreIndex,\n",
    "    SummaryIndex\n",
    ")\n",
    "from llama_index.llms.vertex import Vertex\n",
    "from GCP.lib import VertexIEmbeddings\n",
    "\n",
    "Settings.embed_model = VertexIEmbeddings(credentials_path=credentials_path)\n",
    "Settings.llm = Vertex(model=\"gemini-1.5-pro-001\")"
   ],
   "id": "8a314a458e2df213",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T05:26:41.726035Z",
     "start_time": "2024-09-07T05:26:41.276118Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "\n",
    "with open('embeded_nodes_v2.pkl', 'rb') as inp:  # 'rb' para leer en modo binario\n",
    "    nodes = pickle.load(inp)\n",
    "\n",
    "vector_index = VectorStoreIndex(nodes)\n",
    "summary_index = SummaryIndex(nodes)\n",
    "\n",
    "vector_query_engine = vector_index.as_query_engine(similarity_top_k=5)\n",
    "summary_query_engine = summary_index.as_query_engine()"
   ],
   "id": "73f63525a57464b9",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T11:00:01.231761Z",
     "start_time": "2024-09-07T11:00:01.226746Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from llama_index.core.tools import QueryEngineTool\n",
    "from llama_index.core.agent import ReActAgent\n",
    "from llama_index.tools.google import GoogleSearchToolSpec \n",
    "\n",
    "summary_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=summary_query_engine,\n",
    "    name=\"summary\",\n",
    "    description=(\n",
    "        \"Useful for paper-related summary questions.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "vector_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=vector_query_engine,\n",
    "    name=\"vector\",\n",
    "    description=(\n",
    "        \"Useful for retrieving specific context from of the paper.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "# google_tool = GoogleSearchToolSpec(key=os.getenv('GOOGLE_SEARCH_API_KEY'), engine='f2159a8a6b9484f93', num=2)\n",
    "\n",
    "agent_tools = [\n",
    "    summary_tool, \n",
    "    vector_tool, \n",
    "    # google_tool\n",
    "]"
   ],
   "id": "b91caa48f3a67c1e",
   "outputs": [],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T10:20:24.891491Z",
     "start_time": "2024-09-07T10:20:24.886982Z"
    }
   },
   "cell_type": "code",
   "source": "agent = ReActAgent.from_tools(agent_tools, verbose=True)",
   "id": "c72cbea5b925a5a9",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T10:22:50.959860Z",
     "start_time": "2024-09-07T10:22:45.180452Z"
    }
   },
   "cell_type": "code",
   "source": "print(agent.query(\"What is the main idea of the paper?\").response)",
   "id": "75e8c3b23317431e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step f24586fc-c64c-4e6e-b2bb-121481ed0a3a. Step input: What is the main idea of the paper?\n",
      "\u001B[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
      "Action: query_engine_tool\n",
      "Action Input: {'input': 'What is the main idea of the paper?'}\n",
      "\u001B[0m\u001B[1;3;34mObservation: This research explores how a retrieval-based architecture can be used to improve the performance of various NLP tasks that require extensive knowledge. \n",
      "\n",
      "\u001B[0m> Running step 7d528b78-b008-43d8-b0bc-baac8b9f5589. Step input: None\n",
      "\u001B[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: This research explores how a retrieval-based architecture can improve the performance of various NLP tasks that require extensive knowledge.\n",
      "\u001B[0mThis research explores how a retrieval-based architecture can improve the performance of various NLP tasks that require extensive knowledge.\n"
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T10:23:14.293456Z",
     "start_time": "2024-09-07T10:23:06.848662Z"
    }
   },
   "cell_type": "code",
   "source": "print(agent.query(\"Cual es la idea principal del articulo?\").response)",
   "id": "d0874fb43eea44e9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step e201bee7-a025-4689-9809-b22317452ded. Step input: Cual es la idea principal del articulo?\n",
      "\u001B[1;3;38;5;200mThought: The current language of the user is: Spanish. I need to use a tool to help me answer the question.\n",
      "Action: query_engine_tool\n",
      "Action Input: {'input': 'What is the main idea of the article?'}\n",
      "\u001B[0m\u001B[1;3;34mObservation: This document focuses on a novel approach to natural language processing called Retrieval-Augmented Generation (RAG). The authors argue that their specific method, which aggregates information from multiple retrieved sources, offers advantages over previous techniques, particularly in knowledge-intensive tasks. They highlight the model's improved factuality, control, and interpretability, suggesting its potential benefits in various real-world applications. \n",
      "\n",
      "\u001B[0m> Running step cfd503c2-b7d3-4bea-b6a7-0f2d69c39ae6. Step input: None\n",
      "\u001B[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: La idea principal del artículo es presentar un nuevo enfoque para el procesamiento del lenguaje natural llamado Generación Aumentada por Recuperación (RAG). Los autores argumentan que su método específico, que agrega información de múltiples fuentes recuperadas, ofrece ventajas sobre las técnicas anteriores, particularmente en tareas que requieren un uso intensivo de conocimiento. Destacan la mejora en la factualidad, el control y la interpretabilidad del modelo, lo que sugiere sus beneficios potenciales en diversas aplicaciones del mundo real.\n",
      "\u001B[0mLa idea principal del artículo es presentar un nuevo enfoque para el procesamiento del lenguaje natural llamado Generación Aumentada por Recuperación (RAG). Los autores argumentan que su método específico, que agrega información de múltiples fuentes recuperadas, ofrece ventajas sobre las técnicas anteriores, particularmente en tareas que requieren un uso intensivo de conocimiento. Destacan la mejora en la factualidad, el control y la interpretabilidad del modelo, lo que sugiere sus beneficios potenciales en diversas aplicaciones del mundo real.\n"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T10:25:21.764992Z",
     "start_time": "2024-09-07T10:25:15.979314Z"
    }
   },
   "cell_type": "code",
   "source": "print(agent.query(\"dame un resumen del paper?\").response)\n",
   "id": "b82e1f419fed902f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 2770eb7e-0be3-4ecf-a439-fbbdc007e433. Step input: dame un resumen del paper?\n",
      "\u001B[1;3;38;5;200mThought: The current language of the user is: Spanish. I need to use a tool to help me answer the question.\n",
      "Action: query_engine_tool\n",
      "Action Input: {'input': 'Please provide a summary of the paper.'}\n",
      "\u001B[0m\u001B[1;3;34mObservation: This research paper explores how a retrieval-based architecture can be used to improve performance across a range of NLP tasks that require extensive knowledge. It builds upon previous research in the field and demonstrates the effectiveness of this approach. \n",
      "\n",
      "\u001B[0m> Running step de97bbaf-f19e-400b-a3ac-030d71fd2001. Step input: None\n",
      "\u001B[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: Este trabajo de investigación explora cómo una arquitectura basada en recuperación puede usarse para mejorar el rendimiento en una variedad de tareas de PNL que requieren un conocimiento extenso. Se basa en investigaciones previas en el campo y demuestra la eficacia de este enfoque.\n",
      "\u001B[0mEste trabajo de investigación explora cómo una arquitectura basada en recuperación puede usarse para mejorar el rendimiento en una variedad de tareas de PNL que requieren un conocimiento extenso. Se basa en investigaciones previas en el campo y demuestra la eficacia de este enfoque.\n"
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T10:28:55.675846Z",
     "start_time": "2024-09-07T10:28:37.329343Z"
    }
   },
   "cell_type": "code",
   "source": "print(agent.query(\"dame un resumen muy completo y detallado del articull 'Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks'\").response)\n",
   "id": "394cf2d24f051283",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 78209244-e6b9-4bcf-8f76-7accf22a9b4d. Step input: dame un resumen muy completo y detallado del articull 'Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks'\n",
      "\u001B[1;3;38;5;200mThought: The current language of the user is: Spanish. I need to use a tool to help me answer the question.\n",
      "Action: query_engine_tool\n",
      "Action Input: {'input': \"Please provide a very complete and detailed summary of the paper 'Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks'.\"}\n",
      "\u001B[0m\u001B[1;3;34mObservation: This research paper introduces a novel approach called Retrieval-Augmented Generation (RAG) to enhance the performance of pre-trained language models on tasks that demand extensive knowledge. The authors argue that while large language models demonstrate impressive capabilities in various NLP tasks, they struggle to effectively utilize specific knowledge when needed. \n",
      "\n",
      "The proposed RAG model tackles this challenge by combining a pre-trained sequence-to-sequence model with a non-parametric memory component. This memory takes the form of a comprehensive index of Wikipedia, accessed through a pre-trained neural retriever. The research explores two distinct RAG model formulations: one that relies on the same retrieved passages throughout the generation process and another that allows for different passages to be used for each generated token.\n",
      "\n",
      "Through extensive experiments on a variety of knowledge-intensive NLP tasks, the researchers demonstrate the superiority of RAG models. Notably, these models achieve state-of-the-art results on three open-domain question answering tasks, surpassing both traditional sequence-to-sequence models and specialized retrieve-and-extract methods. Furthermore, in language generation tasks, RAG models exhibit a remarkable ability to produce text that is more specific, diverse, and factually grounded compared to a purely parametric sequence-to-sequence baseline.\n",
      "\n",
      "The paper also delves into the relationship between RAG and existing retrieve-and-edit approaches, highlighting key differences in how retrieved content is utilized. Instead of focusing on minor edits to a single retrieved item, RAG models excel at aggregating information from multiple retrieved pieces. This distinction underscores the innovative nature of the RAG approach and its potential to significantly advance the field of knowledge-intensive NLP. \n",
      "\n",
      "\u001B[0m> Running step b1844419-598e-4546-ab78-b7572fb39773. Step input: None\n",
      "\u001B[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: El artículo de investigación presenta un nuevo enfoque llamado Generación Aumentada por Recuperación (RAG, por sus siglas en inglés) para mejorar el rendimiento de los modelos de lenguaje pre-entrenados en tareas que requieren un conocimiento extenso. \n",
      "\n",
      "Los autores argumentan que, si bien los grandes modelos de lenguaje demuestran capacidades impresionantes en varias tareas de PNL, tienen dificultades para utilizar eficazmente el conocimiento específico cuando es necesario. El modelo RAG propuesto aborda este desafío combinando un modelo de secuencia a secuencia pre-entrenado con un componente de memoria no paramétrico. Esta memoria toma la forma de un índice completo de Wikipedia, al que se accede a través de un recuperador neuronal pre-entrenado. \n",
      "\n",
      "La investigación explora dos formulaciones distintas del modelo RAG: una que se basa en los mismos pasajes recuperados durante todo el proceso de generación y otra que permite utilizar diferentes pasajes para cada token generado. A través de experimentos extensos en una variedad de tareas de PNL intensivas en conocimiento, los investigadores demuestran la superioridad de los modelos RAG. \n",
      "\n",
      "En particular, estos modelos logran resultados de vanguardia en tres tareas de respuesta a preguntas de dominio abierto, superando tanto a los modelos tradicionales de secuencia a secuencia como a los métodos especializados de recuperación y extracción. Además, en las tareas de generación de lenguaje, los modelos RAG exhiben una notable capacidad para producir texto más específico, diverso y basado en hechos en comparación con una línea de base de secuencia a secuencia puramente paramétrica. \n",
      "\n",
      "El artículo también profundiza en la relación entre RAG y los enfoques existentes de recuperación y edición, destacando las diferencias clave en la forma en que se utiliza el contenido recuperado. En lugar de centrarse en ediciones menores de un solo elemento recuperado, los modelos RAG sobresalen en la agregación de información de múltiples piezas recuperadas. Esta distinción subraya la naturaleza innovadora del enfoque RAG y su potencial para avanzar significativamente en el campo de la PNL intensiva en conocimiento.\n",
      "\u001B[0mEl artículo de investigación presenta un nuevo enfoque llamado Generación Aumentada por Recuperación (RAG, por sus siglas en inglés) para mejorar el rendimiento de los modelos de lenguaje pre-entrenados en tareas que requieren un conocimiento extenso. \n",
      "\n",
      "Los autores argumentan que, si bien los grandes modelos de lenguaje demuestran capacidades impresionantes en varias tareas de PNL, tienen dificultades para utilizar eficazmente el conocimiento específico cuando es necesario. El modelo RAG propuesto aborda este desafío combinando un modelo de secuencia a secuencia pre-entrenado con un componente de memoria no paramétrico. Esta memoria toma la forma de un índice completo de Wikipedia, al que se accede a través de un recuperador neuronal pre-entrenado. \n",
      "\n",
      "La investigación explora dos formulaciones distintas del modelo RAG: una que se basa en los mismos pasajes recuperados durante todo el proceso de generación y otra que permite utilizar diferentes pasajes para cada token generado. A través de experimentos extensos en una variedad de tareas de PNL intensivas en conocimiento, los investigadores demuestran la superioridad de los modelos RAG. \n",
      "\n",
      "En particular, estos modelos logran resultados de vanguardia en tres tareas de respuesta a preguntas de dominio abierto, superando tanto a los modelos tradicionales de secuencia a secuencia como a los métodos especializados de recuperación y extracción. Además, en las tareas de generación de lenguaje, los modelos RAG exhiben una notable capacidad para producir texto más específico, diverso y basado en hechos en comparación con una línea de base de secuencia a secuencia puramente paramétrica. \n",
      "\n",
      "El artículo también profundiza en la relación entre RAG y los enfoques existentes de recuperación y edición, destacando las diferencias clave en la forma en que se utiliza el contenido recuperado. En lugar de centrarse en ediciones menores de un solo elemento recuperado, los modelos RAG sobresalen en la agregación de información de múltiples piezas recuperadas. Esta distinción subraya la naturaleza innovadora del enfoque RAG y su potencial para avanzar significativamente en el campo de la PNL intensiva en conocimiento.\n"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T10:27:50.574606Z",
     "start_time": "2024-09-07T10:27:46.119582Z"
    }
   },
   "cell_type": "code",
   "source": "print(agent.query(\"Dime cual es el titulo del articulo\").response)\n",
   "id": "c1ba748f8e76c4d6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step f4c49110-488c-4c7f-bdcd-cbab756c88e4. Step input: Dime cual es el titulo del articulo\n",
      "\u001B[1;3;38;5;200mThought: The current language of the user is: Spanish. I need to use a tool to help me answer the question.\n",
      "Action: query_engine_tool\n",
      "Action Input: {'input': 'What is the title of the paper?'}\n",
      "\u001B[0m\u001B[1;3;34mObservation: Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks \n",
      "\n",
      "\u001B[0m> Running step 6ad12d5b-e00f-42d4-ada4-224bb2d01d44. Step input: None\n",
      "\u001B[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: El título del artículo es \"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\".\n",
      "\u001B[0mEl título del artículo es \"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\".\n"
     ]
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T10:31:02.258465Z",
     "start_time": "2024-09-07T10:30:57.703241Z"
    }
   },
   "cell_type": "code",
   "source": "print(agent.query(\"Que es el PNL?\").response)",
   "id": "c1a9ac8a0dc7044c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 348fbb8c-5f56-49b7-b951-1fb433a3cbff. Step input: Que es el PNL?\n",
      "\u001B[1;3;38;5;200mThought: The current language of the user is: Spanish. I need to use a tool to help me answer the question.\n",
      "Action: query_engine_tool\n",
      "Action Input: {'input': 'What is NLP?'}\n",
      "\u001B[0m\u001B[1;3;34mObservation: It stands for Natural Language Processing. \n",
      "\n",
      "\u001B[0m> Running step 4889852c-1471-46ce-b1cc-79a278021ccd. Step input: None\n",
      "\u001B[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: PNL significa Procesamiento del Lenguaje Natural. Es un campo de la inteligencia artificial que se enfoca en la interacción entre las computadoras y el lenguaje humano.\n",
      "\u001B[0mPNL significa Procesamiento del Lenguaje Natural. Es un campo de la inteligencia artificial que se enfoca en la interacción entre las computadoras y el lenguaje humano.\n"
     ]
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T10:32:09.643655Z",
     "start_time": "2024-09-07T10:32:02.019579Z"
    }
   },
   "cell_type": "code",
   "source": "print(agent.query(\"Genera una lista de los descubrimientos mas destacables del artigulo de RAG?\").response)",
   "id": "80d950497eb305ce",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step bc031000-3b7a-43b2-995e-72755c2cc65d. Step input: Genera una lista de los descubrimientos mas destacables del artigulo de RAG?\n",
      "\u001B[1;3;38;5;200mThought: The current language of the user is: Spanish. I need to use a tool to help me answer the question.\n",
      "Action: query_engine_tool\n",
      "Action Input: {'input': 'What are the most notable findings of the RAG paper?'}\n",
      "\u001B[0m\u001B[1;3;34mObservation: The researchers found that their RAG models achieved state-of-the-art results on open-domain question answering tasks. Human evaluators preferred RAG's output over a standard BART model, finding it more factual and specific. The researchers also demonstrated the flexibility of the retrieval component, showing it could be updated without retraining the entire model. \n",
      "\n",
      "\u001B[0m> Running step 2d316c83-1aea-4a10-b9a5-55eceb113372. Step input: None\n",
      "\u001B[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: Los descubrimientos más destacables del artículo de RAG son:\n",
      "\n",
      "* **Resultados de vanguardia en tareas de preguntas y respuestas de dominio abierto:** Los modelos RAG lograron resultados innovadores en estas tareas.\n",
      "* **Preferencia humana por las respuestas de RAG:** Los evaluadores humanos prefirieron las respuestas generadas por RAG sobre las de un modelo BART estándar, considerándolas más fácticas y específicas.\n",
      "* **Flexibilidad del componente de recuperación:** Los investigadores demostraron que el componente de recuperación podía actualizarse sin necesidad de volver a entrenar todo el modelo.\n",
      "\u001B[0mLos descubrimientos más destacables del artículo de RAG son:\n",
      "\n",
      "* **Resultados de vanguardia en tareas de preguntas y respuestas de dominio abierto:** Los modelos RAG lograron resultados innovadores en estas tareas.\n",
      "* **Preferencia humana por las respuestas de RAG:** Los evaluadores humanos prefirieron las respuestas generadas por RAG sobre las de un modelo BART estándar, considerándolas más fácticas y específicas.\n",
      "* **Flexibilidad del componente de recuperación:** Los investigadores demostraron que el componente de recuperación podía actualizarse sin necesidad de volver a entrenar todo el modelo.\n"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T11:00:07.874366Z",
     "start_time": "2024-09-07T11:00:06.793760Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from llama_index.core.objects import ObjectIndex\n",
    "\n",
    "obj_index = ObjectIndex.from_objects(\n",
    "    agent_tools,\n",
    "    index_cls=VectorStoreIndex,\n",
    ")"
   ],
   "id": "811a2b50b3cad087",
   "outputs": [],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T11:01:02.902095Z",
     "start_time": "2024-09-07T11:01:02.178695Z"
    }
   },
   "cell_type": "code",
   "source": [
    "obj_retriver = obj_index.as_retriever()\n",
    "res: list[QueryEngineTool] = obj_retriver.retrieve(\"Dame un resumen del articulo\")\n",
    "print(res[0].metadata)\n",
    "res: list[QueryEngineTool] = obj_retriver.retrieve(\"Que significa PNL?\")\n",
    "print(res[0].metadata)"
   ],
   "id": "b70a55d7f2ca613c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ToolMetadata(description='Useful for paper-related summary questions.', name='summary', fn_schema=<class 'llama_index.core.tools.types.DefaultToolFnSchema'>, return_direct=False)\n",
      "ToolMetadata(description='Useful for paper-related summary questions.', name='summary', fn_schema=<class 'llama_index.core.tools.types.DefaultToolFnSchema'>, return_direct=False)\n"
     ]
    }
   ],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T15:05:11.062334Z",
     "start_time": "2024-09-07T15:05:11.058034Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from llama_index.core import ChatPromptTemplate\n",
    "from llama_index.core.llms import ChatMessage, MessageRole\n",
    "\n",
    "agent2 = ReActAgent.from_tools(agent_tools, verbose=True, chat_history=[ChatMessage(content=\"You are an expert system about RAG systems for RENAUL GROUP, your name is RENI.\", role=MessageRole.SYSTEM)])"
   ],
   "id": "725e9c3d4447223d",
   "outputs": [],
   "execution_count": 85
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T15:05:53.231431Z",
     "start_time": "2024-09-07T15:05:51.728305Z"
    }
   },
   "cell_type": "code",
   "source": "print(agent2.chat(\"What is the main idea of the paper?\").response)",
   "id": "1163c387449a4138",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 75620c6e-0e44-4e3e-8ad7-09134165803e. Step input: What is the main idea of the paper?\n",
      "\u001B[1;3;38;5;200mThought: The current language of the user is: English. I need to know which paper the user is referring to.\n",
      "Answer: Please provide me with the paper you are referring to.\n",
      "\u001B[0mPlease provide me with the paper you are referring to.\n"
     ]
    }
   ],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T15:06:20.840394Z",
     "start_time": "2024-09-07T15:06:19.104558Z"
    }
   },
   "cell_type": "code",
   "source": "print(agent2.chat(\"What is your name?\").response)",
   "id": "7a3aafd2d748e40c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step fb1bf06f-c3e2-4c7a-9f73-d98f19aa7587. Step input: What is your name?\n",
      "\u001B[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: I am RENI, an expert system about RAG systems for RENAUL GROUP.\n",
      "\u001B[0mI am RENI, an expert system about RAG systems for RENAUL GROUP.\n"
     ]
    }
   ],
   "execution_count": 90
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

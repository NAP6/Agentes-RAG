{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T11:26:48.279479Z",
     "start_time": "2024-08-29T11:26:09.816991Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from google.oauth2 import service_account\n",
    "from GCP.lib.LlamaIndex_custom.Vertex_LlamaIndex import Vertex\n",
    "import vertexai\n",
    "from vertexai.generative_models import (\n",
    "    GenerationConfig,\n",
    "    GenerativeModel,\n",
    "    Part,\n",
    "    Image\n",
    ")\n",
    "\n",
    "# filename = 'C:\\\\Agentes-RAG\\\\GCP-Credentials\\\\llms-433815-f5629eae9456.json'\n",
    "filename = 'C:\\\\Agentes-RAG\\\\GCP-Credentials\\\\llms-433815-5e7ca2a0c045.json'\n",
    "credentials: service_account.Credentials = (\n",
    "    service_account.Credentials.from_service_account_file(filename)\n",
    ")\n",
    "\n",
    "#Login\n",
    "vertexai.init(project=credentials.project_id, location='us-central1', credentials=credentials)"
   ],
   "id": "b6ab6cb9dcf5b11d",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T11:27:30.640578Z",
     "start_time": "2024-08-29T11:27:28.603473Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llama_endpoint = f\"publishers/meta/models/llama3-405b-instruct-maas\"\n",
    "llama_model = Vertex(\n",
    "    model=llama_endpoint ,endpoint=True, project=credentials.project_id, credentials=credentials\n",
    ")\n",
    "\n",
    "resp = llama_model.complete('Como te llamas, y quien te creo?')\n",
    "print(resp.text)"
   ],
   "id": "4fa38c183843d846",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mi nombre es Llama. Llama significa \"Meta AI de modelo de lenguaje grande\".\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "from vertexai.preview.language_models import TextEmbeddingModel\n",
    "embedd_model = TextEmbeddingModel.from_pretrained(\"text-embedding-004\")\n",
    "\n",
    "res = embedd_model.get_embeddings(['Hola Mundo!', 'Como Estas!'])\n",
    "res[0].values"
   ],
   "id": "aa664e4226b9afe9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T10:46:06.290957Z",
     "start_time": "2024-08-29T10:45:57.258610Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gemini_model = GenerativeModel(\"gemini-1.5-pro-001\")\n",
    "text_part = Part.from_text(\"Hola como te llamas, y quien te creo?\")\n",
    "\n",
    "response = gemini_model.generate_content([text_part])\n",
    "response.text"
   ],
   "id": "ae4eaffe4f819432",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Soy un modelo de lenguaje grande, entrenado por Google. \\n\\nNo tengo nombre como las personas. ðŸ˜Š \\n\\nMi propÃ³sito es ayudarte con la informaciÃ³n y las tareas que me solicites usando el conocimiento que he adquirido durante mi entrenamiento. \\n\\nÂ¿QuÃ© puedo hacer por ti hoy? \\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T10:46:20.087028Z",
     "start_time": "2024-08-29T10:46:06.398103Z"
    }
   },
   "cell_type": "code",
   "source": [
    "img_part = Part.from_image(Image.load_from_file(\"./img.jpg\"))\n",
    "text_part = Part.from_text(\"\"\"\n",
    "Eres un transcriptor, tu trabajo consiste en recibir imagenes y convertirlas en HTML, Markdown o texto plano.\n",
    "\n",
    "Si las imagenes son muy complejas, como graficos fotos de personas, paisajes, etc. Lo describiras  con el mayor detalle posible.\n",
    "\"\"\")\n",
    "\n",
    "content = [\n",
    "    img_part,\n",
    "    text_part\n",
    "]\n",
    "\n",
    "response = gemini_model.generate_content(content)\n",
    "print(response.text)"
   ],
   "id": "c694fcfd33969276",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```html\n",
      "<table>\n",
      "  <thead>\n",
      "    <tr>\n",
      "      <th>Nota</th>\n",
      "      <th>Frecuencia Absoluta</th>\n",
      "      <th>Frecuencia Relativa</th>\n",
      "      <th>Frecuencia Relativa Porcentual (%)</th>\n",
      "    </tr>\n",
      "  </thead>\n",
      "  <tbody>\n",
      "    <tr>\n",
      "      <td>2,8</td>\n",
      "      <td>1</td>\n",
      "      <td>0,041</td>\n",
      "      <td>4,166</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>3,2</td>\n",
      "      <td>4</td>\n",
      "      <td>0,166</td>\n",
      "      <td>16,666</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>3,9</td>\n",
      "      <td>3</td>\n",
      "      <td>0,125</td>\n",
      "      <td>12,500</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>4,2</td>\n",
      "      <td>5</td>\n",
      "      <td>0,208</td>\n",
      "      <td>20,833</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>5,0</td>\n",
      "      <td>4</td>\n",
      "      <td>0,166</td>\n",
      "      <td>16,666</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>5,6</td>\n",
      "      <td>3</td>\n",
      "      <td>0,125</td>\n",
      "      <td>12,500</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>6,0</td>\n",
      "      <td>4</td>\n",
      "      <td>0,166</td>\n",
      "      <td>16,666</td>\n",
      "    </tr>\n",
      "  </tbody>\n",
      "</table>\n",
      "\n",
      "<p>Â¿QuÃ© conclusiones puedes obtener de la tabla anterior?</p>\n",
      "```\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T10:46:33.618862Z",
     "start_time": "2024-08-29T10:46:20.145810Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config_model = GenerationConfig(\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "response = gemini_model.generate_content(content, generation_config=config_model)\n",
    "print(response.text)"
   ],
   "id": "c1c7719261c47228",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<table>\n",
      "  <thead>\n",
      "    <tr>\n",
      "      <th>Nota</th>\n",
      "      <th>Frecuencia Absoluta</th>\n",
      "      <th>Frecuencia Relativa</th>\n",
      "      <th>Frecuencia Relativa Porcentual (%)</th>\n",
      "    </tr>\n",
      "  </thead>\n",
      "  <tbody>\n",
      "    <tr>\n",
      "      <td>2,8</td>\n",
      "      <td>1</td>\n",
      "      <td>0,041</td>\n",
      "      <td>4,166</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>3,2</td>\n",
      "      <td>4</td>\n",
      "      <td>0,166</td>\n",
      "      <td>16,666</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>3,9</td>\n",
      "      <td>3</td>\n",
      "      <td>0,125</td>\n",
      "      <td>12,500</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>4,2</td>\n",
      "      <td>5</td>\n",
      "      <td>0,208</td>\n",
      "      <td>20,833</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>5,0</td>\n",
      "      <td>4</td>\n",
      "      <td>0,166</td>\n",
      "      <td>16,666</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>5,6</td>\n",
      "      <td>3</td>\n",
      "      <td>0,125</td>\n",
      "      <td>12,500</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>6,0</td>\n",
      "      <td>4</td>\n",
      "      <td>0,166</td>\n",
      "      <td>16,666</td>\n",
      "    </tr>\n",
      "  </tbody>\n",
      "</table>\n",
      "\n",
      "Â¿QuÃ© conclusiones puedes obtener de la tabla anterior?\n",
      "\n"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-11T10:54:22.017994Z",
     "start_time": "2024-09-11T10:54:22.010272Z"
    }
   },
   "source": [
    "import pickle\n",
    "from collections import defaultdict\n",
    "from typing import Sequence\n",
    "\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core.schema import BaseNode, MetadataMode\n"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T22:04:24.476848Z",
     "start_time": "2024-09-08T22:04:24.460278Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('C:/Agentes-RAG/src/data/nodes/Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.temporal2.pk', 'rb') as file:\n",
    "    model:Sequence[BaseNode] = pickle.load(file)"
   ],
   "id": "988f65884f7afcf5",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T22:04:26.217601Z",
     "start_time": "2024-09-08T22:04:26.214114Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(model[4].get_content(MetadataMode.ALL))\n",
    "print(len(model))"
   ],
   "id": "1984266c5ac56e9c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block_type: Author Names\n",
      "file_type: application/pdf\n",
      "languages: ['eng']\n",
      "page_number: 1\n",
      "file_name: Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf\n",
      "title_of_the_document: Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\n",
      "image_path: nan\n",
      "makes_sense: True\n",
      "description: Lists the authors of the document.\n",
      "\n",
      "Mike Lewis†, Wen-tau Yih†, Tim Rocktäschel†‡, Sebastian Riedel†‡, Douwe Kiela†\n",
      "11\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T21:11:19.363464Z",
     "start_time": "2024-09-08T21:11:19.355851Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from llama_index.core.schema import NodeRelationship\n",
    "\n",
    "node: BaseNode = model[10]\n",
    "print(node.node_id)\n",
    "print(node.text)\n",
    "print(node.metadata['block_type'])\n",
    "print(node.metadata['image_path'])\n",
    "node.relationships[NodeRelationship.PREVIOUS].node_id\n",
    "res = list(filter(\n",
    "    lambda x: x.node_id == '0_Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks', \n",
    "    model\n",
    "))\n",
    "# if len(res) > 0:\n",
    "#     print(res[0].text)\n",
    "node.metadata\n",
    "\n",
    "res"
   ],
   "id": "64a5403152605402",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5_Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\n",
      "Aleksandra Piktus†, Fabio Petroni†, Vladimir Karpukhin†, Naman Goyal†, Heinrich Küttler†,\n",
      "Author Names\n",
      "nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(id_='0_Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks', embedding=None, metadata={'block_type': 'UncategorizedText', 'file_type': 'application/pdf', 'languages': ['eng'], 'page_number': 1, 'file_name': 'Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf', 'title_of_the_document': 'Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks', 'image_path': nan, 'makes_sense': False, 'description': 'The text block contains a sequence of numbers without any context or explanation, making it nonsensical.'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1_Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks', node_type=None, metadata={}, hash=None)}, text='1 2 0 2', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 89
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T15:48:02.807881Z",
     "start_time": "2024-09-08T15:48:02.799652Z"
    }
   },
   "cell_type": "code",
   "source": [
    "node.metadata['makes_sense'] = True\n",
    "node.metadata['title_of_the_document']"
   ],
   "id": "d60d95f8bbd02db4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T21:14:30.015360Z",
     "start_time": "2024-09-08T21:14:30.001203Z"
    }
   },
   "cell_type": "code",
   "source": "res[0].node_id, res[0].relationships.get(NodeRelationship.PREVIOUS).node_id",
   "id": "7a85de9f0dc79bfe",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'node_id'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[99], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m res[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mnode_id, \u001B[43mres\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrelationships\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mNodeRelationship\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mPREVIOUS\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnode_id\u001B[49m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'NoneType' object has no attribute 'node_id'"
     ]
    }
   ],
   "execution_count": 99
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T15:57:49.494145Z",
     "start_time": "2024-09-08T15:57:49.488654Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.Ingestion.lib.library_custom.llama_index.transformations import Unstructured_Medatata_PostProcessor\n",
    "tranformation = Unstructured_Medatata_PostProcessor()\n",
    "model[3:5]"
   ],
   "id": "b98ee9cf697299df",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id_='3_Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks', embedding=None, metadata={'block_type': 'Title', 'file_type': 'application/pdf', 'languages': ['eng'], 'page_number': 1, 'file_name': 'Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf', 'title_of_the_document': 'Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks', 'image_path': nan}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='2_Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks', node_type=None, metadata={}, hash=None), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4_Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks', node_type=None, metadata={}, hash=None)}, text='Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='4_Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks', embedding=None, metadata={'block_type': 'NarrativeText', 'file_type': 'application/pdf', 'languages': ['eng'], 'page_number': 1, 'file_name': 'Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf', 'title_of_the_document': 'Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks', 'image_path': nan}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3_Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks', node_type=None, metadata={}, hash=None), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5_Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks', node_type=None, metadata={}, hash=None)}, text=\"Patrick Lewis'?, Ethan Perez*,\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T12:19:34.748607Z",
     "start_time": "2024-09-11T12:18:48.689558Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "os.environ['GCP_CREDENTIALS_PATH'] = r\"C:\\Agentes-RAG\\GCP-Credentials\\llms-433815-5e7ca2a0c045.json\"\n",
    "\n",
    "from src.app.config import Config\n",
    "# Config.set_gcp_llm_by_name('gemini-1.5-flash-001')\n",
    "print(Config.llm.model)\n",
    "# llm = Config.llm\n",
    "# print(llm.complete('Hola').text)\n",
    "\n",
    "from src.app.agent.load_index import NodeLoaderAgent\n",
    "\n",
    "indx_agent = NodeLoaderAgent(\n",
    "    pkl_path='C:/Agentes-RAG/GCP/Procesar Bloques Unstructured/embeded_nodes_v2.pkl',\n",
    "    verbose=False\n",
    ")"
   ],
   "id": "f5ca084698132b9b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gemini-1.5-pro-001\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T07:28:09.397470Z",
     "start_time": "2024-09-11T07:28:09.370769Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sq = indx_agent.summary_index\n",
    "ret = sq.as_retriever().retrieve('Give me a summary')\n",
    "print(len(ret))"
   ],
   "id": "a7b316eeb5f7cad7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T12:19:45.114898Z",
     "start_time": "2024-09-11T12:19:45.105670Z"
    }
   },
   "cell_type": "code",
   "source": [
    "qe = indx_agent.summary_qe\n",
    "qe"
   ],
   "id": "584b5b881b2f0466",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine at 0x1a48dc5b170>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T07:29:01.696170Z",
     "start_time": "2024-09-11T07:28:12.487687Z"
    }
   },
   "cell_type": "code",
   "source": [
    "res = qe.query('Give me a summary') # ventana de contexto por defecto\n",
    "res.response"
   ],
   "id": "220885a9df840b05",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The retrieval component would \"collapse\" and learn to retrieve the same documents regardless of the input for tasks such as story generation [11]. \\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T11:26:39.994056Z",
     "start_time": "2024-09-11T11:26:30.962693Z"
    }
   },
   "cell_type": "code",
   "source": [
    "res = qe.query('Give me a summary') # ventana de contexto de 1 millon de tokens\n",
    "res.response"
   ],
   "id": "f9d66eb408785794",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This research paper explores Retrieval-Augmented Generation (RAG) models, which combine pre-trained language models with access to external knowledge. The authors demonstrate that RAG models outperform other approaches on tasks like question answering and fact verification. They also highlight the advantages of RAG models, such as their flexibility and ability to update their knowledge easily. The paper discusses the technical details of RAG models, including their components, training process, and decoding strategies. It also explores the challenges of using external knowledge sources and the potential societal impact of these models. \\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T12:20:15.155616Z",
     "start_time": "2024-09-11T12:20:04.527356Z"
    }
   },
   "cell_type": "code",
   "source": [
    "res = qe.query('Give me a summary') # ventana de contexto de 1 millon de tokens Gemini 1.5 Pro\n",
    "res.response"
   ],
   "id": "174d7bcf18826bcc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This document presents research on Retrieval-Augmented Generation (RAG) models for knowledge-intensive NLP tasks. RAG models combine pre-trained parametric and non-parametric memory for language generation, achieving state-of-the-art results on various tasks, including open-domain question answering, abstractive question answering, Jeopardy question generation, and fact verification. The authors explore two RAG formulations: RAG-Sequence and RAG-Token, and demonstrate their effectiveness through extensive experiments and comparisons with existing models. The research highlights the benefits of combining parametric and non-parametric memory, showcasing RAG's ability to generate more factual, specific, and diverse language while mitigating issues like hallucination. The authors also discuss the flexibility of RAG models in updating knowledge and explore potential societal benefits and drawbacks. \\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T07:29:30.004494Z",
     "start_time": "2024-09-11T07:29:29.997156Z"
    }
   },
   "cell_type": "code",
   "source": "res.response",
   "id": "3cc8307723672449",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The retrieval component would \"collapse\" and learn to retrieve the same documents regardless of the input for tasks such as story generation [11]. \\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T10:54:25.228036Z",
     "start_time": "2024-09-11T10:54:25.214394Z"
    }
   },
   "cell_type": "code",
   "source": "Settings.context_window",
   "id": "459d6762e200007a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3900"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T11:12:15.020465Z",
     "start_time": "2024-09-11T11:12:15.009286Z"
    }
   },
   "cell_type": "code",
   "source": "Settings.llm.metadata",
   "id": "9b542e062d9592db",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMMetadata(context_window=3900, num_output=256, is_chat_model=True, is_function_calling_model=True, model_name='gemini-1.5-flash-001', system_role=<MessageRole.USER: 'user'>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T13:53:17.619771Z",
     "start_time": "2024-09-11T13:53:14.496717Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Config.llm.complete(\"\"\"Construct a very short prompt that accurately describes the use of this information retrieval tool for performing Query Answering (QA) tasks. This tool contains a document with the following information:\n",
    "    <document>\n",
    "    This document presents research on Retrieval-Augmented Generation (RAG) models for knowledge-intensive NLP tasks. RAG models combine pre-trained parametric and non-parametric memory for language generation, achieving state-of-the-art results on various tasks, including open-domain question answering, abstractive question answering, Jeopardy question generation, and fact verification. The authors explore two RAG formulations: RAG-Sequence and RAG-Token, and demonstrate their effectiveness through extensive experiments and comparisons with existing models. The research highlights the benefits of combining parametric and non-parametric memory, showcasing RAG's ability to generate more factual, specific, and diverse language while mitigating issues like hallucination. The authors also discuss the flexibility of RAG models in updating knowledge and explore potential societal benefits and drawbacks.\n",
    "    </document>\n",
    "The description should be brief and primarily based on the following example:\n",
    "    <example_prompt>\n",
    "    Useful for any requests that require a holistic summary of EVERYTHING about California. For questions  more specific sections, please use the vector_tool.about\n",
    "    </example_prompt>\n",
    "Additionally, include minimal but relevant information about the tool itself, such as how it works and specific examples of when it would be useful, particularly in the context of the document.\"\"\").text"
   ],
   "id": "d2bc20ba5e2078ee",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"**Prompt:**\\n\\nUseful for answering questions about **Retrieval-Augmented Generation (RAG) models** and their applications in **knowledge-intensive NLP tasks**. \\n\\n**Explanation:**\\n\\nThis tool utilizes a document summarizing research on RAG models. It's particularly helpful for questions about how RAG models combine different memory types for language generation, their effectiveness in tasks like **question answering and fact verification**, and their potential benefits and drawbacks. For questions about specific RAG formulations (e.g., RAG-Sequence), consider refining your query. \\n\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c72bed2b530cc9b4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
